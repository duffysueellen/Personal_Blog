[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!"
  },
  {
    "objectID": "posts/my-new-post/index.html",
    "href": "posts/my-new-post/index.html",
    "title": "Future Post",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Patient Provider Relationship, A Synthetic Social Network",
    "section": "",
    "text": "POST 8\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPOST 9\n\n\nmostly notes\n\n\n\n\ncode\n\n\nanalysis\n\n\nblock_model\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2024\n\n\nSue-Ellen Duffy\n\n\n\n\n\n\n  \n\n\n\n\nPOST 9\n\n\nmostly notes\n\n\n\n\ncode\n\n\nanalysis\n\n\nblock_model\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2024\n\n\nSue-Ellen Duffy\n\n\n\n\n\n\n  \n\n\n\n\nPOST 10\n\n\nGender Matrix\n\n\n\n\ncode\n\n\nanalysis\n\n\nblock_model\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2024\n\n\nSue-Ellen Duffy\n\n\n\n\n\n\n  \n\n\n\n\nPOST 8\n\n\nCUG\n\n\n\n\ncode\n\n\nanalysis\n\n\nblock_model\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2024\n\n\nSue-Ellen Duffy\n\n\n\n\n\n\n  \n\n\n\n\nPOST 7\n\n\nNetwork Block Modeling - Geographical Comparisson\n\n\n\n\ncode\n\n\nanalysis\n\n\nblock_model\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2024\n\n\nSue-Ellen Duffy\n\n\n\n\n\n\n  \n\n\n\n\nPOST 6\n\n\nNetwork Block Modeling - Geographical Comparisson\n\n\n\n\ncode\n\n\nanalysis\n\n\nblock_model\n\n\n\n\n\n\n\n\n\n\n\nMay 2, 2024\n\n\nSue-Ellen Duffy\n\n\n\n\n\n\n  \n\n\n\n\nPOST 5\n\n\nNetwork Block Modeling - Geographical Comparisson\n\n\n\n\ncode\n\n\nanalysis\n\n\nblock_model\n\n\nprovider network\n\n\ngeography\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2024\n\n\nSue-Ellen Duffy\n\n\n\n\n\n\n  \n\n\n\n\nPOST 4\n\n\nNetwork Block Modeling - Providers\n\n\n\n\ncode\n\n\nanalysis\n\n\nblock_model\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2024\n\n\nSue-Ellen Duffy\n\n\n\n\n\n\n  \n\n\n\n\nPOST 3\n\n\nNetwork Block Modeling - Patients\n\n\n\n\ncode\n\n\nanalysis\n\n\nblock_model\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2024\n\n\nSue-Ellen Duffy\n\n\n\n\n\n\n  \n\n\n\n\nPOST 2\n\n\nNetwork Exploration\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2024\n\n\nSue-Ellen Duffy\n\n\n\n\n\n\n  \n\n\n\n\nPOST 1\n\n\nData Cleaning, Exploration, and Network Analysis\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2024\n\n\nSue-Ellen Duffy\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/Post_One/post_1.html",
    "href": "posts/Post_One/post_1.html",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "",
    "text": "Data for this project were taken from Synthetic Mass, which creates Synthetic patient data from Synthea.\nWhile a whole host of datasets are available within each download, I will focus this project on three datasets: patients.csv, providers.csv, and encounters.csv.\nThis post will primarily focus on data cleaning and data exploration with some exploration into social network analysis through transforming the data into an incidence matrix and plotting some attributes.\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(statnet)\nlibrary(ggplot2)\nlibrary(patchwork)"
  },
  {
    "objectID": "posts/Post_One/post_1.html#patient-data",
    "href": "posts/Post_One/post_1.html#patient-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "PATIENT DATA",
    "text": "PATIENT DATA\nThe following table is the data available in the patient dataset.\n\npatients &lt;- read_csv(\"synthea_sample_data_csv_latest/patients.csv\")\n\nRows: 121 Columns: 27\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (19): Id, SSN, DRIVERS, PASSPORT, PREFIX, FIRST, LAST, SUFFIX, MAIDEN, ...\ndbl   (6): FIPS, LAT, LON, HEALTHCARE_EXPENSES, HEALTHCARE_COVERAGE, INCOME\ndate  (2): BIRTHDATE, DEATHDATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhead(patients)\n\n# A tibble: 6 × 27\n  Id      BIRTHDATE  DEATHDATE  SSN   DRIVERS PASSPORT PREFIX FIRST LAST  SUFFIX\n  &lt;chr&gt;   &lt;date&gt;     &lt;date&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; \n1 b573d4… 1988-02-12 2004-12-30 999-… S99986… &lt;NA&gt;     &lt;NA&gt;   Avri… Olso… &lt;NA&gt;  \n2 270357… 1999-03-13 NA         999-… S99998… X640979… Ms.    Norm… Lang… &lt;NA&gt;  \n3 35589a… 2003-02-05 NA         999-… S99996… X735788… Ms.    Pegg… Eich… &lt;NA&gt;  \n4 d46186… 1986-11-07 NA         999-… S99939… X782935… Mrs.   Ashl… Will… &lt;NA&gt;  \n5 983105… 1999-05-21 NA         999-… S99973… X519829… Ms.    Chri… Anku… &lt;NA&gt;  \n6 54ac07… 1988-02-12 NA         999-… S99995… X507824… Mrs.   Dion… O'Ko… &lt;NA&gt;  \n# ℹ 17 more variables: MAIDEN &lt;chr&gt;, MARITAL &lt;chr&gt;, RACE &lt;chr&gt;,\n#   ETHNICITY &lt;chr&gt;, GENDER &lt;chr&gt;, BIRTHPLACE &lt;chr&gt;, ADDRESS &lt;chr&gt;, CITY &lt;chr&gt;,\n#   STATE &lt;chr&gt;, COUNTY &lt;chr&gt;, FIPS &lt;dbl&gt;, ZIP &lt;chr&gt;, LAT &lt;dbl&gt;, LON &lt;dbl&gt;,\n#   HEALTHCARE_EXPENSES &lt;dbl&gt;, HEALTHCARE_COVERAGE &lt;dbl&gt;, INCOME &lt;dbl&gt;\n\n\n\nstr(patients)\n\nspc_tbl_ [121 × 27] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Id                 : chr [1:121] \"b573d409-cfaf-c585-a25b-e9d4cf510bd3\" \"2703570e-f634-d4cc-13db-2ae14e19ae59\" \"35589a76-2a97-0a89-8c2d-56defc8627af\" \"d46186a3-507c-0b22-1bfc-1f88bd7cbd7d\" ...\n $ BIRTHDATE          : Date[1:121], format: \"1988-02-12\" \"1999-03-13\" ...\n $ DEATHDATE          : Date[1:121], format: \"2004-12-30\" NA ...\n $ SSN                : chr [1:121] \"999-97-2089\" \"999-76-8207\" \"999-64-2625\" \"999-67-4853\" ...\n $ DRIVERS            : chr [1:121] \"S99986968\" \"S99998444\" \"S99996738\" \"S99939817\" ...\n $ PASSPORT           : chr [1:121] NA \"X64097979X\" \"X7357887X\" \"X78293510X\" ...\n $ PREFIX             : chr [1:121] NA \"Ms.\" \"Ms.\" \"Mrs.\" ...\n $ FIRST              : chr [1:121] \"Avril120\" \"Norma469\" \"Peggie783\" \"Ashlie138\" ...\n $ LAST               : chr [1:121] \"Olson653\" \"Langosh790\" \"Eichmann909\" \"Williamson769\" ...\n $ SUFFIX             : chr [1:121] NA NA NA NA ...\n $ MAIDEN             : chr [1:121] NA NA NA \"Cummerata161\" ...\n $ MARITAL            : chr [1:121] NA NA NA \"M\" ...\n $ RACE               : chr [1:121] \"white\" \"white\" \"white\" \"white\" ...\n $ ETHNICITY          : chr [1:121] \"nonhispanic\" \"nonhispanic\" \"nonhispanic\" \"nonhispanic\" ...\n $ GENDER             : chr [1:121] \"F\" \"F\" \"F\" \"F\" ...\n $ BIRTHPLACE         : chr [1:121] \"Quincy  Massachusetts  US\" \"Somerville  Massachusetts  US\" \"Pittsfield  Massachusetts  US\" \"Salem  Massachusetts  US\" ...\n $ ADDRESS            : chr [1:121] \"590 Kuhic Frontage road\" \"525 Gleason Burg Suite 75\" \"230 Ratke Neck Suite 55\" \"355 Eichmann Underpass\" ...\n $ CITY               : chr [1:121] \"Newton\" \"Bridgewater\" \"Walpole\" \"Lexington\" ...\n $ STATE              : chr [1:121] \"Massachusetts\" \"Massachusetts\" \"Massachusetts\" \"Massachusetts\" ...\n $ COUNTY             : chr [1:121] \"Middlesex County\" \"Plymouth County\" \"Norfolk County\" \"Middlesex County\" ...\n $ FIPS               : num [1:121] 25017 25023 25021 25017 25017 ...\n $ ZIP                : chr [1:121] \"02461\" \"02324\" \"02081\" \"02421\" ...\n $ LAT                : num [1:121] 42.4 42 42.1 42.4 42.3 ...\n $ LON                : num [1:121] -71.2 -71 -71.2 -71.2 -71.5 ...\n $ HEALTHCARE_EXPENSES: num [1:121] 31150 50725 65580 162538 141345 ...\n $ HEALTHCARE_COVERAGE: num [1:121] 129135 100008 32578 809077 282706 ...\n $ INCOME             : num [1:121] 482269 190464 78997 6472 141475 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Id = col_character(),\n  ..   BIRTHDATE = col_date(format = \"\"),\n  ..   DEATHDATE = col_date(format = \"\"),\n  ..   SSN = col_character(),\n  ..   DRIVERS = col_character(),\n  ..   PASSPORT = col_character(),\n  ..   PREFIX = col_character(),\n  ..   FIRST = col_character(),\n  ..   LAST = col_character(),\n  ..   SUFFIX = col_character(),\n  ..   MAIDEN = col_character(),\n  ..   MARITAL = col_character(),\n  ..   RACE = col_character(),\n  ..   ETHNICITY = col_character(),\n  ..   GENDER = col_character(),\n  ..   BIRTHPLACE = col_character(),\n  ..   ADDRESS = col_character(),\n  ..   CITY = col_character(),\n  ..   STATE = col_character(),\n  ..   COUNTY = col_character(),\n  ..   FIPS = col_double(),\n  ..   ZIP = col_character(),\n  ..   LAT = col_double(),\n  ..   LON = col_double(),\n  ..   HEALTHCARE_EXPENSES = col_double(),\n  ..   HEALTHCARE_COVERAGE = col_double(),\n  ..   INCOME = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nsummary(patients)\n\n      Id              BIRTHDATE            DEATHDATE         \n Length:121         Min.   :1915-06-30   Min.   :1974-12-14  \n Class :character   1st Qu.:1959-04-12   1st Qu.:2004-04-13  \n Mode  :character   Median :1983-05-26   Median :2010-05-15  \n                    Mean   :1979-08-14   Mean   :2008-12-31  \n                    3rd Qu.:1999-09-28   3rd Qu.:2019-12-16  \n                    Max.   :2022-08-22   Max.   :2023-10-05  \n                                         NA's   :100         \n     SSN              DRIVERS            PASSPORT            PREFIX         \n Length:121         Length:121         Length:121         Length:121        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    FIRST               LAST              SUFFIX             MAIDEN         \n Length:121         Length:121         Length:121         Length:121        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   MARITAL              RACE            ETHNICITY            GENDER         \n Length:121         Length:121         Length:121         Length:121        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  BIRTHPLACE          ADDRESS              CITY              STATE          \n Length:121         Length:121         Length:121         Length:121        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    COUNTY               FIPS           ZIP                 LAT       \n Length:121         Min.   :25001   Length:121         Min.   :41.56  \n Class :character   1st Qu.:25014   Class :character   1st Qu.:42.15  \n Mode  :character   Median :25017   Mode  :character   Median :42.28  \n                    Mean   :25018                      Mean   :42.24  \n                    3rd Qu.:25025                      3rd Qu.:42.40  \n                    Max.   :25027                      Max.   :42.77  \n                    NA's   :19                                        \n      LON         HEALTHCARE_EXPENSES HEALTHCARE_COVERAGE     INCOME      \n Min.   :-73.26   Min.   :    500     Min.   :      0     Min.   :  3365  \n 1st Qu.:-71.51   1st Qu.:  21279     1st Qu.:  23029     1st Qu.: 32577  \n Median :-71.13   Median :  65580     Median : 165466     Median : 71082  \n Mean   :-71.27   Mean   : 166163     Mean   : 409297     Mean   :134519  \n 3rd Qu.:-71.01   3rd Qu.: 221068     3rd Qu.: 679128     3rd Qu.:135462  \n Max.   :-70.12   Max.   :1547205     Max.   :1955909     Max.   :931642  \n                                                                          \n\n\n\n#create NAME column combining FIRST and LAST names\npatients &lt;- patients %&gt;%\n    rename(PATIENT = Id) %&gt;%\n  unite(NAME, FIRST, LAST, sep = \" \")\n\n#trim whitespace NAME\npatients$NAME &lt;- trimws(patients$NAME)\n\n#trim whitespace COUNTY\npatients$CITY &lt;- trimws(patients$CITY)\n\n#clean up GENDER, RACE, ETHNICITY, and INCOME sections\npatients &lt;- patients %&gt;%\n  mutate(\n    GENDER = tolower(GENDER),\n    GENDER = case_when(\n      GENDER %in% c(\"male\", \"m\", \"man\") ~ \"Male\",\n      GENDER %in% c(\"female\", \"f\", \"woman\") ~ \"Female\",\n      TRUE ~ NA_character_  # assign NA to any non-standard values\n    ),\n# race (patient)\n    RACE = tolower(RACE),  # convert race to lower case for consistency\n\n# ethnicity (patient)\n    ETHNICITY = tolower(ETHNICITY),  # convert ethnicity to lower case for consistency\n\n# marital (patient)\n    MARITAL = ifelse(MARITAL == \"M\", \"Married\",\n                    ifelse(MARITAL == \"D\", \"Divorced\",\n                    ifelse(MARITAL == \"W\", \"Widowed\",\n                    ifelse(MARITAL == \"S\", \"Single\", MARITAL)))),\n\n# income (patient)\n    INCOME = as.numeric(INCOME)  # convert income to numeric if necessary\n  ) %&gt;%\n  drop_na(GENDER, RACE) \n\nI am only keeping the demographic data below (gender, race, marital status, income, and age) which will be used as an attribute for each patient.\n\n#Create AGE from BIRTHDATE\npatients &lt;- patients %&gt;%\n  mutate(\n    BIRTHDATE = as.Date(BIRTHDATE),  # Ensure 'dob' is in Date format\n    AGE = interval(BIRTHDATE, today()) / years(1)  # Calculate age in years\n  ) %&gt;%\n  mutate(\n    AGE = floor(AGE)  # complete years only, removing decimal\n  )\n# Only keep patient name and demographics. This will be utilized as the attribute data for analysis.\npat_attr &lt;- patients%&gt;% \n  select(NAME, GENDER, RACE, MARITAL, CITY, INCOME, AGE)\nhead(pat_attr)\n\n# A tibble: 6 × 7\n  NAME                       GENDER RACE  MARITAL CITY        INCOME   AGE\n  &lt;chr&gt;                      &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 Avril120 Olson653          Female white &lt;NA&gt;    Newton      482269    36\n2 Norma469 Langosh790        Female white &lt;NA&gt;    Bridgewater 190464    25\n3 Peggie783 Eichmann909      Female white &lt;NA&gt;    Walpole      78997    21\n4 Ashlie138 Williamson769    Female white Married Lexington     6472    37\n5 Christiane220 Ankunding277 Female white &lt;NA&gt;    Hopkinton   141475    24\n6 Dione665 O'Kon634          Female white Married Newton      482269    36\n\n\n\npat_race &lt;- ggplot(pat_attr,aes(RACE)) + geom_bar()\npat_gender &lt;- ggplot(pat_attr,aes(GENDER)) + geom_bar()\n\npat_race + pat_gender + plot_annotation(title = \"Patient Race and Gender Breakdown\")\n\n\n\nggplot(pat_attr,aes(MARITAL)) + geom_bar() + labs(title = \"Patient Marital Status\")\n\n\n\npat_income &lt;- ggplot(pat_attr, aes(x = 1, y = INCOME)) +\n    geom_jitter(width = 0.2) +\n    labs(x = NULL, y = \"Income\") +\n    theme_minimal() + labs(title = \"Patient Income\")\n\nsummary(pat_attr$INCOME)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   3365   32577   71082  134519  135462  931642 \n\npat_age &lt;- ggplot(pat_attr,aes(AGE)) + geom_bar()"
  },
  {
    "objectID": "posts/Post_One/post_1.html#provider-data",
    "href": "posts/Post_One/post_1.html#provider-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "PROVIDER DATA",
    "text": "PROVIDER DATA\nThe following table is the data available in the provider dataset.\n\nproviders &lt;- read_csv(\"synthea_sample_data_csv_latest/providers.csv\") %&gt;%\n    rename(PROVIDER = Id)\n\nRows: 279 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (9): Id, ORGANIZATION, NAME, GENDER, SPECIALITY, ADDRESS, CITY, STATE, ZIP\ndbl (4): LAT, LON, ENCOUNTERS, PROCEDURES\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(providers)\n\n# A tibble: 6 × 13\n  PROVIDER  ORGANIZATION NAME  GENDER SPECIALITY ADDRESS CITY  STATE ZIP     LAT\n  &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 586477e1… 74ab949d-17… Ted9… M      GENERAL P… 881 Ma… Fitc… MA    01420  42.6\n2 4b284e0c… e09d4c49-c2… Barb… F      GENERAL P… 60 HOS… LEOM… MA    0145…  42.5\n3 88668b3f… e76b5eb0-0c… Gise… F      GENERAL P… 1400 V… West… MA    02132  42.3\n4 21a7f0e9… 77645e49-3f… Vell… F      GENERAL P… 363 HI… FALL… MA    0272…  41.7\n5 49671606… aa682136-a4… Prec… F      GENERAL P… 501 CO… NORW… MA    0206…  42.2\n6 bcc6badc… d2284f74-b6… Fern… F      GENERAL P… 331 E … E FA… MA    0253…  41.6\n# ℹ 3 more variables: LON &lt;dbl&gt;, ENCOUNTERS &lt;dbl&gt;, PROCEDURES &lt;dbl&gt;\n\n\nI am only keeping the demographic data below (gender) which will be used as an attribute for each provider.\n\n#trim whitespace NAME\nproviders$NAME &lt;- trimws(providers$NAME)\n\n\nggplot(providers, aes(GENDER)) +geom_bar() + labs(title = \"Provider Gender Breakdown\")"
  },
  {
    "objectID": "posts/Post_One/post_1.html#patient-and-provider",
    "href": "posts/Post_One/post_1.html#patient-and-provider",
    "title": "The Patient Provider Relationship, A Synthetic Social Network",
    "section": "PATIENT AND PROVIDER",
    "text": "PATIENT AND PROVIDER\n\n#combine pro and pat attr\npat_attr$type &lt;- \"PATIENT\"\npro_attr$type &lt;- \"PROVIDER\"\nboth_attr &lt;- bind_rows(pat_attr, pro_attr)\nhead(both_attr)\n\n# A tibble: 6 × 7\n  NAME                       GENDER RACE  MARITAL INCOME   AGE type   \n  &lt;chr&gt;                      &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  \n1 Avril120 Olson653          F      white &lt;NA&gt;    482269    36 PATIENT\n2 Norma469 Langosh790        F      white &lt;NA&gt;    190464    25 PATIENT\n3 Peggie783 Eichmann909      F      white &lt;NA&gt;     78997    21 PATIENT\n4 Ashlie138 Williamson769    F      white M         6472    37 PATIENT\n5 Christiane220 Ankunding277 F      white &lt;NA&gt;    141475    24 PATIENT\n6 Dione665 O'Kon634          F      white M       482269    36 PATIENT"
  },
  {
    "objectID": "posts/Post_One/post_1.html#encounter-data",
    "href": "posts/Post_One/post_1.html#encounter-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "ENCOUNTER DATA",
    "text": "ENCOUNTER DATA\n\nencounters &lt;- read_csv(\"synthea_sample_data_csv_latest/encounters.csv\")\n\nRows: 11987 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (8): Id, PATIENT, ORGANIZATION, PROVIDER, PAYER, ENCOUNTERCLASS, DESCRI...\ndbl  (5): CODE, BASE_ENCOUNTER_COST, TOTAL_CLAIM_COST, PAYER_COVERAGE, REASO...\ndttm (2): START, STOP\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(encounters)\n\n# A tibble: 6 × 15\n  Id       START               STOP                PATIENT ORGANIZATION PROVIDER\n  &lt;chr&gt;    &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;   \n1 4afc6ab… 2013-11-02 00:34:37 2013-11-02 00:49:37 270357… 51370692-62… c0cc76b…\n2 c502ee2… 2014-11-01 12:48:31 2014-11-01 13:03:31 35589a… 57e4e5fa-d6… 896d5c7…\n3 6f3ad10… 1995-02-03 08:38:10 1995-02-03 08:53:10 b573d4… 67d2f85b-dd… 4087a49…\n4 0d9b475… 2015-02-25 16:48:31 2015-02-25 17:17:55 35589a… ca62a361-9c… 370ff56…\n5 ec0d6c6… 2013-11-09 00:34:37 2013-11-09 00:49:37 270357… 51370692-62… c0cc76b…\n6 ec41ff9… 2014-03-16 11:34:37 2014-03-16 11:49:37 270357… 51370692-62… c0cc76b…\n# ℹ 9 more variables: PAYER &lt;chr&gt;, ENCOUNTERCLASS &lt;chr&gt;, CODE &lt;dbl&gt;,\n#   DESCRIPTION &lt;chr&gt;, BASE_ENCOUNTER_COST &lt;dbl&gt;, TOTAL_CLAIM_COST &lt;dbl&gt;,\n#   PAYER_COVERAGE &lt;dbl&gt;, REASONCODE &lt;dbl&gt;, REASONDESCRIPTION &lt;chr&gt;\n\n\n\nggplot(encounters, aes(ENCOUNTERCLASS)) + geom_bar() + coord_flip()+ labs(title = \"Type of Visit\")\n\n\n\nggplot(data = encounters %&gt;% \n         count(DESCRIPTION) %&gt;% \n         filter(n &gt; 50),  # Filter for counts higher than 10\n       aes(x = DESCRIPTION, y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + labs(title = paste(\"Visit Description\", \"\\n*filtered to show &gt;50 visits\"))\n\n\n\nggplot(data = encounters %&gt;% \n         count(REASONDESCRIPTION) %&gt;% \n         filter(n &gt; 50),  # Filter for counts higher than 10\n       aes(x = REASONDESCRIPTION, y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + labs(title = paste(\"Reason Patient Visited Provider\", \"\\n*filtered to show &gt;50 visits\"))\n\n\n\n\nI am noticing a lot of kidney related diseases in this dataset"
  },
  {
    "objectID": "posts/Post_One/post_1.html#edgelist",
    "href": "posts/Post_One/post_1.html#edgelist",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "EDGELIST",
    "text": "EDGELIST\n\n# Create Edgelist\nencounters_el &lt;- encounter_attributes %&gt;%\n  group_by(PATIENT, PROVIDER) %&gt;%\n  summarize(COUNT = n()) \n\n`summarise()` has grouped output by 'PATIENT'. You can override using the\n`.groups` argument.\n\nhead(encounters_el)\n\n# A tibble: 6 × 3\n# Groups:   PATIENT [2]\n  PATIENT               PROVIDER              COUNT\n  &lt;chr&gt;                 &lt;chr&gt;                 &lt;int&gt;\n1 Akiko835 Larkin917    Emilio417 Barton704      18\n2 Akiko835 Larkin917    Frederic454 Larkin917     7\n3 Akiko835 Larkin917    Jim478 Goyette777         2\n4 Akiko835 Larkin917    Kirby843 McKenzie376     19\n5 Akiko835 Larkin917    Ted955 Reilly981          1\n6 Anneliese170 Berge125 Althea11 Ankunding277     6\n\ndim(encounters_el)\n\n[1] 437   3"
  },
  {
    "objectID": "posts/Post_One/post_1.html#combined-attribute-list",
    "href": "posts/Post_One/post_1.html#combined-attribute-list",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "COMBINED ATTRIBUTE LIST",
    "text": "COMBINED ATTRIBUTE LIST\n\n#combine pro and pat attr\npat_attr$type &lt;- \"PATIENT\"\npro_attr &lt;- providers_filtered %&gt;%\n  select(NAME, GENDER, CITY)\npro_attr$type &lt;- \"PROVIDER\"\nboth_attr &lt;- bind_rows(pat_attr, pro_attr)\nhead(both_attr)\n\n# A tibble: 6 × 8\n  NAME                       GENDER RACE  MARITAL CITY        INCOME   AGE type \n  &lt;chr&gt;                      &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n1 Avril120 Olson653          Female white &lt;NA&gt;    Newton      482269    36 PATI…\n2 Norma469 Langosh790        Female white &lt;NA&gt;    Bridgewater 190464    25 PATI…\n3 Peggie783 Eichmann909      Female white &lt;NA&gt;    Walpole      78997    21 PATI…\n4 Ashlie138 Williamson769    Female white Married Lexington     6472    37 PATI…\n5 Christiane220 Ankunding277 Female white &lt;NA&gt;    Hopkinton   141475    24 PATI…\n6 Dione665 O'Kon634          Female white Married Newton      482269    36 PATI…\n\n\n\n#create combined attribute list\nattribute_list &lt;- do.call(list, both_attr)"
  },
  {
    "objectID": "posts/Post_One/post_1.html#network",
    "href": "posts/Post_One/post_1.html#network",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "NETWORK",
    "text": "NETWORK\n\n# create bipartite network with attributes\nencounters.st.3 &lt;- network(encounters_el,\n                         directed = FALSE,\n                         bipartite = TRUE,\n                         matrix.type = \"edgelist\",\n                         vertex.attr = attribute_list)\nencounters.st.3\n\n Network attributes:\n  vertices = 374 \n  directed = FALSE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = 121 \n  total edges= 437 \n    missing edges= 0 \n    non-missing edges= 437 \n\n Vertex attribute names: \n    AGE CITY GENDER INCOME MARITAL NAME RACE type vertex.names \n\n Edge attribute names: \n    COUNT"
  },
  {
    "objectID": "posts/Post_One/post_1.html#combine-patient-provider-and-encounter-data",
    "href": "posts/Post_One/post_1.html#combine-patient-provider-and-encounter-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "Combine Patient, Provider, and Encounter Data",
    "text": "Combine Patient, Provider, and Encounter Data\nI am taking this step here so that I have a master dataset (encounters_attributes) and so that I can create an edgelist more easily.\n\n# Perform a left join to merge encounters with provider_attributes based on PROVIDER\nencounters_cleaning &lt;- left_join(encounters, providers, by = \"PROVIDER\")\n# Replace the PROVIDER column with the corresponding names from the NAME column\nencounters_cleaning$PROVIDER &lt;- encounters_cleaning$NAME\n# Remove the NAME column if no longer needed\nencounters_cleaning &lt;- encounters_cleaning %&gt;%\n  select(-NAME)\n#Repeat for Provider\nencounters_cleaning &lt;- left_join(encounters_cleaning, patients, by = \"PATIENT\")\nencounters_cleaning$PATIENT &lt;- encounters_cleaning$NAME\nencounters_cleaning &lt;- encounters_cleaning %&gt;%\n  select(-NAME) \n#Clearly identify the Encounter ID\nencounters_cleaning &lt;- encounters_cleaning %&gt;%\n  rename(ENCOUNTER_ID = Id)"
  },
  {
    "objectID": "posts/Post_Two/post_2.html",
    "href": "posts/Post_Two/post_2.html",
    "title": "Network Exploration",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(ggplot2)\nlibrary(patchwork)\nThis post will explore the Synthetic Mass network data in more detail."
  },
  {
    "objectID": "posts/Post_Two/post_2.html#graphs-with-sna",
    "href": "posts/Post_Two/post_2.html#graphs-with-sna",
    "title": "Network Exploration",
    "section": "Graphs with sna",
    "text": "Graphs with sna\n\n# load the sna library to get the gplot() function\nlibrary( sna )\n\n# set the seed to reproduce the plot layout\nset.seed( 507 )\n\n# execute the plot\ngplot(\n  encounters.st.3,             \n  gmode = \"twomode\",                     # indicate it is two modes\n  usearrows = FALSE,                     # turn off the arrowheads\n  vertex.cex=2,                          # size the nodes     \n  label.cex=1.2,                         # size the labels\n  main=\"Bipartite Graph of Encounters using SNA\"                 # add a title\n)\n\n\n\n\n\nincidence_graph &lt;- graph_from_biadjacency_matrix(encounters.st.3)\n\ndetach(“package:sna”)"
  },
  {
    "objectID": "posts/Post_Two/post_2.html#graphs-with-igraph",
    "href": "posts/Post_Two/post_2.html#graphs-with-igraph",
    "title": "Network Exploration",
    "section": "Graphs with igraph",
    "text": "Graphs with igraph\n\nvertex_colors &lt;- ifelse(attribute_list$GENDER == \"F\", \"blue\", \"magenta\")\nV(incidence_graph)$shape &lt;- ifelse(V(incidence_graph)$type, \"square\", \"circle\")\n\n# Define edge colors based on COUNT attribute\nedge_colors &lt;- ifelse(encounters_el$COUNT &lt; 5, \"yellow\", \n                      ifelse(encounters_el$COUNT &gt;= 5 & encounters_el$COUNT &lt;= 19, \"lightblue\", \"red\"))\n\n# Check if the length of edge_colors matches the number of edges\nif (length(edge_colors) == ecount(incidence_graph)) {\n  # Set edge attributes based on counts\n  E(incidence_graph)$color &lt;- edge_colors\n} else {\n  print(\"Length of edge_colors does not match the number of edges in the graph.\")\n}\n\nE(incidence_graph)$color &lt;- edge_colors\n\n# set the seed to reproduce the plot layout\nset.seed( 235 )\n\nplot(incidence_graph,\n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 3, \n     vertex.color = vertex_colors,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Patient Provider Incidence Graph\")\n# Define legend for vertex colors\nlegend(\"bottomright\",\n       legend = c(\"Female\", \"Male\"),  # You can customize these labels\n       fill = c(\"magenta\", \"blue\"),   # Fill colors corresponding to vertex colors\n       title = \"Nodes: Gender\")              # Legend title\n\n# Define legend for vertex shapes\nlegend(\"topright\",\n       legend = c(\"Patient\", \"Provider\"),  # You can customize these labels\n       pch = c(1, 0),                      # Point shapes corresponding to vertex shapes\n       title = \"Nodes: Who\")                     # Legend title\n\n# Define legend for edge colors\nlegend(\"topleft\",\n       legend = c(\"1-4\", \"5-19\", \"20+\"),  # You can customize these labels\n       col = c(\"yellow\", \"lightblue\", \"red\"),  # Line colors corresponding to edge colors\n       lwd = 2,                            # Line width\n       title = \"Edges: # of Visits\")              # Legend title\n\n\n\n\n\n#Calculating centrality\ntypes &lt;- V(incidence_graph)$type\ndeg&lt;- igraph::degree(incidence_graph)\nbet &lt;- igraph::betweenness(incidence_graph)\nclos &lt;- igraph::closeness(incidence_graph)\neig &lt;- eigen_centrality(incidence_graph)$vector\nconst &lt;- constraint(incidence_graph)\ncent_df &lt;- data.frame(types, deg, bet, clos, eig, const)\nhead(cent_df[order(cent_df$deg, decreasing = TRUE),], 10)\n\n                           types deg        bet         clos        eig\nTed955 Reilly981            TRUE  28 27013.6588 0.0012239902 1.00000000\nTimmy68 Nolan344           FALSE   7   885.6299 0.0007002801 0.02480592\nTrula820 Johns824          FALSE   7  6649.9824 0.0010000000 0.20635920\nChun678 Hirthe744          FALSE   6  1404.0134 0.0009578544 0.24432907\nCorey514 Gaylord332        FALSE   6  2402.5000 0.0009578544 0.19651997\nDennis979 Dickens475       FALSE   6  1785.4929 0.0009652510 0.22004854\nEnola75 Tromp100           FALSE   6   758.6271 0.0009560229 0.29716393\nJacqualine965 Aufderhar910 FALSE   6  3265.0333 0.0010080645 0.22137300\nJed345 Muller251           FALSE   6  3019.5333 0.0010080645 0.22693121\nMamie949 Leannon79         FALSE   6   799.1374 0.0009560229 0.28361363\n                                const\nTed955 Reilly981           0.03571429\nTimmy68 Nolan344           0.14285714\nTrula820 Johns824          0.14285714\nChun678 Hirthe744          0.16666667\nCorey514 Gaylord332        0.16666667\nDennis979 Dickens475       0.16666667\nEnola75 Tromp100           0.16666667\nJacqualine965 Aufderhar910 0.16666667\nJed345 Muller251           0.16666667\nMamie949 Leannon79         0.16666667\n\n\n\nV(incidence_graph)$size &lt;- igraph::degree(incidence_graph)\n\n# set the seed to reproduce the plot layout\nset.seed( 235 )\n\nplot(incidence_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.color = vertex_colors,\n     edge.color = \"gray\",\n     edge.label = NA,\n     vertex.label = NA,\n     main = \"Patient Provider Incidence Graph with Degree Information\")\n# Define legend for vertex colors\nlegend(\"bottomright\",\n       legend = c(\"Female\", \"Male\"),  # You can customize these labels\n       fill = c(\"magenta\", \"blue\"),   # Fill colors corresponding to vertex colors\n       title = \"Nodes: Gender\")              # Legend title\n\n# Define legend for vertex shapes\nlegend(\"topright\",\n       legend = c(\"Patient\", \"Provider\"),  # You can customize these labels\n       pch = c(1, 0),                      # Point shapes corresponding to vertex shapes\n       title = \"Nodes: Who\")                     # Legend title\n\n# Define legend for edge colors\nlegend(\"topleft\", \n       legend = \"Vertex Size\", \n       pch = 1, \n       pt.cex = seq(0.5, 3, length.out = 5), \n       title = \"Degree\")\n\n\n\n\nHere we can see there is one Provider that sees the most patients, with degree centrality = 28. The next largest degree centrality are in the 5 to 7 range and the majority of those nodes are patients.\n\nV(incidence_graph)$size &lt;- igraph::closeness(incidence_graph)\n\n# set the seed to reproduce the plot layout\nset.seed( 235 )\n\nplot(incidence_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.color = vertex_colors,\n     edge.color = \"gray\",\n     edge.label = NA,\n     vertex.label = NA,\n     main = \"Patient Provider Incidence Graph with Closeness Information\")\n# Define legend for vertex colors\nlegend(\"bottomright\",\n       legend = c(\"Female\", \"Male\"),  # You can customize these labels\n       fill = c(\"magenta\", \"blue\"),   # Fill colors corresponding to vertex colors\n       title = \"Nodes: Gender\")              # Legend title\n\n# Define legend for vertex shapes\nlegend(\"topright\",\n       legend = c(\"Patient\", \"Provider\"),  # You can customize these labels\n       pch = c(1, 0),                      # Point shapes corresponding to vertex shapes\n       title = \"Nodes: Who\")                     # Legend title\n\n# Define legend for edge colors\nlegend(\"topleft\", \n       legend = \"Vertex Size\", \n       pch = 1, \n       pt.cex = seq(0.5, 3, length.out = 5), \n       title = \"Closeness\")\n\n\n\n\nHere we see two of the dyads on the outer right side of this incidence graph have the largest closeness score. This is because their network is complete (they are both connected to one another)."
  },
  {
    "objectID": "posts/Post_Three/post_3.html",
    "href": "posts/Post_Three/post_3.html",
    "title": "Network Block Modeling - Patients",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\n\nThis post will explore the Synthetic Mass network data in more detail.\n\nRead in Data\n\npat_attr &lt;- read_csv(\"post1_data/pat_attr.csv\", \n    col_types = cols(...1 = col_skip()))\npro_attr &lt;- read_csv(\"post1_data/pro_attr.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaning &lt;- read_csv(\"post1_data//encounters_cleaning.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaned &lt;- read_csv(\"post1_data//encounters_cleaned.csv\", \n    col_types = cols(...1 = col_skip()))\nencounter_attributes &lt;- read_csv(\"post1_data/encounter_attributes.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_el  &lt;- read_csv(\"post1_data/encounters_el.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_st_3 &lt;- read_csv(\"post1_data/encounters.st.3.csv\", \n    col_types = cols(...1 = col_skip()))\nattribute_list &lt;- read.csv(\"post1_data/attribute_list.csv\")\n\n\n\nCreate bipartite network with attributes\n\nencounters.stat &lt;- network(encounters_el,\n                         directed = FALSE,\n                         bipartite = TRUE,\n                         matrix.type = \"edgelist\",\n                         vertex.attr = attribute_list)\n\n\n#create igraph\nencounters.ig &lt;- graph_from_biadjacency_matrix(encounters.stat)\n\n\nencounters.stat2 &lt;- asNetwork(encounters.ig)\n\n\nprojected_graph &lt;- bipartite_projection(encounters.ig)\npatient_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj1))\n\npatient.stat &lt;- asNetwork(projected_graph$proj1)\n\npatient.se &lt;- equiv.clust(patient_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\nnames(patient.se)\n\n[1] \"cluster\"        \"metric\"         \"equiv.fun\"      \"cluster.method\"\n[5] \"glabels\"        \"plabels\"       \n\n\n\nplot(patient.se, main = \"patient\")\nrect.hclust(patient.se$cluster, k = 4)\n\n\n\n\n\npat_blk_model.patient.org &lt;- blockmodel(patient_matrix,\n patient.se, k = 4)\n\n\n pat_blk_model.patient.org$block.model\n\n           Block 1     Block 2     Block 3     Block 4\nBlock 1 1.00000000 0.018535262 0.112244898 0.061224490\nBlock 2 0.01853526 0.020772476 0.003616637 0.005424955\nBlock 3 0.11224490 0.003616637 0.238095238 0.000000000\nBlock 4 0.06122449 0.005424955 0.000000000 0.476190476\n\n\n\nplot.block&lt;-function(x=pat_blk_mod, main=NULL, cex.lab=.00001,show_labels = FALSE){\n plot.sociomatrix(x$blocked.data, labels=list(x$plabels,x$plabels),\n main=main, drawlines = FALSE, cex.lab=cex.lab)\n for (j in 2:length(x$plabels)) if (x$block.membership[j] !=\n x$block.membership[j-1])\n abline(v = j- 0.5, h = j- 0.5, lty = 3, xpd=FALSE)\n }\n \nplot.block(pat_blk_model.patient.org, main = \"patient\")\n\n\n\n\n\n#pat_blks6 &lt;- blockmodeling::optRandomParC(patient_matrix,k=6, rep=20, approaches=\"ss\", blocks=\"com\")\n\n\n# Save the blks2 object to a file\n#saveRDS(pat_blks6, \"pat_blks6_results.rds\")\n\n# Later, when you want to use it again, you can read it back into R\npat_blks6 &lt;- readRDS(\"pat_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\npat_blk_mod &lt;- blockmodel(patient_matrix, pat_blks6$best$best1$clu,\n                      plabels = rownames(patient_matrix))\n# print blockmodel object\npat_blk_mod$block.model\n\n           Block 1     Block 2     Block 3     Block 4 Block 5    Block 6\nBlock 1 1.00000000 1.000000000 0.083333333 0.011538462 0.03125 0.00000000\nBlock 2 1.00000000 1.000000000 0.000000000 0.007692308 0.00000 0.75000000\nBlock 3 0.08333333 0.000000000 0.131578947 0.001538462 0.00000 0.00000000\nBlock 4 0.01153846 0.007692308 0.001538462 0.019711538 0.00000 0.02307692\nBlock 5 0.03125000 0.000000000 0.000000000 0.000000000 1.00000 0.00000000\nBlock 6 0.00000000 0.750000000 0.000000000 0.023076923 0.00000 0.66666667\n\n\n#assign attributes\n\nglimpse(pat_blk_mod)\n\nList of 11\n $ block.membership: int [1:121] 1 1 1 1 1 1 1 1 1 1 ...\n $ order.vector    : int [1:121] 1 5 16 22 24 26 28 29 35 36 ...\n $ block.content   : chr \"density\"\n $ blocked.data    : num [1:121, 1:121] 0 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:121] \"Akiko835 Larkin917\" \"Arleen939 Kling921\" \"Casandra937 Grimes165\" \"Chun678 Hirthe744\" ...\n  .. ..$ : chr [1:121] \"Akiko835 Larkin917\" \"Arleen939 Kling921\" \"Casandra937 Grimes165\" \"Chun678 Hirthe744\" ...\n $ block.model     : num [1:6, 1:6] 1 1 0.0833 0.0115 0.0312 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n  .. ..$ : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n $ plabels         : chr [1:121] \"Akiko835 Larkin917\" \"Arleen939 Kling921\" \"Casandra937 Grimes165\" \"Chun678 Hirthe744\" ...\n $ glabels         : int [1:121] 1 2 3 4 5 6 7 8 9 10 ...\n $ rlabels         : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n $ cluster.method  : chr \"Prespecified\"\n $ equiv.fun       : chr \"None\"\n $ equiv.metric    : chr \"None\"\n - attr(*, \"class\")= chr \"blockmodel\"\n\n\n\npat_attr$block &lt;- pat_blk_mod$block.membership\nhead(pat_attr)\n\n# A tibble: 6 × 9\n  NAME                       GENDER RACE  MARITAL CITY  INCOME   AGE type  block\n  &lt;chr&gt;                      &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt;\n1 Avril120 Olson653          Female white &lt;NA&gt;    Newt… 482269    36 PATI…     1\n2 Norma469 Langosh790        Female white &lt;NA&gt;    Brid… 190464    25 PATI…     1\n3 Peggie783 Eichmann909      Female white &lt;NA&gt;    Walp…  78997    21 PATI…     1\n4 Ashlie138 Williamson769    Female white Married Lexi…   6472    37 PATI…     1\n5 Christiane220 Ankunding277 Female white &lt;NA&gt;    Hopk… 141475    24 PATI…     1\n6 Dione665 O'Kon634          Female white Married Newt… 482269    36 PATI…     1\n\n#write.csv(pat_attr, \"pat_attr.csv\")\n\n\nplot.block(pat_blk_mod, main = \"patient\",\n           cex.lab = .000001)\n\n\n\n\n\n#assign block membership to vertex attribute\npatient.stat%v%\"role\"&lt;-pat_blk_mod$block.membership[match(patient.stat%v%\"vertex.names\",pat_blk_mod$plabels)]\n#plot network using \"role\" to color nodes\nGGally::ggnet2(patient.stat,\n               node.color=\"role\", \n               node.size=sna::degree(patient.stat, gmode=\"graph\"),\n               node.alpha = .5)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\n\n\nlibrary(ade4)\n\nWarning: package 'ade4' was built under R version 4.3.3\n\n\n\nencounters.adj.ig &lt;- igraph::as_biadjacency_matrix(encounters.ig)\n\npatients_jaccard &lt;- dist.binary(encounters.adj.ig,\n            method = 1, # method=1 Jaccard index\n            upper = TRUE,\n            diag = FALSE)\n\npatients_jaccard &lt;- as.matrix(patients_jaccard)\ndiag(patients_jaccard) &lt;- 0\n\n\n#binarize\npatients_jaccard_bi &lt;- ifelse(patients_jaccard &gt; 0.99, 1, 0)\n\n\n#create igraph object\npatients_jaccard.ig &lt;- graph_from_adjacency_matrix(patients_jaccard_bi, mode = \"undirected\")\nsummary(patients_jaccard.ig)\n\nIGRAPH cfa603f UN-- 121 6723 -- \n+ attr: name (v/c)\n\n\n\nplot(patients_jaccard.ig,  edge.width = 0.0002, edge.color = \"lightgray\",  vertex.size = 2, vertex.label = NA)\n\n\n\n\n\n# Load the igraph package\nlibrary(igraph)\n\n# Create an igraph object from the blockmodel\ng &lt;- graph_from_adjacency_matrix(patient_matrix, mode = \"undirected\", weighted = FALSE)\n\n# Plot the graph without labels\nplot(g,      \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 2, \n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Patient Network\")"
  },
  {
    "objectID": "posts/Post_Four/post_4.html",
    "href": "posts/Post_Four/post_4.html",
    "title": "Network Block Modeling - Providers",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\n\nThis post will explore the Synthetic Mass network data in more detail.\n\nRead in Data\n\npat_attr &lt;- read_csv(\"post1_data/pat_attr.csv\", \n    col_types = cols(...1 = col_skip()))\npro_attr &lt;- read_csv(\"post1_data/pro_attr.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaning &lt;- read_csv(\"post1_data//encounters_cleaning.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaned &lt;- read_csv(\"post1_data//encounters_cleaned.csv\", \n    col_types = cols(...1 = col_skip()))\nencounter_attributes &lt;- read_csv(\"post1_data/encounter_attributes.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_el  &lt;- read_csv(\"post1_data/encounters_el.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_st_3 &lt;- read_csv(\"post1_data/encounters.st.3.csv\", \n    col_types = cols(...1 = col_skip()))\nattribute_list &lt;- read.csv(\"post1_data/attribute_list.csv\")\n\n\n\nCreate bipartite network with attributes\n\nencounters.stat &lt;- network(encounters_el,\n                         directed = FALSE,\n                         bipartite = TRUE,\n                         matrix.type = \"edgelist\",\n                         vertex.attr = attribute_list)\n\n\n#create igraph\nencounters.ig &lt;- graph_from_biadjacency_matrix(encounters.stat)\n\n\nencounters.stat2 &lt;- asNetwork(encounters.ig)\n\n\nprojected_graph &lt;- bipartite_projection(encounters.ig)\nprovider_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj2))\n\nprovider.stat &lt;- asNetwork(projected_graph$proj2)\n\nprovider.se &lt;- equiv.clust(provider_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\nnames(provider.se)\n\n[1] \"cluster\"        \"metric\"         \"equiv.fun\"      \"cluster.method\"\n[5] \"glabels\"        \"plabels\"       \n\n\n\nplot(provider.se, main = \"provider\")\nrect.hclust(provider.se$cluster, k = 12)\n\n\n\n\n\nblk_model.provider.org &lt;- blockmodel(provider_matrix,\n provider.se, k = 6)\n\n\n blk_model.provider.org$block.model\n\n            Block 1   Block 2     Block 3    Block 4    Block 5    Block 6\nBlock 1 0.013527738 0.2995595 0.001762115 0.00715859 0.07929515 0.05286344\nBlock 2 0.299559471       NaN 0.400000000 1.00000000 1.00000000 1.00000000\nBlock 3 0.001762115 0.4000000 0.476190476 0.00000000 0.00000000 0.00000000\nBlock 4 0.007158590 1.0000000 0.000000000 0.75000000 0.00000000 0.37500000\nBlock 5 0.079295154 1.0000000 0.000000000 0.00000000        NaN 0.00000000\nBlock 6 0.052863436 1.0000000 0.000000000 0.37500000 0.00000000        NaN\n\n\n\nplot.block&lt;-function(x=blk_mod, main=NULL, cex.lab=.00001,show_labels = FALSE){\n plot.sociomatrix(x$blocked.data, labels=list(x$plabels,x$plabels),\n main=main, drawlines = FALSE, cex.lab=cex.lab)\n for (j in 2:length(x$plabels)) if (x$block.membership[j] !=\n x$block.membership[j-1])\n abline(v = j- 0.5, h = j- 0.5, lty = 3, xpd=FALSE)\n }\n \nplot.block(blk_model.provider.org, main = \"provider\")\n\n\n\n\n\n#prov_blks6 &lt;- blockmodeling::optRandomParC(provider_matrix, k=6, rep=10, approaches=\"ss\", blocks=\"com\")\n\n\n# Save the prov_blks6 object to a file\n#saveRDS(prov_blks6, \"prov_blks6_results.rds\")\n\n# Later, when you want to use it again, you can read it back into R\nprov_blks6 &lt;- readRDS(\"prov_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\nprov_blk_mod &lt;- blockmodel(provider_matrix, prov_blks6$best$best1$clu,\n                      plabels = rownames(provider_matrix))\n# print blockmodel object\nprov_blk_mod$block.model\n\n            Block 1     Block 2 Block 3     Block 4     Block 5     Block 6\nBlock 1 1.000000000 0.000000000   1.000 0.008333333 0.400000000 0.000000000\nBlock 2 0.000000000 0.800000000   0.600 0.001388889 0.000000000 0.010828025\nBlock 3 1.000000000 0.600000000     NaN 1.000000000 0.125000000 0.000000000\nBlock 4 0.008333333 0.001388889   1.000 0.053208138 0.000000000 0.004777070\nBlock 5 0.400000000 0.000000000   0.125 0.000000000 0.142857143 0.002388535\nBlock 6 0.000000000 0.010828025   0.000 0.004777070 0.002388535 0.015515270\n\n\n\nglimpse(prov_blk_mod)\n\nList of 11\n $ block.membership: int [1:253] 1 1 1 1 1 2 2 2 2 2 ...\n $ order.vector    : int [1:253] 29 39 76 112 208 20 23 24 25 26 ...\n $ block.content   : chr \"density\"\n $ blocked.data    : num [1:253, 1:253] 0 1 1 1 1 0 0 0 0 0 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:253] \"Yesenia104 Wilderman619\" \"Floy720 Greenfelder433\" \"Vito638 Barton704\" \"Omer483 Koepp521\" ...\n  .. ..$ : chr [1:253] \"Yesenia104 Wilderman619\" \"Floy720 Greenfelder433\" \"Vito638 Barton704\" \"Omer483 Koepp521\" ...\n $ block.model     : num [1:6, 1:6] 1 0 1 0.00833 0.4 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n  .. ..$ : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n $ plabels         : chr [1:253] \"Yesenia104 Wilderman619\" \"Floy720 Greenfelder433\" \"Vito638 Barton704\" \"Omer483 Koepp521\" ...\n $ glabels         : int [1:253] 1 2 3 4 5 6 7 8 9 10 ...\n $ rlabels         : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n $ cluster.method  : chr \"Prespecified\"\n $ equiv.fun       : chr \"None\"\n $ equiv.metric    : chr \"None\"\n - attr(*, \"class\")= chr \"blockmodel\"\n\n\n\npro_attr$block &lt;- prov_blk_mod$block.membership \n\nhead(pro_attr)\n\n# A tibble: 6 × 5\n  NAME                      GENDER CITY         type     block\n  &lt;chr&gt;                     &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;    &lt;int&gt;\n1 Ted955 Reilly981          M      Fitchburg    PROVIDER     1\n2 Barbara209 Maldonado119   F      LEOMINSTER   PROVIDER     1\n3 Gisele901 Lehner980       F      West Roxbury PROVIDER     1\n4 Vella930 Ankunding277     F      FALL RIVER   PROVIDER     1\n5 Precious140 Runolfsson901 F      NORWELL      PROVIDER     1\n6 Fernande593 Mosciski958   F      E FALMOUTH   PROVIDER     2\n\nwrite.csv(pro_attr, \"pro_attr.csv\")\n\n\nplot.block(prov_blk_mod, main = \"Provider 6 Block Model\",\n           cex.lab = .000001)\n\n\n\n\n\n#assign block membership to vertex attribute\nprovider.stat%v%\"role\"&lt;-prov_blk_mod$block.membership[match(provider.stat%v%\"vertex.names\",prov_blk_mod$plabels)]\n#plot network using \"role\" to color nodes\nGGally::ggnet2(provider.stat,\n               node.color=\"role\", \n               node.size=sna::degree(provider.stat, gmode=\"graph\"),\n               node.alpha = .5)  + ggtitle(\"Provider 6 Block Model Network\")\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\n\n\n#blks2 &lt;- blockmodeling::optRandomParC(provider_matrix, k=12, rep=10, approaches=\"ss\", blocks=\"com\")\n\n\n# Save the blks2 object to a file\n#saveRDS(blks2, \"blks2_results.rds\")\n\n# Later, when you want to use it again, you can read it back into R\nblks2 &lt;- readRDS(\"blks2_results.rds\")\n\n\n# blockmodel with optimized partition\nblks2_mod &lt;- blockmodel(provider_matrix, blks2$best$best1$clu,\n                      plabels = rownames(provider_matrix))\n# print blockmodel object\nblks2_mod$block.model\n\n           Block 1 Block 2     Block 3    Block 4     Block 5     Block 6\nBlock 1        NaN    0.00 1.000000000 1.00000000 0.000000000 0.600000000\nBlock 2  0.0000000    0.20 0.000000000 0.00000000 0.000000000 0.240000000\nBlock 3  1.0000000    0.00 0.272727273 0.04545455 0.007667032 0.009090909\nBlock 4  1.0000000    0.00 0.045454545 0.86666667 0.014056225 0.000000000\nBlock 5  0.0000000    0.00 0.007667032 0.01405622 0.022627094 0.002409639\nBlock 6  0.6000000    0.24 0.009090909 0.00000000 0.002409639 0.800000000\nBlock 7  1.0000000    0.00 0.000000000 0.00000000 0.007831325 0.000000000\nBlock 8  0.0000000    0.00 0.000000000 0.02000000 0.000000000 0.000000000\nBlock 9  1.0000000    0.00 0.000000000 0.00000000 0.007530120 0.000000000\nBlock 10 0.0000000    0.00 0.000000000 0.00000000 0.002409639 0.060000000\nBlock 11 0.0000000    0.00 0.000000000 0.00000000 0.002259036 0.000000000\nBlock 12 0.1666667    0.00 0.000000000 0.00000000 0.016064257 0.000000000\n             Block 7    Block 8    Block 9    Block 10    Block 11   Block 12\nBlock 1  1.000000000 0.00000000 1.00000000 0.000000000 0.000000000 0.16666667\nBlock 2  0.000000000 0.00000000 0.00000000 0.000000000 0.000000000 0.00000000\nBlock 3  0.000000000 0.00000000 0.00000000 0.000000000 0.000000000 0.00000000\nBlock 4  0.000000000 0.02000000 0.00000000 0.000000000 0.000000000 0.00000000\nBlock 5  0.007831325 0.00000000 0.00753012 0.002409639 0.002259036 0.01606426\nBlock 6  0.000000000 0.00000000 0.00000000 0.060000000 0.000000000 0.00000000\nBlock 7  0.268421053 0.00000000 0.00250000 0.000000000 0.000000000 0.00000000\nBlock 8  0.000000000 0.04979592 0.00000000 0.000000000 0.012500000 0.00000000\nBlock 9  0.002500000 0.00000000 0.07564103 0.000000000 0.000000000 0.03750000\nBlock 10 0.000000000 0.00000000 0.00000000 0.700000000 0.000000000 0.00000000\nBlock 11 0.000000000 0.01250000 0.00000000 0.000000000 0.200000000 0.00000000\nBlock 12 0.000000000 0.00000000 0.03750000 0.000000000 0.000000000 0.86666667\n\n\n\nplot.block(blks2_mod, main = \"Provider 12 Block Model\",\n           cex.lab = .000001)\n\n\n\n\n\n#assign block membership to vertex attribute\nprovider.stat%v%\"role2\"&lt;-blks2_mod$block.membership[match(provider.stat%v%\"vertex.names\",blks2_mod$plabels)]\n#plot network using \"role\" to color nodes\nGGally::ggnet2(provider.stat,\n               node.color=\"role2\", \n               node.size=sna::degree(provider.stat, gmode=\"graph\"),\n               node.alpha = .5) + ggtitle(\"Provider 12 Block Model Network\")\n\n\n\n\nWith 12 distinct blocks, I start to loose definition of the exterior and interior. Notice the green color mixed in close to the center and tied with gray nodes in the outer ring. This is too many blocks, 6 defines more visually appealing divisions. Additional analysis will need to be done to understand if these blocks can actually be defined by anything other than ties. Onto deeper exploration of blocks…\n#Next Steps Jaccard similarity\n\nlibrary(ade4)\n\nWarning: package 'ade4' was built under R version 4.3.3\n\n\n\nencounters.adj.ig &lt;- igraph::as_biadjacency_matrix(encounters.ig)\n\nproviders_jaccard &lt;- dist.binary(t(encounters.adj.ig),\n            method = 1, # method=1 Jaccard index\n            upper = TRUE,\n            diag = FALSE)\n\n\nproviders_jaccard &lt;- as.matrix(providers_jaccard)\ndiag(providers_jaccard) &lt;- 0\n\n\n#binarize\nproviders_jaccard_bi &lt;- ifelse(providers_jaccard &gt; 0.99, 1, 0)\n\n\n#create igraph object\nproviders_jaccard.ig &lt;- graph_from_adjacency_matrix(providers_jaccard_bi, mode = \"undirected\")\nproviders_jaccard.ig\n\nIGRAPH 5606312 UN-- 253 31324 -- \n+ attr: name (v/c)\n+ edges from 5606312 (vertex names):\n [1] Emilio417 Barton704--Althea11 Ankunding277\n [2] Emilio417 Barton704--Jerrell6 Rippin620   \n [3] Emilio417 Barton704--Linette249 Runte676  \n [4] Emilio417 Barton704--Irene779 Garza151    \n [5] Emilio417 Barton704--Randy380 Bergstrom287\n [6] Emilio417 Barton704--Booker670 Casper496  \n [7] Emilio417 Barton704--Brock407 VonRueden376\n [8] Emilio417 Barton704--Chang901 Kutch271    \n+ ... omitted several edges\n\n\n\nplot(providers_jaccard.ig,  edge.width = 0.0002, edge.color = \"lightgray\",  vertex.size = 2, vertex.label = NA)\n\n\n\n\n\n# Load the igraph package\nlibrary(igraph)\n\n# Create an igraph object from the blockmodel\ng &lt;- graph_from_adjacency_matrix(provider_matrix, mode = \"undirected\", weighted = FALSE)\n\n# Plot the graph without labels\nplot(g,      layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 2, \n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Provider Network\")"
  },
  {
    "objectID": "posts/Post_Five/post_5.html",
    "href": "posts/Post_Five/post_5.html",
    "title": "Network Block Modeling - Geographical Comparisson",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\nThis post will explore the Synthetic Mass network data in more detail."
  },
  {
    "objectID": "posts/Post_Three/post_3adjustment.html",
    "href": "posts/Post_Three/post_3adjustment.html",
    "title": "Network Block Modeling - Patients",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\n\nThis post will explore the Synthetic Mass network data in more detail.\n\nRead in Data\n\npat_attr &lt;- read_csv(\"post_one_data/pat_attr.csv\", \n    col_types = cols(...1 = col_skip()))\npro_attr &lt;- read_csv(\"post_one_data/pro_attr.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaning &lt;- read_csv(\"post_one_data//encounters_cleaning.csv\", \n    col_types = cols(...1 = col_skip()))\nencounter_attributes &lt;- read_csv(\"post_one_data/encounter_attributes.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_el  &lt;- read_csv(\"post_one_data/encounters_el.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_st_3 &lt;- read_csv(\"post_one_data/encounters.st.3.csv\", \n    col_types = cols(...1 = col_skip()))\nattribute_list &lt;- read.csv(\"post_one_data/attribute_list.csv\")\n\n\n\nCreate bipartite network with attributes\n\nencounters.stat &lt;- network(encounters_el,\n                         directed = FALSE,\n                         bipartite = TRUE,\n                         matrix.type = \"edgelist\",\n                         vertex.attr = attribute_list)\n\n\n#create igraph\nencounters.ig &lt;- graph_from_biadjacency_matrix(encounters.stat)\n\n\nencounters.stat2 &lt;- asNetwork(encounters.ig)\n\n\nprojected_graph &lt;- bipartite_projection(encounters.ig)\npatient_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj1))\n\npatient.stat &lt;- asNetwork(projected_graph$proj1)\n\npatient.se &lt;- equiv.clust(patient_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\nnames(patient.se)\n\n[1] \"cluster\"        \"metric\"         \"equiv.fun\"      \"cluster.method\"\n[5] \"glabels\"        \"plabels\"       \n\n\n\nplot(patient.se, main = \"patient\")\nrect.hclust(patient.se$cluster, k = 4)\n\n\n\n\n\npat_blk_model.patient.org &lt;- blockmodel(patient_matrix,\n patient.se, k = 4)\n\n\n pat_blk_model.patient.org$block.model\n\n           Block 1     Block 2     Block 3     Block 4\nBlock 1 1.00000000 0.018535262 0.112244898 0.061224490\nBlock 2 0.01853526 0.020772476 0.003616637 0.005424955\nBlock 3 0.11224490 0.003616637 0.238095238 0.000000000\nBlock 4 0.06122449 0.005424955 0.000000000 0.476190476\n\n\n\nplot.block&lt;-function(x=pat_blk_mod, main=NULL, cex.lab=.00001,show_labels = FALSE){\n plot.sociomatrix(x$blocked.data, labels=list(x$plabels,x$plabels),\n main=main, drawlines = FALSE, cex.lab=cex.lab)\n for (j in 2:length(x$plabels)) if (x$block.membership[j] !=\n x$block.membership[j-1])\n abline(v = j- 0.5, h = j- 0.5, lty = 3, xpd=FALSE)\n }\n \nplot.block(pat_blk_model.patient.org, main = \"patient\")\n\n\n\n\n\n#pat_blks6 &lt;- blockmodeling::optRandomParC(patient_matrix,k=6, rep=20, approaches=\"ss\", blocks=\"com\")\n\n\n# Save the blks2 object to a file\n#saveRDS(pat_blks6, \"pat_blks6_results.rds\")\n\n# Later, when you want to use it again, you can read it back into R\npat_blks6 &lt;- readRDS(\"pat_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\npat_blk_mod &lt;- blockmodel(patient_matrix, pat_blks6$best$best1$clu,\n                      plabels = rownames(patient_matrix))\n# print blockmodel object\npat_blk_mod$block.model\n\n           Block 1     Block 2     Block 3     Block 4 Block 5    Block 6\nBlock 1 1.00000000 1.000000000 0.083333333 0.011538462 0.03125 0.00000000\nBlock 2 1.00000000 1.000000000 0.000000000 0.007692308 0.00000 0.75000000\nBlock 3 0.08333333 0.000000000 0.131578947 0.001538462 0.00000 0.00000000\nBlock 4 0.01153846 0.007692308 0.001538462 0.019711538 0.00000 0.02307692\nBlock 5 0.03125000 0.000000000 0.000000000 0.000000000 1.00000 0.00000000\nBlock 6 0.00000000 0.750000000 0.000000000 0.023076923 0.00000 0.66666667\n\n\n#assign attributes\n\nglimpse(pat_blk_mod)\n\nList of 11\n $ block.membership: int [1:121] 1 1 1 1 1 1 1 1 1 1 ...\n $ order.vector    : int [1:121] 1 5 16 22 24 26 28 29 35 36 ...\n $ block.content   : chr \"density\"\n $ blocked.data    : num [1:121, 1:121] 0 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:121] \"Akiko835 Larkin917\" \"Arleen939 Kling921\" \"Casandra937 Grimes165\" \"Chun678 Hirthe744\" ...\n  .. ..$ : chr [1:121] \"Akiko835 Larkin917\" \"Arleen939 Kling921\" \"Casandra937 Grimes165\" \"Chun678 Hirthe744\" ...\n $ block.model     : num [1:6, 1:6] 1 1 0.0833 0.0115 0.0312 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n  .. ..$ : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n $ plabels         : chr [1:121] \"Akiko835 Larkin917\" \"Arleen939 Kling921\" \"Casandra937 Grimes165\" \"Chun678 Hirthe744\" ...\n $ glabels         : int [1:121] 1 2 3 4 5 6 7 8 9 10 ...\n $ rlabels         : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n $ cluster.method  : chr \"Prespecified\"\n $ equiv.fun       : chr \"None\"\n $ equiv.metric    : chr \"None\"\n - attr(*, \"class\")= chr \"blockmodel\"\n\n\n\npat_attr$block &lt;- pat_blk_mod$block.membership\nhead(pat_attr)\n\n# A tibble: 6 × 8\n  NAME                       GENDER RACE  MARITAL INCOME   AGE type    block\n  &lt;chr&gt;                      &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;int&gt;\n1 Avril120 Olson653          F      white &lt;NA&gt;    482269    36 PATIENT     1\n2 Norma469 Langosh790        F      white &lt;NA&gt;    190464    25 PATIENT     1\n3 Peggie783 Eichmann909      F      white &lt;NA&gt;     78997    21 PATIENT     1\n4 Ashlie138 Williamson769    F      white M         6472    37 PATIENT     1\n5 Christiane220 Ankunding277 F      white &lt;NA&gt;    141475    24 PATIENT     1\n6 Dione665 O'Kon634          F      white M       482269    36 PATIENT     1\n\n#write.csv(pat_attr, \"pat_attr.csv\")\n\n\nplot.block(pat_blk_mod, main = \"patient\",\n           cex.lab = .000001)\n\n\n\n\n\n#assign block membership to vertex attribute\npatient.stat%v%\"role\"&lt;-pat_blk_mod$block.membership[match(patient.stat%v%\"vertex.names\",pat_blk_mod$plabels)]\n#plot network using \"role\" to color nodes\nGGally::ggnet2(patient.stat,\n               node.color=\"role\", \n               node.size=sna::degree(patient.stat, gmode=\"graph\"),\n               node.alpha = .5)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\n\n\nlibrary(ade4)\n\nWarning: package 'ade4' was built under R version 4.3.3\n\n\n\nencounters.adj.ig &lt;- igraph::as_biadjacency_matrix(encounters.ig)\n\npatients_jaccard &lt;- dist.binary(encounters.adj.ig,\n            method = 1, # method=1 Jaccard index\n            upper = TRUE,\n            diag = FALSE)\n\npatients_jaccard &lt;- as.matrix(patients_jaccard)\ndiag(patients_jaccard) &lt;- 0\n\n\n#binarize\npatients_jaccard_bi &lt;- ifelse(patients_jaccard &gt; 0.99, 1, 0)\n\n\n#create igraph object\npatients_jaccard.ig &lt;- graph_from_adjacency_matrix(patients_jaccard_bi, mode = \"undirected\")\npatients_jaccard.ig\n\nIGRAPH 3caafa3 UN-- 121 6723 -- \n+ attr: name (v/c)\n+ edges from 3caafa3 (vertex names):\n [1] Akiko835 Larkin917--Anneliese170 Berge125  \n [2] Akiko835 Larkin917--Anthony633 Renner328   \n [3] Akiko835 Larkin917--Ashlie138 Williamson769\n [4] Akiko835 Larkin917--Avril120 Olson653      \n [5] Akiko835 Larkin917--Basil991 Hilll811      \n [6] Akiko835 Larkin917--Benjamin360 Hintz995   \n [7] Akiko835 Larkin917--Brendan864 MacGyver246 \n [8] Akiko835 Larkin917--Bula88 Prohaska837     \n+ ... omitted several edges\n\n\n\nplot(patients_jaccard.ig,  edge.width = 0.0002, edge.color = \"lightgray\",  vertex.size = 2, vertex.label = NA)\n\n\n\n\n\n# Load the igraph package\nlibrary(igraph)\n\n# Create an igraph object from the blockmodel\ng &lt;- graph_from_adjacency_matrix(patient_matrix, mode = \"undirected\", weighted = FALSE)\n\n# Plot the graph without labels\nplot(g,      \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 2, \n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Patient Network\")"
  },
  {
    "objectID": "posts/Post_One/post_1.html#check-dimensions-of-providers",
    "href": "posts/Post_One/post_1.html#check-dimensions-of-providers",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "check dimensions of Providers…",
    "text": "check dimensions of Providers…\nIn later analysis I noticed that while there are 279 providers in the provider.csv, there are only 253 providers listed in the encounters df. I need to find out who is in the encounters list and only keep them for analysis\n\ncheck_prov &lt;- encounters_cleaning %&gt;%\n  group_by(PROVIDER, ORGANIZATION.x) %&gt;%\n  summarize(COUNT = n())\n\n`summarise()` has grouped output by 'PROVIDER'. You can override using the\n`.groups` argument.\n\ncheck_prov2 &lt;- providers %&gt;% \n  group_by(NAME, PROVIDER)\n\n\ndim(check_prov)\n\n[1] 253   3\n\ndim(check_prov2)\n\n[1] 279  13\n\n\n\n# Perform semi-join to keep providers present in both datasets\nproviders_only_in_providers_df &lt;- check_prov2 %&gt;%\n  anti_join(check_prov, by = c(\"NAME\" = \"PROVIDER\"))\n\n# Print the dimensions of the filtered dataset\nprint(dim(providers_only_in_providers_df))\n\n[1] 26 13\n\nprint(providers_only_in_providers_df)\n\n# A tibble: 26 × 13\n# Groups:   NAME, PROVIDER [26]\n   PROVIDER ORGANIZATION NAME  GENDER SPECIALITY ADDRESS CITY  STATE ZIP     LAT\n   &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 c96d72f… 05bcaa3e-aa… Bok9… F      GENERAL P… 1 LOVE… SOUT… MA    0266…  41.7\n 2 3527717… 8e3ca57f-6f… Conc… F      GENERAL P… 89 MOR… ANDO… MA    0181…  42.7\n 3 8307628… 02c936e2-3a… Royc… F      GENERAL P… 120 FI… BOST… MA    0212…  42.3\n 4 31b33e0… 7a3b8310-02… Leif… M      GENERAL P… 6 HATF… NORT… MA    0106…  42.3\n 5 97c7e69… 68ea50ba-27… Alan… M      GENERAL P… 25 ARM… WEST… MA    0246…  42.4\n 6 3d3b1f7… 65f0254a-73… Carl… F      GENERAL P… 720 BO… MARL… MA    0175…  42.4\n 7 e0755f5… 27bf2e46-74… Kath… F      GENERAL P… 80 BOS… NORT… MA    0186…  42.6\n 8 03c9650… 200746fc-5d… Latr… F      GENERAL P… 800 CU… WOBU… MA    0180…  42.5\n 9 b622a6a… 9b1f8cd0-22… Clau… M      GENERAL P… 800 ES… LAWR… MA    0184…  42.7\n10 bedab72… a609d72c-6c… Mega… F      GENERAL P… 1000 N… PITT… MA    0120…  42.5\n# ℹ 16 more rows\n# ℹ 3 more variables: LON &lt;dbl&gt;, ENCOUNTERS &lt;dbl&gt;, PROCEDURES &lt;dbl&gt;\n\n\n\n# Perform anti-join to remove providers only present in check_prov2 from the original dataset\nproviders_filtered &lt;- providers %&gt;%\n  anti_join(providers_only_in_providers_df, by = c(\"NAME\" = \"NAME\"))\n\n# Print the dimensions of the resulting dataset\nprint(dim(providers_filtered))\n\n[1] 253  13\n\n\n\ncheck_pat &lt;- encounters_cleaning %&gt;%\n  group_by(PATIENT, GENDER.y) %&gt;%\n  summarize(COUNT = n())\n\n`summarise()` has grouped output by 'PATIENT'. You can override using the\n`.groups` argument.\n\ncheck_pat2 &lt;- patients %&gt;%\n  group_by(NAME,PATIENT)\n\n\ndim(check_pat)\n\n[1] 121   3\n\ndim(check_pat2)\n\n[1] 121  27\n\n\n\n# Perform a left join to merge encounters with provider_attributes based on PROVIDER\nencounters_cleaned &lt;- left_join(encounters, providers_filtered, by = \"PROVIDER\")\n# Replace the PROVIDER column with the corresponding names from the NAME column\nencounters_cleaned$PROVIDER &lt;- encounters_cleaned$NAME\n# Remove the NAME column if no longer needed\nencounters_cleaned &lt;- encounters_cleaned %&gt;%\n  select(-NAME)\n#Repeat for Provider\nencounters_cleaned &lt;- left_join(encounters_cleaned, patients, by = \"PATIENT\")\nencounters_cleaned$PATIENT &lt;- encounters_cleaned$NAME\nencounters_cleaned &lt;- encounters_cleaned %&gt;%\n  select(-NAME) \n#Clearly identify the Encounter ID\nencounters_cleaned &lt;- encounters_cleaned %&gt;%\n  rename(ENCOUNTER_ID = Id)\n\n\nencounter_attributes &lt;- encounters_cleaned %&gt;%\n  select(ENCOUNTER_ID, PATIENT, PROVIDER, GENDER.x, GENDER.y, RACE, MARITAL, ETHNICITY, INCOME, CITY.x, CITY.y)\n# View the updated dataframe\nhead(encounter_attributes)\n\n# A tibble: 6 × 11\n  ENCOUNTER_ID PATIENT PROVIDER GENDER.x GENDER.y RACE  MARITAL ETHNICITY INCOME\n  &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt;\n1 4afc6abc-ab… Norma4… Jeromy1… M        Female   white &lt;NA&gt;    nonhispa… 190464\n2 c502ee2d-1d… Peggie… Abdul21… M        Female   white &lt;NA&gt;    nonhispa…  78997\n3 6f3ad103-a2… Avril1… Marshal… M        Female   white &lt;NA&gt;    nonhispa… 482269\n4 0d9b475b-5e… Peggie… Benedic… M        Female   white &lt;NA&gt;    nonhispa…  78997\n5 ec0d6c63-84… Norma4… Jeromy1… M        Female   white &lt;NA&gt;    nonhispa… 190464\n6 ec41ff94-ed… Norma4… Jeromy1… M        Female   white &lt;NA&gt;    nonhispa… 190464\n# ℹ 2 more variables: CITY.x &lt;chr&gt;, CITY.y &lt;chr&gt;"
  },
  {
    "objectID": "posts/Post_Five/post_5.html#patient",
    "href": "posts/Post_Five/post_5.html#patient",
    "title": "Network Block Modeling - Geographical Comparisson",
    "section": "PATIENT",
    "text": "PATIENT\n\npatient_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj1))\n\npatient.stat &lt;- asNetwork(projected_graph$proj1)\n\npatient.se &lt;- equiv.clust(patient_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\n\npat_blk_model.patient.org &lt;- blockmodel(patient_matrix,\n patient.se, k = 4)\n\n\nplot.block&lt;-function(x=pat_blk_mod, main=NULL, cex.lab=.00001,show_labels = FALSE){\n plot.sociomatrix(x$blocked.data, labels=list(x$plabels,x$plabels),\n main=main, drawlines = FALSE, cex.lab=cex.lab)\n for (j in 2:length(x$plabels)) if (x$block.membership[j] !=\n x$block.membership[j-1])\n abline(v = j- 0.5, h = j- 0.5, lty = 3, xpd=FALSE)\n }\n \nplot.block(pat_blk_model.patient.org, main = \"patient\")\n\n\n\n\n\npat_blks6 &lt;- readRDS(\"pat_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\npat_blk_mod &lt;- blockmodel(patient_matrix, pat_blks6$best$best1$clu,\n                      plabels = rownames(patient_matrix))\n\n\n#assign block membership to vertex attribute\npatient.stat%v%\"role\"&lt;-pat_blk_mod$block.membership[match(patient.stat%v%\"vertex.names\",pat_blk_mod$plabels)]\n#plot network using \"role\" to color nodes\nGGally::ggnet2(patient.stat,\n               node.color=\"role\", \n               node.size=sna::degree(patient.stat, gmode=\"graph\"),\n               node.alpha = .5)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2"
  },
  {
    "objectID": "posts/Post_Five/post_5.html#provider",
    "href": "posts/Post_Five/post_5.html#provider",
    "title": "Network Block Modeling - Geographical Comparisson",
    "section": "PROVIDER",
    "text": "PROVIDER\n\nprovider_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj2))\n\nprovider.stat &lt;- asNetwork(projected_graph$proj2)\n\nprovider.se &lt;- equiv.clust(provider_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\n\nblk_model.provider.org &lt;- blockmodel(provider_matrix,\n provider.se, k = 6)\n\n\nprov_blks6 &lt;- readRDS(\"prov_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\nprov_blk_mod &lt;- blockmodel(provider_matrix, prov_blks6$best$best1$clu,\n                      plabels = rownames(provider_matrix))\n\n\n#assign block membership to vertex attribute\nprovider.stat%v%\"role\"&lt;-prov_blk_mod$block.membership[match(provider.stat%v%\"vertex.names\",prov_blk_mod$plabels)]\n\n#plot network using \"role\" to color nodes\nGGally::ggnet2(provider.stat,\n               node.color=\"role\", \n               node.size=sna::degree(provider.stat, gmode=\"graph\"),\n               node.alpha = .5) + ggtitle(\"Provider 6 Block Model Network\")"
  },
  {
    "objectID": "posts/Post_Five/post_5.html#create-new-attribute-lists",
    "href": "posts/Post_Five/post_5.html#create-new-attribute-lists",
    "title": "Network Block Modeling - Geographical Comparisson",
    "section": "Create New Attribute Lists",
    "text": "Create New Attribute Lists\n\npat_attr$block &lt;- pat_blk_mod$block.membership\npro_attr$block &lt;- prov_blk_mod$block.membership\nboth_attr &lt;- bind_rows(pat_attr, pro_attr)\n\npat_attr_list &lt;- do.call(list, pat_attr)\npro_attr_list &lt;- do.call(list, pro_attr)\nattribute_list &lt;- do.call(list, both_attr)\n\n\nprovider.st &lt;- network(provider_matrix,\n                       directed = FALSE,\n                       matrix.type = \"adjacency\",\n                       vertex.attr = pro_attr_list)\nprovider.st\n\n Network attributes:\n  vertices = 253 \n  directed = FALSE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = FALSE \n  total edges= 554 \n    missing edges= 0 \n    non-missing edges= 554 \n\n Vertex attribute names: \n    block CITY GENDER NAME type vertex.names \n\nNo edge attributes\n\n\n\nprovider_graph &lt;- graph_from_biadjacency_matrix(provider.st)\n\n\n#assign colors\n#colors &lt;-  c(\"yellow\", \"blue\", \"green\", \"orange\", \"red\", \"purple\")\n#vertex_colors &lt;- colors[pro_attr_list$block]\nvertex_colors &lt;- ifelse(pro_attr_list$CITY == \"BOSTON\", \"red\", \"white\")\n\nvertex_shape &lt;- ifelse(pro_attr_list$CITY == \"BOSTON\", \"circle\", \"square\")\n\n\nplot(provider_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 4, \n     vertex.color = vertex_colors,\n     vertex.shape = vertex_shape,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"SN Graph\")\n\n\n\n\nWhat other cities are on the provider list. Boston is not being properly represented, I have a feeling\n\ntable(pro_attr$CITY)\n\n\n         ALLSTON          AMHERST          ANDOVER        ARLINGTON \n               1                2                1                3 \n          AUBURN       AUBURNDALE       BELLINGHAM          BEVERLY \n               1                2                1                2 \n          Boston           BOSTON      BRIDGEWATER         BRIGHTON \n               1                5                2                2 \n        BROCKTON        BROOKLINE        CAMBRIDGE      CHARLESTOWN \n               1                2                4                1 \n        CHARLTON          CHATHAM       CHELMSFORD          CHELSEA \n               1                1                1                2 \n        CHICOPEE        DARTMOUTH           DEDHAM       DORCHESTER \n               2                1                5                2 \n      E FALMOUTH        Fairhaven        FAIRHAVEN       FALL RIVER \n               1                1                3                4 \n        FALMOUTH        Fitchburg       FOXBOROUGH       FRAMINGHAM \n               3                1                1                2 \n      GEORGETOWN           GROTON          HANOVER     HARWICH PORT \n               1                1                2                1 \n       HAVERHILL          HINGHAM        HOLLISTON          HOLYOKE \n               3                2                1                2 \n       HOPKINTON          HYANNIS        HYDE PARK    Jamaica Plain \n               2                2                1                1 \n   JAMAICA PLAIN         LAWRENCE       LEOMINSTER        LEXINGTON \n               2                3                2                3 \n          LOWELL           LUDLOW             Lynn             LYNN \n               3                1                1                1 \n          MALDEN      MARLBOROUGH         MATTAPAN          MEDFORD \n               1                5                2                2 \n         MELROSE          METHUEN       MIDDLEBORO          MILFORD \n               2                2                1                3 \n          MILTON           NATICK          NEEDHAM      NEW BEDFORD \n               3                3                2                3 \n     NEWBURYPORT           NEWTON      NORTH ADAMS    NORTH ANDOVER \n               1                5                1                1 \n NORTH DARTMOUTH      NORTHAMPTON     NORTHBOROUGH          NORWELL \n               1                1                1                3 \n         NORWOOD       OAK BLUFFS          PEABODY         PEMBROKE \n               6                1                2                1 \n      PITTSFIELD         PLYMOUTH           QUINCY         RANDOLPH \n               3                6                3                2 \n         RAYNHAM          READING         ROCHDALE       ROSLINDALE \n               2                1                1                4 \n          ROWLEY          ROXBURY       S YARMOUTH            SALEM \n               1                1                1                2 \n        SCITUATE           SHARON       SHREWSBURY       SOMERVILLE \n               3                1                1                3 \n  SOUTH YARMOUTH     SOUTHBOROUGH      SPRINGFIELD         STONEHAM \n               2                1                2                2 \n       STOUGHTON        TEWKSBURY            UPTON         UXBRIDGE \n               2                2                1                1 \n         WALPOLE          WALTHAM          WAREHAM        WELLESLEY \n               2                7                3                1 \nWEST BRIDGEWATER     West Roxbury     WEST ROXBURY      WESTBOROUGH \n               3                1                1                4 \n        WESTFORD         WESTWOOD         WEYMOUTH        WILBRAHAM \n               3                1                2                1 \n    WILLIAMSTOWN         WINTHROP           WOBURN        Worcester \n               1                1                6                1 \n       WORCESTER \n              17 \n\npro_attr &lt;- pro_attr %&gt;%\n  mutate(\n    CITY =tolower(CITY)\n  )\npro_attr_list &lt;- do.call(list, pro_attr)\n\nShould have cleaned that earlier, but here we go!\n\nBoston_Neighborhoods &lt;- c(\n  \"ALLSTON\",\n  \"BRIGHTON\",\n  \"BOSTON\",\n  \"CHARLESTOWN\",\n  \"DORCHESTER\",\n  \"HYDE PARK\",\n  \"JAMAICA PLAIN\",\n  \"MATTAPAN\",\n  \"ROSLINDALE\",\n  \"ROXBURY\",\n  \"West Roxbury\",\n  \"WEST ROXBURY\"\n)\nBoston_Neighborhoods &lt;- tolower(Boston_Neighborhoods)\n\n\n#assign colors\n#colors &lt;-  c(\"yellow\", \"blue\", \"green\", \"orange\", \"red\", \"purple\")\n#vertex_colors &lt;- colors[pro_attr_list$block]\nvertex_colors &lt;- ifelse(pro_attr_list$CITY %in% Boston_Neighborhoods, \"red\", \"white\")\nvertex_shape &lt;- ifelse(pro_attr_list$block == \"1\", \"circle\", \"square\")\n#vertex_shape &lt;- ifelse(pro_attr_list$CITY == \"BOSTON\", \"circle\", \"square\")\n\n\nplot(provider_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 4, \n     vertex.color = vertex_colors,\n     vertex.shape = vertex_shape,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Providers - RED = BOSTON\")\n\n\n\n\nSo… it’s not Boston related.\nHow about Highest populations\n\nlargest_pop &lt;- c(\n\"Boston\",\n\"Worcester\",\n\"Springfield\",\n\"Cambridge\",\n\"Lowell\",\n\"Brockton\",\n\"Quincy\",\n\"Lynn\",\n\"New Bedford\",\n\"Fall River\",\n\"Lawrence\",\n\"Newton\",\n\"Somerville\",\n\"Framingham\",\n\"Haverhill\")\nlargest_pop &lt;- tolower(largest_pop)\n\n\n#assign colors\n#colors &lt;-  c(\"yellow\", \"blue\", \"green\", \"orange\", \"red\", \"purple\")\n#vertex_colors &lt;- colors[pro_attr_list$block]\nvertex_colors &lt;- ifelse(pro_attr_list$CITY %in% largest_pop, \"red\", \"white\")\nvertex_shape &lt;- ifelse(pro_attr_list$block == \"1\", \"circle\", \"square\")\n#vertex_shape &lt;- ifelse(pro_attr_list$CITY == \"BOSTON\", \"circle\", \"square\")\n\n\nplot(provider_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 4, \n     vertex.color = vertex_colors,\n     vertex.shape = vertex_shape,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Providers - RED = Largest Cities\")\n\n\n\n\n\nblock1 &lt;- pro_attr %&gt;%\n  filter(block == 1)\nblock1\n\n# A tibble: 10 × 5\n   NAME                      GENDER CITY         type     block\n   &lt;chr&gt;                     &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;    &lt;int&gt;\n 1 Ted955 Reilly981          M      fitchburg    PROVIDER     1\n 2 Barbara209 Maldonado119   F      leominster   PROVIDER     1\n 3 Gisele901 Lehner980       F      west roxbury PROVIDER     1\n 4 Vella930 Ankunding277     F      fall river   PROVIDER     1\n 5 Precious140 Runolfsson901 F      norwell      PROVIDER     1\n 6 Fernande593 Mosciski958   F      e falmouth   PROVIDER     1\n 7 Jolie499 Parisian75       F      worcester    PROVIDER     1\n 8 Archie818 McCullough561   M      medford      PROVIDER     1\n 9 Maxima831 Fahey393        F      plymouth     PROVIDER     1\n10 Mickey576 Borer986        F      worcester    PROVIDER     1\n\n\n\nTed955 &lt;- encounters_cleaned %&gt;% \n    filter(PROVIDER == \"Ted955 Reilly981\") %&gt;% \n    group_by(PROVIDER, CITY.x, REASONDESCRIPTION)%&gt;%\n  summarize(COUNT = n()) \n\n`summarise()` has grouped output by 'PROVIDER', 'CITY.x'. You can override\nusing the `.groups` argument.\n\nTed955\n\n# A tibble: 11 × 4\n# Groups:   PROVIDER, CITY.x [1]\n   PROVIDER         CITY.x    REASONDESCRIPTION                            COUNT\n   &lt;chr&gt;            &lt;chr&gt;     &lt;chr&gt;                                        &lt;int&gt;\n 1 Ted955 Reilly981 Fitchburg Abnormal findings diagnostic imaging heart+…    11\n 2 Ted955 Reilly981 Fitchburg Acute ST segment elevation myocardial infar…     1\n 3 Ted955 Reilly981 Fitchburg Acute non-ST segment elevation myocardial i…     2\n 4 Ted955 Reilly981 Fitchburg Aortic valve regurgitation (disorder)            4\n 5 Ted955 Reilly981 Fitchburg Aortic valve stenosis (disorder)                 6\n 6 Ted955 Reilly981 Fitchburg Chronic congestive heart failure (disorder)     86\n 7 Ted955 Reilly981 Fitchburg History of coronary artery bypass grafting …     6\n 8 Ted955 Reilly981 Fitchburg Ischemic heart disease (disorder)               30\n 9 Ted955 Reilly981 Fitchburg Mitral valve regurgitation (disorder)            2\n10 Ted955 Reilly981 Fitchburg Myocardial infarction (disorder)                 3\n11 Ted955 Reilly981 Fitchburg Stroke                                           1\n\n\nGonna go ahead and say Ted’s a Cardiologist"
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html",
    "href": "posts/Post_One - Copy/post_drug.html",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "",
    "text": "Research Question\nDoes the demographic profile, including factors such as marital status, gender, and income, significantly impact the utilization of healthcare services among people who use drugs (PWUD), and does it influence the structure and strength of social network connections between PWUD and healthcare providers?\nHypothesis\nData Collection\nData for this project were taken from Synthetic Mass, which creates Synthetic patient data from Synthea.\nCriteria for patient download will be set to include patients that have experienced overdose, substance use treatment, and have other indicators in their health records that could be considered substance use.\nWhile a whole host of datasets are available within each download, I will focus this project on three datasets: patients.csv, providers.csv, and encounters.csv.\nData Cleaning\nData for this project will be read in, reduced to only necessary data, cleaned (trim ws, recode variables, match across datasets, and other data cleaning processes)\nData Analysis\nAnalysis will primarily be of a two-mode network, developing an analysis of the patient-provider relationship. Weights will be assigned to the number of visits between patients and providers. Block Modeling analysis will be performed in one-mode networks of patient or providers to understand the structure of the networks. Blocks will be assigned to patients and providers as an attribute for analysis.\nCleaning\nThis post will primarily focus on data cleaning and data exploration with some exploration into social network analysis through transforming the data into an incidence matrix and plotting some attributes.\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(statnet)\nlibrary(ggplot2)\nlibrary(patchwork)"
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html#patient-data",
    "href": "posts/Post_One - Copy/post_drug.html#patient-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "PATIENT DATA",
    "text": "PATIENT DATA\nThe following table is the data available in the patient dataset.\n\npatients &lt;- read_csv(\"synthea_sample_data_csv_latest/patients.csv\")\n\nRows: 86 Columns: 27\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (19): Id, SSN, DRIVERS, PASSPORT, PREFIX, FIRST, LAST, SUFFIX, MAIDEN, ...\ndbl   (6): FIPS, LAT, LON, HEALTHCARE_EXPENSES, HEALTHCARE_COVERAGE, INCOME\ndate  (2): BIRTHDATE, DEATHDATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhead(patients)\n\n# A tibble: 6 × 27\n  Id      BIRTHDATE  DEATHDATE SSN    DRIVERS PASSPORT PREFIX FIRST LAST  SUFFIX\n  &lt;chr&gt;   &lt;date&gt;     &lt;date&gt;    &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; \n1 fd7d27… 1986-07-11 NA        999-5… S99942… X400041… Mrs.   Anni… Glea… &lt;NA&gt;  \n2 cb36b3… 1958-12-12 NA        999-7… S99991… X680941… Mrs.   Juli… Barr… &lt;NA&gt;  \n3 757603… 1977-08-09 NA        999-7… S99974… X378787… Mrs.   Ales… Hean… &lt;NA&gt;  \n4 a970cc… 1997-07-04 NA        999-8… S99937… X401363… Ms.    Sand… Rice… &lt;NA&gt;  \n5 298741… 1979-05-05 NA        999-2… S99988… X201473… Mrs.   Mia3… Runt… &lt;NA&gt;  \n6 0863bd… 1997-11-12 NA        999-8… S99962… X675884… Mr.    Dami… Dach… &lt;NA&gt;  \n# ℹ 17 more variables: MAIDEN &lt;chr&gt;, MARITAL &lt;chr&gt;, RACE &lt;chr&gt;,\n#   ETHNICITY &lt;chr&gt;, GENDER &lt;chr&gt;, BIRTHPLACE &lt;chr&gt;, ADDRESS &lt;chr&gt;, CITY &lt;chr&gt;,\n#   STATE &lt;chr&gt;, COUNTY &lt;chr&gt;, FIPS &lt;dbl&gt;, ZIP &lt;chr&gt;, LAT &lt;dbl&gt;, LON &lt;dbl&gt;,\n#   HEALTHCARE_EXPENSES &lt;dbl&gt;, HEALTHCARE_COVERAGE &lt;dbl&gt;, INCOME &lt;dbl&gt;\n\n\n\nstr(patients)\n\nspc_tbl_ [86 × 27] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Id                 : chr [1:86] \"fd7d2777-0aa7-4495-7355-7d57087f73b1\" \"cb36b365-bfa5-aa61-3240-ed97d2c7b7fa\" \"75760354-5f22-c391-cb3a-f7523b73277d\" \"a970cca2-8c88-a67a-8675-00aa26069356\" ...\n $ BIRTHDATE          : Date[1:86], format: \"1986-07-11\" \"1958-12-12\" ...\n $ DEATHDATE          : Date[1:86], format: NA NA ...\n $ SSN                : chr [1:86] \"999-54-2711\" \"999-75-6253\" \"999-70-3855\" \"999-86-9249\" ...\n $ DRIVERS            : chr [1:86] \"S99942559\" \"S99991886\" \"S99974938\" \"S99937640\" ...\n $ PASSPORT           : chr [1:86] \"X40004111X\" \"X68094169X\" \"X37878770X\" \"X40136308X\" ...\n $ PREFIX             : chr [1:86] \"Mrs.\" \"Mrs.\" \"Mrs.\" \"Ms.\" ...\n $ FIRST              : chr [1:86] \"Annice210\" \"Julianne852\" \"Alesha810\" \"Sandee884\" ...\n $ LAST               : chr [1:86] \"Gleason633\" \"Barrows492\" \"Heaney114\" \"Rice937\" ...\n $ SUFFIX             : chr [1:86] NA NA NA NA ...\n $ MAIDEN             : chr [1:86] \"Koss676\" \"Jacobs452\" \"Labadie908\" NA ...\n $ MARITAL            : chr [1:86] \"M\" \"W\" \"D\" NA ...\n $ RACE               : chr [1:86] \"white\" \"white\" \"white\" \"white\" ...\n $ ETHNICITY          : chr [1:86] \"nonhispanic\" \"nonhispanic\" \"nonhispanic\" \"nonhispanic\" ...\n $ GENDER             : chr [1:86] \"F\" \"F\" \"F\" \"F\" ...\n $ BIRTHPLACE         : chr [1:86] \"Wrentham  Massachusetts  US\" \"Yarmouth Port  Massachusetts  US\" \"East Harwich  Massachusetts  US\" \"Springfield  Massachusetts  US\" ...\n $ ADDRESS            : chr [1:86] \"288 Steuber Landing Suite 38\" \"782 Lynch Dale\" \"415 Emmerich Trail\" \"726 Harvey Throughway\" ...\n $ CITY               : chr [1:86] \"Brookline\" \"Hamilton\" \"Framingham\" \"Taunton\" ...\n $ STATE              : chr [1:86] \"Massachusetts\" \"Massachusetts\" \"Massachusetts\" \"Massachusetts\" ...\n $ COUNTY             : chr [1:86] \"Norfolk County\" \"Essex County\" \"Middlesex County\" \"Bristol County\" ...\n $ FIPS               : num [1:86] 25021 NA 25017 25005 NA ...\n $ ZIP                : chr [1:86] \"02446\" \"00000\" \"01701\" \"02767\" ...\n $ LAT                : num [1:86] 42.4 42.6 42.2 41.9 42.6 ...\n $ LON                : num [1:86] -71.1 -70.8 -71.5 -71.1 -71.4 ...\n $ HEALTHCARE_EXPENSES: num [1:86] 13891 1027127 1021095 80365 577671 ...\n $ HEALTHCARE_COVERAGE: num [1:86] 550582 224662 180027 159483 691055 ...\n $ INCOME             : num [1:86] 1565 39537 114339 96256 71238 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Id = col_character(),\n  ..   BIRTHDATE = col_date(format = \"\"),\n  ..   DEATHDATE = col_date(format = \"\"),\n  ..   SSN = col_character(),\n  ..   DRIVERS = col_character(),\n  ..   PASSPORT = col_character(),\n  ..   PREFIX = col_character(),\n  ..   FIRST = col_character(),\n  ..   LAST = col_character(),\n  ..   SUFFIX = col_character(),\n  ..   MAIDEN = col_character(),\n  ..   MARITAL = col_character(),\n  ..   RACE = col_character(),\n  ..   ETHNICITY = col_character(),\n  ..   GENDER = col_character(),\n  ..   BIRTHPLACE = col_character(),\n  ..   ADDRESS = col_character(),\n  ..   CITY = col_character(),\n  ..   STATE = col_character(),\n  ..   COUNTY = col_character(),\n  ..   FIPS = col_double(),\n  ..   ZIP = col_character(),\n  ..   LAT = col_double(),\n  ..   LON = col_double(),\n  ..   HEALTHCARE_EXPENSES = col_double(),\n  ..   HEALTHCARE_COVERAGE = col_double(),\n  ..   INCOME = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nsummary(patients)\n\n      Id              BIRTHDATE            DEATHDATE         \n Length:86          Min.   :1918-12-18   Min.   :1980-02-04  \n Class :character   1st Qu.:1956-09-07   1st Qu.:1999-02-19  \n Mode  :character   Median :1973-07-22   Median :2007-02-09  \n                    Mean   :1971-05-21   Mean   :2005-05-07  \n                    3rd Qu.:1987-07-27   3rd Qu.:2016-01-04  \n                    Max.   :2004-12-24   Max.   :2021-09-26  \n                                         NA's   :73          \n     SSN              DRIVERS            PASSPORT            PREFIX         \n Length:86          Length:86          Length:86          Length:86         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    FIRST               LAST              SUFFIX             MAIDEN         \n Length:86          Length:86          Length:86          Length:86         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   MARITAL              RACE            ETHNICITY            GENDER         \n Length:86          Length:86          Length:86          Length:86         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  BIRTHPLACE          ADDRESS              CITY              STATE          \n Length:86          Length:86          Length:86          Length:86         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    COUNTY               FIPS           ZIP                 LAT       \n Length:86          Min.   :25001   Length:86          Min.   :41.55  \n Class :character   1st Qu.:25009   Class :character   1st Qu.:41.95  \n Mode  :character   Median :25017   Mode  :character   Median :42.31  \n                    Mean   :25015                      Mean   :42.21  \n                    3rd Qu.:25021                      3rd Qu.:42.46  \n                    Max.   :25027                      Max.   :42.82  \n                    NA's   :21                                        \n      LON         HEALTHCARE_EXPENSES HEALTHCARE_COVERAGE     INCOME      \n Min.   :-73.09   Min.   :   9291     Min.   :      0     Min.   :  1565  \n 1st Qu.:-71.45   1st Qu.:  39582     1st Qu.:  65610     1st Qu.: 30205  \n Median :-71.14   Median : 108692     Median : 322025     Median : 69924  \n Mean   :-71.27   Mean   : 206222     Mean   : 471978     Mean   :161151  \n 3rd Qu.:-70.97   3rd Qu.: 262415     3rd Qu.: 690279     3rd Qu.:128855  \n Max.   :-70.17   Max.   :1058955     Max.   :1893513     Max.   :840567  \n                                                                          \n\n\n\n#create NAME column combining FIRST and LAST names\npatients &lt;- patients %&gt;%\n    rename(PATIENT = Id) %&gt;%\n  unite(NAME, FIRST, LAST, sep = \" \")\n\n#trim whitespace NAME\npatients$NAME &lt;- trimws(patients$NAME)\n\n#trim whitespace COUNTY\npatients$CITY &lt;- trimws(patients$CITY)\n\n#clean up GENDER, RACE, ETHNICITY, and INCOME sections\npatients &lt;- patients %&gt;%\n  mutate(\n    GENDER = tolower(GENDER),\n    GENDER = case_when(\n      GENDER %in% c(\"male\", \"m\", \"man\") ~ \"Male\",\n      GENDER %in% c(\"female\", \"f\", \"woman\") ~ \"Female\",\n      TRUE ~ NA_character_  # assign NA to any non-standard values\n    ),\n# city (patient)\n    CITY =tolower(CITY),\n# race (patient)\n    RACE = tolower(RACE),  # convert race to lower case for consistency\n\n# ethnicity (patient)\n    ETHNICITY = tolower(ETHNICITY),  # convert ethnicity to lower case for consistency\n\n# marital (patient)\n    MARITAL = ifelse(MARITAL == \"M\", \"Married\",\n                    ifelse(MARITAL == \"D\", \"Divorced\",\n                    ifelse(MARITAL == \"W\", \"Widowed\",\n                    ifelse(MARITAL == \"S\", \"Single\", MARITAL)))),\n\n# income (patient)\n    INCOME = as.numeric(INCOME)  # convert income to numeric if necessary\n  ) %&gt;%\n  drop_na(GENDER, RACE) \n\nI am only keeping the demographic data below (gender, race, marital status, income, and age) which will be used as an attribute for each patient.\n\n#Create AGE from BIRTHDATE\npatients &lt;- patients %&gt;%\n  mutate(\n    BIRTHDATE = as.Date(BIRTHDATE),  # Ensure 'dob' is in Date format\n    AGE = interval(BIRTHDATE, today()) / years(1)  # Calculate age in years\n  ) %&gt;%\n  mutate(\n    AGE = floor(AGE)  # complete years only, removing decimal\n  )\n# Only keep patient name and demographics. This will be utilized as the attribute data for analysis.\npat_attr &lt;- patients%&gt;% \n  select(NAME, GENDER, RACE, MARITAL, CITY, INCOME, AGE)\nhead(pat_attr)\n\n# A tibble: 6 × 7\n  NAME                   GENDER RACE  MARITAL  CITY       INCOME   AGE\n  &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Annice210 Gleason633   Female white Married  brookline    1565    37\n2 Julianne852 Barrows492 Female white Widowed  hamilton    39537    65\n3 Alesha810 Heaney114    Female white Divorced framingham 114339    46\n4 Sandee884 Rice937      Female white &lt;NA&gt;     taunton     96256    26\n5 Mia349 Runte676        Female white Divorced chelmsford  71238    44\n6 Damian46 Dach178       Male   white &lt;NA&gt;     swansea     74155    26\n\n\n\npat_race &lt;- ggplot(pat_attr,aes(RACE)) + geom_bar()\npat_gender &lt;- ggplot(pat_attr,aes(GENDER)) + geom_bar()\n\npat_race + pat_gender + plot_annotation(title = \"Patient Race and Gender Breakdown\")\n\n\n\nggplot(pat_attr,aes(MARITAL)) + geom_bar() + labs(title = \"Patient Marital Status\")\n\n\n\npat_income &lt;- ggplot(pat_attr, aes(x = 1, y = INCOME)) +\n    geom_jitter(width = 0.2) +\n    labs(x = NULL, y = \"Income\") +\n    theme_minimal() + labs(title = \"Patient Income\")\n\nsummary(pat_attr$INCOME)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1565   30205   69924  161151  128855  840567 \n\npat_age &lt;- ggplot(pat_attr,aes(AGE)) + geom_bar()\n\nggplot(data = patients %&gt;% \n         count(CITY) %&gt;% \n         filter(n &gt; 2),  # Filter for counts higher than 10\n       aes(x = CITY, y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + labs(title = paste(\"Patients Cities\", \"\\n*filtered to show &gt;2 Patients per City\"))"
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html#provider-data",
    "href": "posts/Post_One - Copy/post_drug.html#provider-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "PROVIDER DATA",
    "text": "PROVIDER DATA\nThe following table is the data available in the provider dataset.\n\nproviders &lt;- read_csv(\"synthea_sample_data_csv_latest/providers.csv\") %&gt;%\n    rename(PROVIDER = Id)\n\nRows: 815 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (9): Id, ORGANIZATION, NAME, GENDER, SPECIALITY, ADDRESS, CITY, STATE, ZIP\ndbl (4): LAT, LON, ENCOUNTERS, PROCEDURES\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(providers)\n\n# A tibble: 6 × 13\n  PROVIDER  ORGANIZATION NAME  GENDER SPECIALITY ADDRESS CITY  STATE ZIP     LAT\n  &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 86726ad9… 74ab949d-17… Ted9… M      GENERAL P… 881 Ma… Fitc… MA    01420  42.6\n2 47fdff5b… 588f6ce6-b8… Tiff… F      GENERAL P… 461 WA… JAMA… MA    0213…  42.3\n3 b31700a0… 324b4137-57… Herm… F      GENERAL P… 134 NO… NORT… MA    0186…  42.6\n4 0ada8fec… b6398e07-49… Shan… M      GENERAL P… 19 TAC… WORC… MA    0160…  42.3\n5 31214beb… faffaf6a-ee… Jaun… F      GENERAL P… 66 WAS… STOU… MA    0207…  42.1\n6 38a7cc67… 17a4bae5-8b… Olym… F      GENERAL P… 512 MA… SHRE… MA    0154…  42.3\n# ℹ 3 more variables: LON &lt;dbl&gt;, ENCOUNTERS &lt;dbl&gt;, PROCEDURES &lt;dbl&gt;\n\n\nI am only keeping the demographic data below (gender) which will be used as an attribute for each provider.\n\n#trim whitespace NAME\nproviders$NAME &lt;- trimws(providers$NAME)\nproviders &lt;- providers %&gt;%\n  mutate(\n    GENDER = tolower(GENDER),\n    GENDER = case_when(\n      GENDER %in% c(\"male\", \"m\", \"man\") ~ \"Male\",\n      GENDER %in% c(\"female\", \"f\", \"woman\") ~ \"Female\",\n      TRUE ~ NA_character_  # assign NA to any non-standard values\n    ),\n    CITY =tolower(CITY)\n  )"
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html#encounter-data",
    "href": "posts/Post_One - Copy/post_drug.html#encounter-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "ENCOUNTER DATA",
    "text": "ENCOUNTER DATA\n\nencounters &lt;- read_csv(\"synthea_sample_data_csv_latest/encounters.csv\")\n\nRows: 6109 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (8): Id, PATIENT, ORGANIZATION, PROVIDER, PAYER, ENCOUNTERCLASS, DESCRI...\ndbl  (5): CODE, BASE_ENCOUNTER_COST, TOTAL_CLAIM_COST, PAYER_COVERAGE, REASO...\ndttm (2): START, STOP\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(encounters)\n\n# A tibble: 6 × 15\n  Id       START               STOP                PATIENT ORGANIZATION PROVIDER\n  &lt;chr&gt;    &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;   \n1 1b544ce… 2000-11-11 13:33:09 2000-11-11 14:33:09 fd7d27… db28cc9a-fd… 715b985…\n2 0d642d8… 2001-03-30 13:33:09 2001-03-30 14:33:09 fd7d27… db28cc9a-fd… 715b985…\n3 99d190e… 2001-11-28 13:33:09 2001-11-28 14:33:09 fd7d27… db28cc9a-fd… 715b985…\n4 cc07637… 2004-09-03 13:33:09 2004-09-03 14:31:19 fd7d27… 3d5fbf38-c7… 2655ff5…\n5 05a2433… 2005-09-09 13:33:09 2005-09-09 14:16:34 fd7d27… 3d5fbf38-c7… 2655ff5…\n6 8844f58… 2008-09-12 13:33:09 2008-09-12 14:28:22 fd7d27… 3d5fbf38-c7… 2655ff5…\n# ℹ 9 more variables: PAYER &lt;chr&gt;, ENCOUNTERCLASS &lt;chr&gt;, CODE &lt;dbl&gt;,\n#   DESCRIPTION &lt;chr&gt;, BASE_ENCOUNTER_COST &lt;dbl&gt;, TOTAL_CLAIM_COST &lt;dbl&gt;,\n#   PAYER_COVERAGE &lt;dbl&gt;, REASONCODE &lt;dbl&gt;, REASONDESCRIPTION &lt;chr&gt;"
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html#combine-patient-provider-and-encounter-data",
    "href": "posts/Post_One - Copy/post_drug.html#combine-patient-provider-and-encounter-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "Combine Patient, Provider, and Encounter Data",
    "text": "Combine Patient, Provider, and Encounter Data\nI am taking this step here so that I have a master dataset (encounters_attributes) and so that I can create an edgelist more easily.\n\n# Perform a left join to merge encounters with provider_attributes based on PROVIDER\nencounters_cleaning &lt;- left_join(encounters, providers, by = \"PROVIDER\")\n# Replace the PROVIDER column with the corresponding names from the NAME column\nencounters_cleaning$PROVIDER &lt;- encounters_cleaning$NAME\n# Remove the NAME column if no longer needed\nencounters_cleaning &lt;- encounters_cleaning %&gt;%\n  select(-NAME)\n#Repeat for Provider\nencounters_cleaning &lt;- left_join(encounters_cleaning, patients, by = \"PATIENT\")\nencounters_cleaning$PATIENT &lt;- encounters_cleaning$NAME\nencounters_cleaning &lt;- encounters_cleaning %&gt;%\n  select(-NAME) \n#Clearly identify the Encounter ID\nencounters_cleaning &lt;- encounters_cleaning %&gt;%\n  rename(ENCOUNTER_ID = Id)"
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html#check-dimensions-between-datasets",
    "href": "posts/Post_One - Copy/post_drug.html#check-dimensions-between-datasets",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "Check Dimensions between Datasets",
    "text": "Check Dimensions between Datasets\nIn later analysis I noticed that while there are more providers in the provider.csv, than there are providers listed in the encounters.csv. I will clean the data to only include providers that appear in the encounters.csv.\n\ncheck_prov &lt;- encounters_cleaning %&gt;%\n  group_by(PROVIDER, GENDER.x) %&gt;%\n  summarize(COUNT = n())\n\n`summarise()` has grouped output by 'PROVIDER'. You can override using the\n`.groups` argument.\n\ncheck_prov_enc &lt;- providers %&gt;% \n  group_by(NAME, PROVIDER)\n\n\ndim(check_prov)\n\n[1] 222   3\n\ndim(check_prov_enc)\n\n[1] 815  13\n\n\n\n# Perform semi-join to keep providers present in both datasets\nproviders_only_in_providers_df &lt;- check_prov_enc %&gt;%\n  anti_join(check_prov, by = c(\"NAME\" = \"PROVIDER\"))\n\n# Print the dimensions of the filtered dataset\nprint(dim(providers_only_in_providers_df))\n\n[1] 592  13\n\nprint(providers_only_in_providers_df)\n\n# A tibble: 592 × 13\n# Groups:   NAME, PROVIDER [592]\n   PROVIDER ORGANIZATION NAME  GENDER SPECIALITY ADDRESS CITY  STATE ZIP     LAT\n   &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 47fdff5… 588f6ce6-b8… Tiff… Female GENERAL P… 461 WA… jama… MA    0213…  42.3\n 2 b31700a… 324b4137-57… Herm… Female GENERAL P… 134 NO… nort… MA    0186…  42.6\n 3 31214be… faffaf6a-ee… Jaun… Female GENERAL P… 66 WAS… stou… MA    0207…  42.1\n 4 38a7cc6… 17a4bae5-8b… Olym… Female GENERAL P… 512 MA… shre… MA    0154…  42.3\n 5 5b8e0a3… 4112b8b1-59… Ambr… Male   GENERAL P… 37 ROU… sand… MA    0256…  41.8\n 6 5cb9747… e76b5eb0-0c… Gise… Female GENERAL P… 1400 V… west… MA    02132  42.3\n 7 633f248… c241b977-41… Kip4… Male   GENERAL P… 94 MAI… hyan… MA    0260…  41.7\n 8 4886d4a… ef5390b4-cb… Mila… Male   GENERAL P… 360 ME… mald… MA    0214…  42.4\n 9 774bf03… 6fafb5d4-ec… Shel… Female GENERAL P… 320 WE… west… MA    02379  42.0\n10 f4e1828… aa682136-a4… Ánge… Female GENERAL P… 501 CO… norw… MA    0206…  42.2\n# ℹ 582 more rows\n# ℹ 3 more variables: LON &lt;dbl&gt;, ENCOUNTERS &lt;dbl&gt;, PROCEDURES &lt;dbl&gt;\n\n\n\n# Perform anti-join to remove providers only present in check_prov_enc from the original dataset\nproviders_filtered &lt;- providers %&gt;%\n  anti_join(providers_only_in_providers_df, by = c(\"NAME\" = \"NAME\"))\n\n# Print the dimensions of the resulting dataset\nprint(dim(providers_filtered))\n\n[1] 223  13\n\n\nResult is 223, though it should be 222.\n\n# Find duplicate rows based on the NAME column\nduplicate_rows &lt;- providers_filtered[duplicated(providers_filtered$NAME) | duplicated(providers_filtered$NAME, fromLast = TRUE), ]\n\n# Print the duplicate rows\nprint(duplicate_rows %&gt;% select(PROVIDER, CITY))\n\n# A tibble: 2 × 2\n  PROVIDER                             CITY      \n  &lt;chr&gt;                                &lt;chr&gt;     \n1 be12b8b5-2618-3d5e-a976-199d56505cd0 leominster\n2 8e8ca291-3456-359b-9a13-0a6dc7016381 reading   \n\n\nAh Maynard.\n\n# Find duplicate rows based on the NAME column\nMaynard_rows &lt;- encounters_cleaning %&gt;% filter (PROVIDER == \"Maynard46 Buckridge80\")\n\n# Print the duplicate rows\nprint(Maynard_rows %&gt;% group_by(CITY.x)) %&gt;% select(PROVIDER, CITY.x)\n\n# A tibble: 22 × 51\n# Groups:   CITY.x [1]\n   ENCOUNTER_ID   START               STOP                PATIENT ORGANIZATION.x\n   &lt;chr&gt;          &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;         \n 1 a4e40cc3-e8e2… 1958-10-16 18:06:02 1958-10-16 18:51:39 Tommy8… 817f4acb-0184…\n 2 64f7e2f4-4fef… 1960-10-27 18:06:02 1960-10-27 18:47:34 Tommy8… 817f4acb-0184…\n 3 c194d751-9164… 1978-11-16 18:06:02 1978-11-16 18:49:04 Tommy8… 817f4acb-0184…\n 4 8f814ff1-65a5… 1979-11-22 18:06:02 1979-11-22 18:47:03 Tommy8… 817f4acb-0184…\n 5 d99e97ef-b857… 1981-12-03 18:06:02 1981-12-03 19:01:22 Tommy8… 817f4acb-0184…\n 6 c3a214d7-4f71… 1982-12-09 18:06:02 1982-12-09 19:00:00 Tommy8… 817f4acb-0184…\n 7 4a9f1c7b-574c… 1985-12-26 18:06:02 1985-12-26 18:51:22 Tommy8… 817f4acb-0184…\n 8 e8e4f402-08a2… 1987-01-01 18:06:02 1987-01-01 18:46:31 Tommy8… 817f4acb-0184…\n 9 24e91e6e-4ec8… 1989-01-12 18:06:02 1989-01-12 18:38:56 Tommy8… 817f4acb-0184…\n10 83cc31e3-4efc… 1991-01-24 18:06:02 1991-01-24 19:02:22 Tommy8… 817f4acb-0184…\n# ℹ 12 more rows\n# ℹ 46 more variables: PROVIDER &lt;chr&gt;, PAYER &lt;chr&gt;, ENCOUNTERCLASS &lt;chr&gt;,\n#   CODE &lt;dbl&gt;, DESCRIPTION &lt;chr&gt;, BASE_ENCOUNTER_COST &lt;dbl&gt;,\n#   TOTAL_CLAIM_COST &lt;dbl&gt;, PAYER_COVERAGE &lt;dbl&gt;, REASONCODE &lt;dbl&gt;,\n#   REASONDESCRIPTION &lt;chr&gt;, ORGANIZATION.y &lt;chr&gt;, GENDER.x &lt;chr&gt;,\n#   SPECIALITY &lt;chr&gt;, ADDRESS.x &lt;chr&gt;, CITY.x &lt;chr&gt;, STATE.x &lt;chr&gt;,\n#   ZIP.x &lt;chr&gt;, LAT.x &lt;dbl&gt;, LON.x &lt;dbl&gt;, ENCOUNTERS &lt;dbl&gt;, …\n\n\n# A tibble: 22 × 2\n# Groups:   CITY.x [1]\n   PROVIDER              CITY.x \n   &lt;chr&gt;                 &lt;chr&gt;  \n 1 Maynard46 Buckridge80 reading\n 2 Maynard46 Buckridge80 reading\n 3 Maynard46 Buckridge80 reading\n 4 Maynard46 Buckridge80 reading\n 5 Maynard46 Buckridge80 reading\n 6 Maynard46 Buckridge80 reading\n 7 Maynard46 Buckridge80 reading\n 8 Maynard46 Buckridge80 reading\n 9 Maynard46 Buckridge80 reading\n10 Maynard46 Buckridge80 reading\n# ℹ 12 more rows\n\n\nI’ll choose the Maynard in Reading and remove the Maynard in Leominster.\n\nproviders_filtered &lt;- providers_filtered %&gt;%\n  filter(PROVIDER != \"be12b8b5-2618-3d5e-a976-199d56505cd0\")\n# Print the dimensions of the resulting dataset\nprint(dim(providers_filtered))\n\n[1] 222  13\n\n\n\ncheck_pat &lt;- encounters_cleaning %&gt;%\n  group_by(PATIENT, GENDER.y) %&gt;%\n  summarize(COUNT = n())\n\n`summarise()` has grouped output by 'PATIENT'. You can override using the\n`.groups` argument.\n\ncheck_pat_enc &lt;- patients %&gt;%\n  group_by(NAME,PATIENT)\n\n\ndim(check_pat)\n\n[1] 86  3\n\ndim(check_pat_enc)\n\n[1] 86 27\n\n\nPatients have the same dimensions."
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html#patient-data-2",
    "href": "posts/Post_One - Copy/post_drug.html#patient-data-2",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "PATIENT DATA 2",
    "text": "PATIENT DATA 2\n\nggplot(providers_filtered, aes(GENDER)) +geom_bar() + labs(title = \"Provider Gender Breakdown\")\n\n\n\nggplot(data = providers_filtered %&gt;% \n         count(CITY) %&gt;% \n         filter(n &gt; 5),  # Filter for counts higher than 10\n       aes(x = CITY, y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + labs(title = paste(\"Provider Cities\", \"\\n*filtered to show &gt;5 Providers per City\"))"
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html#encounter-data-2",
    "href": "posts/Post_One - Copy/post_drug.html#encounter-data-2",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "ENCOUNTER DATA 2",
    "text": "ENCOUNTER DATA 2\n\nggplot(encounters, aes(ENCOUNTERCLASS)) + geom_bar() + coord_flip()+ labs(title = \"Type of Visit\")\n\n\n\nggplot(data = encounters %&gt;% \n         count(DESCRIPTION) %&gt;% \n         filter(n &gt; 50),  # Filter for counts higher than 10\n       aes(x = DESCRIPTION, y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + labs(title = paste(\"Visit Description\", \"\\n*filtered to show &gt;50 visits\"))\n\n\n\nggplot(data = encounters %&gt;% \n         count(REASONDESCRIPTION) %&gt;% \n         filter(n &gt; 50),  # Filter for counts higher than 10\n       aes(x = reorder(REASONDESCRIPTION, n), y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + labs(title = paste(\"Reason Patient Visited Provider\", \"\\n*filtered to show &gt;50 visits\"))\n\n\n\n\nAside from NA (which does not stand for Narcotics Anonymous) the most frequent reason a patient visits a provider is for “Dependent drug abuse (disorder)”. This is exactly what I would have anticipated seeing in this dataset, considering I called for only patients with a high likelyhood of being drug dependent.\nThe second most frequent reason for visiting a provider is “Chronic kidney disease stage 4 (disorder)”. One insight I have been given is that kidney disease may involve a lot of trips to the doctors for dialysis. I may look into this dataset to see if I’m right, but this is more a side tangent."
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html#join-datasets",
    "href": "posts/Post_One - Copy/post_drug.html#join-datasets",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "Join Datasets",
    "text": "Join Datasets\n\n# Perform a left join to merge encounters with provider_attributes based on PROVIDER\nencounters_cleaned &lt;- left_join(encounters, providers_filtered, by = \"PROVIDER\")\n# Replace the PROVIDER column with the corresponding names from the NAME column\nencounters_cleaned$PROVIDER &lt;- encounters_cleaned$NAME\n# Remove the NAME column if no longer needed\nencounters_cleaned &lt;- encounters_cleaned %&gt;%\n  select(-NAME)\n#Repeat for Provider\nencounters_cleaned &lt;- left_join(encounters_cleaned, patients, by = \"PATIENT\")\nencounters_cleaned$PATIENT &lt;- encounters_cleaned$NAME\nencounters_cleaned &lt;- encounters_cleaned %&gt;%\n  select(-NAME) \n#Clearly identify the Encounter ID\nencounters_cleaned &lt;- encounters_cleaned %&gt;%\n  rename(ENCOUNTER_ID = Id)\n\n\nencounter_attributes &lt;- encounters_cleaned %&gt;%\n  select(ENCOUNTER_ID, PATIENT, PROVIDER, GENDER.x, GENDER.y, RACE, MARITAL, ETHNICITY, INCOME, CITY.x, CITY.y)\n# View the updated dataframe\nhead(encounter_attributes)\n\n# A tibble: 6 × 11\n  ENCOUNTER_ID PATIENT PROVIDER GENDER.x GENDER.y RACE  MARITAL ETHNICITY INCOME\n  &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt;\n1 1b544ceb-bf… Annice… Clement… Male     Female   white Married nonhispa…   1565\n2 0d642d81-96… Annice… Clement… Male     Female   white Married nonhispa…   1565\n3 99d190e1-67… Annice… Clement… Male     Female   white Married nonhispa…   1565\n4 cc076374-d3… Annice… Enrique… Female   Female   white Married nonhispa…   1565\n5 05a24332-4d… Annice… Enrique… Female   Female   white Married nonhispa…   1565\n6 8844f58d-3e… Annice… Enrique… Female   Female   white Married nonhispa…   1565\n# ℹ 2 more variables: CITY.x &lt;chr&gt;, CITY.y &lt;chr&gt;"
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html#edgelist",
    "href": "posts/Post_One - Copy/post_drug.html#edgelist",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "EDGELIST",
    "text": "EDGELIST\n\n# Create Edgelist & Assign Weight by Count of Encounter\nencounters_el &lt;- encounter_attributes %&gt;%\n  group_by(PATIENT, PROVIDER) %&gt;%\n  summarize(COUNT = n()) \n\n`summarise()` has grouped output by 'PATIENT'. You can override using the\n`.groups` argument.\n\nhead(encounters_el)\n\n# A tibble: 6 × 3\n# Groups:   PATIENT [2]\n  PATIENT             PROVIDER                  COUNT\n  &lt;chr&gt;               &lt;chr&gt;                     &lt;int&gt;\n1 Adam631 Hoppe518    Elijah719 White193            8\n2 Adam631 Hoppe518    Fidel864 Swift555             2\n3 Adam631 Hoppe518    Virgen207 Hyatt152            3\n4 Adam631 Hoppe518    Zachery872 Pagac496          31\n5 Alesha810 Heaney114 Kristopher775 Schiller186    13\n6 Alesha810 Heaney114 Laine739 Torphy630            4\n\ndim(encounters_el)\n\n[1] 341   3"
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html#combined-attribute-list",
    "href": "posts/Post_One - Copy/post_drug.html#combined-attribute-list",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "COMBINED ATTRIBUTE LIST",
    "text": "COMBINED ATTRIBUTE LIST\n\n#combine pro and pat attr\npat_attr$type &lt;- \"PATIENT\"\npro_attr &lt;- providers_filtered %&gt;%\n  select(NAME, GENDER, CITY)\npro_attr$type &lt;- \"PROVIDER\"\nboth_attr &lt;- bind_rows(pat_attr, pro_attr)\nhead(both_attr)\n\n# A tibble: 6 × 8\n  NAME                   GENDER RACE  MARITAL  CITY       INCOME   AGE type   \n  &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  \n1 Annice210 Gleason633   Female white Married  brookline    1565    37 PATIENT\n2 Julianne852 Barrows492 Female white Widowed  hamilton    39537    65 PATIENT\n3 Alesha810 Heaney114    Female white Divorced framingham 114339    46 PATIENT\n4 Sandee884 Rice937      Female white &lt;NA&gt;     taunton     96256    26 PATIENT\n5 Mia349 Runte676        Female white Divorced chelmsford  71238    44 PATIENT\n6 Damian46 Dach178       Male   white &lt;NA&gt;     swansea     74155    26 PATIENT\n\n\n\n#create combined attribute list\nattribute_list &lt;- do.call(list, both_attr)"
  },
  {
    "objectID": "posts/Post_One - Copy/post_drug.html#network",
    "href": "posts/Post_One - Copy/post_drug.html#network",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "NETWORK",
    "text": "NETWORK\n\n# create bipartite network with attributes\nencounters.st.3 &lt;- network(encounters_el,\n                         directed = FALSE,\n                         bipartite = TRUE,\n                         matrix.type = \"edgelist\",\n                         vertex.attr = attribute_list)\nencounters.st.3\n\n Network attributes:\n  vertices = 308 \n  directed = FALSE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = 86 \n  total edges= 341 \n    missing edges= 0 \n    non-missing edges= 341 \n\n Vertex attribute names: \n    AGE CITY GENDER INCOME MARITAL NAME RACE type vertex.names \n\n Edge attribute names: \n    COUNT"
  },
  {
    "objectID": "posts/Post_Six/post_6.html",
    "href": "posts/Post_Six/post_6.html",
    "title": "Network Block Modeling - Geographical Comparisson",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(tigris)\nlibrary(stplanr)\nThis post will explore the Synthetic Mass network data in more detail."
  },
  {
    "objectID": "posts/Post_Six/post_6.html#patient",
    "href": "posts/Post_Six/post_6.html#patient",
    "title": "Network Block Modeling - Geographical Comparisson",
    "section": "PATIENT",
    "text": "PATIENT\n\npatient_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj1))\n\npatient.stat &lt;- asNetwork(projected_graph$proj1)\n\npatient.se &lt;- equiv.clust(patient_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\n\npat_blk_model.patient.org &lt;- blockmodel(patient_matrix,\n patient.se, k = 4)\n\n\nplot.block&lt;-function(x=pat_blk_mod, main=NULL, cex.lab=.00001,show_labels = FALSE){\n plot.sociomatrix(x$blocked.data, labels=list(x$plabels,x$plabels),\n main=main, drawlines = FALSE, cex.lab=cex.lab)\n for (j in 2:length(x$plabels)) if (x$block.membership[j] !=\n x$block.membership[j-1])\n abline(v = j- 0.5, h = j- 0.5, lty = 3, xpd=FALSE)\n }\n \nplot.block(pat_blk_model.patient.org, main = \"patient\")\n\n\n\n\n\npat_blks6 &lt;- readRDS(\"pat_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\npat_blk_mod &lt;- blockmodel(patient_matrix, pat_blks6$best$best1$clu,\n                      plabels = rownames(patient_matrix))\n\n\n#assign block membership to vertex attribute\npatient.stat%v%\"role\"&lt;-pat_blk_mod$block.membership[match(patient.stat%v%\"vertex.names\",pat_blk_mod$plabels)]\n#plot network using \"role\" to color nodes\nGGally::ggnet2(patient.stat,\n               node.color=\"role\", \n               node.size=sna::degree(patient.stat, gmode=\"graph\"),\n               node.alpha = .5)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2"
  },
  {
    "objectID": "posts/Post_Six/post_6.html#provider",
    "href": "posts/Post_Six/post_6.html#provider",
    "title": "Network Block Modeling - Geographical Comparisson",
    "section": "PROVIDER",
    "text": "PROVIDER\n\nprovider_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj2))\n\nprovider.stat &lt;- asNetwork(projected_graph$proj2)\n\nprovider.se &lt;- equiv.clust(provider_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\n\nblk_model.provider.org &lt;- blockmodel(provider_matrix,\n provider.se, k = 6)\n\n\nprov_blks6 &lt;- readRDS(\"prov_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\nprov_blk_mod &lt;- blockmodel(provider_matrix, prov_blks6$best$best1$clu,\n                      plabels = rownames(provider_matrix))\n\n\n#assign block membership to vertex attribute\nprovider.stat%v%\"role\"&lt;-prov_blk_mod$block.membership[match(provider.stat%v%\"vertex.names\",prov_blk_mod$plabels)]\n\n#plot network using \"role\" to color nodes\nGGally::ggnet2(provider.stat,\n               node.color=\"role\", \n               node.size=sna::degree(provider.stat, gmode=\"graph\"),\n               node.alpha = .5) + ggtitle(\"Provider 6 Block Model Network\")"
  },
  {
    "objectID": "posts/Post_Six/post_6.html#create-new-attribute-lists",
    "href": "posts/Post_Six/post_6.html#create-new-attribute-lists",
    "title": "Network Block Modeling - Geographical Comparisson",
    "section": "Create New Attribute Lists",
    "text": "Create New Attribute Lists\n\npat_attr$block &lt;- pat_blk_mod$block.membership\npro_attr$block &lt;- prov_blk_mod$block.membership\nboth_attr &lt;- bind_rows(pat_attr, pro_attr)\n\npat_attr_list &lt;- do.call(list, pat_attr)\npro_attr_list &lt;- do.call(list, pro_attr)\nattribute_list &lt;- do.call(list, both_attr)\n\n\nprovider.st &lt;- network(provider_matrix,\n                       directed = FALSE,\n                       matrix.type = \"adjacency\",\n                       vertex.attr = pro_attr_list)\nprovider.st\n\n Network attributes:\n  vertices = 253 \n  directed = FALSE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = FALSE \n  total edges= 554 \n    missing edges= 0 \n    non-missing edges= 554 \n\n Vertex attribute names: \n    block CITY GENDER NAME type vertex.names \n\nNo edge attributes\n\n\n\nprovider_graph &lt;- graph_from_biadjacency_matrix(provider.st)\n\n\n#assign colors\n#colors &lt;-  c(\"yellow\", \"blue\", \"green\", \"orange\", \"red\", \"purple\")\n#vertex_colors &lt;- colors[pro_attr_list$block]\nvertex_colors &lt;- ifelse(pro_attr_list$CITY == \"BOSTON\", \"red\", \"white\")\n\nvertex_shape &lt;- ifelse(pro_attr_list$CITY == \"BOSTON\", \"circle\", \"square\")\n\n\nplot(provider_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 4, \n     vertex.color = vertex_colors,\n     vertex.shape = vertex_shape,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"SN Graph\")\n\n\n\n\nWhat other cities are on the provider list. Boston is not being properly represented, I have a feeling\n\ntable(pro_attr$CITY)\n\n\n         ALLSTON          AMHERST          ANDOVER        ARLINGTON \n               1                2                1                3 \n          AUBURN       AUBURNDALE       BELLINGHAM          BEVERLY \n               1                2                1                2 \n          Boston           BOSTON      BRIDGEWATER         BRIGHTON \n               1                5                2                2 \n        BROCKTON        BROOKLINE        CAMBRIDGE      CHARLESTOWN \n               1                2                4                1 \n        CHARLTON          CHATHAM       CHELMSFORD          CHELSEA \n               1                1                1                2 \n        CHICOPEE        DARTMOUTH           DEDHAM       DORCHESTER \n               2                1                5                2 \n      E FALMOUTH        Fairhaven        FAIRHAVEN       FALL RIVER \n               1                1                3                4 \n        FALMOUTH        Fitchburg       FOXBOROUGH       FRAMINGHAM \n               3                1                1                2 \n      GEORGETOWN           GROTON          HANOVER     HARWICH PORT \n               1                1                2                1 \n       HAVERHILL          HINGHAM        HOLLISTON          HOLYOKE \n               3                2                1                2 \n       HOPKINTON          HYANNIS        HYDE PARK    Jamaica Plain \n               2                2                1                1 \n   JAMAICA PLAIN         LAWRENCE       LEOMINSTER        LEXINGTON \n               2                3                2                3 \n          LOWELL           LUDLOW             Lynn             LYNN \n               3                1                1                1 \n          MALDEN      MARLBOROUGH         MATTAPAN          MEDFORD \n               1                5                2                2 \n         MELROSE          METHUEN       MIDDLEBORO          MILFORD \n               2                2                1                3 \n          MILTON           NATICK          NEEDHAM      NEW BEDFORD \n               3                3                2                3 \n     NEWBURYPORT           NEWTON      NORTH ADAMS    NORTH ANDOVER \n               1                5                1                1 \n NORTH DARTMOUTH      NORTHAMPTON     NORTHBOROUGH          NORWELL \n               1                1                1                3 \n         NORWOOD       OAK BLUFFS          PEABODY         PEMBROKE \n               6                1                2                1 \n      PITTSFIELD         PLYMOUTH           QUINCY         RANDOLPH \n               3                6                3                2 \n         RAYNHAM          READING         ROCHDALE       ROSLINDALE \n               2                1                1                4 \n          ROWLEY          ROXBURY       S YARMOUTH            SALEM \n               1                1                1                2 \n        SCITUATE           SHARON       SHREWSBURY       SOMERVILLE \n               3                1                1                3 \n  SOUTH YARMOUTH     SOUTHBOROUGH      SPRINGFIELD         STONEHAM \n               2                1                2                2 \n       STOUGHTON        TEWKSBURY            UPTON         UXBRIDGE \n               2                2                1                1 \n         WALPOLE          WALTHAM          WAREHAM        WELLESLEY \n               2                7                3                1 \nWEST BRIDGEWATER     West Roxbury     WEST ROXBURY      WESTBOROUGH \n               3                1                1                4 \n        WESTFORD         WESTWOOD         WEYMOUTH        WILBRAHAM \n               3                1                2                1 \n    WILLIAMSTOWN         WINTHROP           WOBURN        Worcester \n               1                1                6                1 \n       WORCESTER \n              17 \n\npro_attr &lt;- pro_attr %&gt;%\n  mutate(\n    CITY =tolower(CITY)\n  )\npro_attr_list &lt;- do.call(list, pro_attr)\n\nShould have cleaned that earlier, but here we go!\n\nBoston_Neighborhoods &lt;- c(\n  \"ALLSTON\",\n  \"BRIGHTON\",\n  \"BOSTON\",\n  \"CHARLESTOWN\",\n  \"DORCHESTER\",\n  \"HYDE PARK\",\n  \"JAMAICA PLAIN\",\n  \"MATTAPAN\",\n  \"ROSLINDALE\",\n  \"ROXBURY\",\n  \"West Roxbury\",\n  \"WEST ROXBURY\"\n)\nBoston_Neighborhoods &lt;- tolower(Boston_Neighborhoods)\n\n\n#assign colors\n#colors &lt;-  c(\"yellow\", \"blue\", \"green\", \"orange\", \"red\", \"purple\")\n#vertex_colors &lt;- colors[pro_attr_list$block]\nvertex_colors &lt;- ifelse(pro_attr_list$CITY %in% Boston_Neighborhoods, \"red\", \"white\")\nvertex_shape &lt;- ifelse(pro_attr_list$block == \"1\", \"circle\", \"square\")\n#vertex_shape &lt;- ifelse(pro_attr_list$CITY == \"BOSTON\", \"circle\", \"square\")\n\n\nplot(provider_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 4, \n     vertex.color = vertex_colors,\n     vertex.shape = vertex_shape,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Providers - RED = BOSTON\")\n\n\n\n\nSo… it’s not Boston related.\nHow about Highest populations\n\nlargest_pop &lt;- c(\n\"Boston\",\n\"Worcester\",\n\"Springfield\",\n\"Cambridge\",\n\"Lowell\",\n\"Brockton\",\n\"Quincy\",\n\"Lynn\",\n\"New Bedford\",\n\"Fall River\",\n\"Lawrence\",\n\"Newton\",\n\"Somerville\",\n\"Framingham\",\n\"Haverhill\")\nlargest_pop &lt;- tolower(largest_pop)\n\n\n#assign colors\n#colors &lt;-  c(\"yellow\", \"blue\", \"green\", \"orange\", \"red\", \"purple\")\n#vertex_colors &lt;- colors[pro_attr_list$block]\nvertex_colors &lt;- ifelse(pro_attr_list$CITY %in% largest_pop, \"red\", \"white\")\nvertex_shape &lt;- ifelse(pro_attr_list$block == \"1\", \"circle\", \"square\")\n#vertex_shape &lt;- ifelse(pro_attr_list$CITY == \"BOSTON\", \"circle\", \"square\")\n\n\nplot(provider_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 4, \n     vertex.color = vertex_colors,\n     vertex.shape = vertex_shape,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Providers - RED = Largest Cities\")\n\n\n\n\n\nblock1 &lt;- pro_attr %&gt;%\n  filter(block == 1)\nblock1\n\n# A tibble: 10 × 5\n   NAME                      GENDER CITY         type     block\n   &lt;chr&gt;                     &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;    &lt;int&gt;\n 1 Ted955 Reilly981          M      fitchburg    PROVIDER     1\n 2 Barbara209 Maldonado119   F      leominster   PROVIDER     1\n 3 Gisele901 Lehner980       F      west roxbury PROVIDER     1\n 4 Vella930 Ankunding277     F      fall river   PROVIDER     1\n 5 Precious140 Runolfsson901 F      norwell      PROVIDER     1\n 6 Fernande593 Mosciski958   F      e falmouth   PROVIDER     1\n 7 Jolie499 Parisian75       F      worcester    PROVIDER     1\n 8 Archie818 McCullough561   M      medford      PROVIDER     1\n 9 Maxima831 Fahey393        F      plymouth     PROVIDER     1\n10 Mickey576 Borer986        F      worcester    PROVIDER     1\n\n\n\nTed955 &lt;- encounters_cleaned %&gt;% \n    filter(PROVIDER == \"Ted955 Reilly981\") %&gt;% \n    group_by(PROVIDER, CITY.x, REASONDESCRIPTION)%&gt;%\n  summarize(COUNT = n()) \n\n`summarise()` has grouped output by 'PROVIDER', 'CITY.x'. You can override\nusing the `.groups` argument.\n\nTed955%&gt;%\n  arrange(desc(COUNT))\n\n# A tibble: 11 × 4\n# Groups:   PROVIDER, CITY.x [1]\n   PROVIDER         CITY.x    REASONDESCRIPTION                            COUNT\n   &lt;chr&gt;            &lt;chr&gt;     &lt;chr&gt;                                        &lt;int&gt;\n 1 Ted955 Reilly981 Fitchburg Chronic congestive heart failure (disorder)     86\n 2 Ted955 Reilly981 Fitchburg Ischemic heart disease (disorder)               30\n 3 Ted955 Reilly981 Fitchburg Abnormal findings diagnostic imaging heart+…    11\n 4 Ted955 Reilly981 Fitchburg Aortic valve stenosis (disorder)                 6\n 5 Ted955 Reilly981 Fitchburg History of coronary artery bypass grafting …     6\n 6 Ted955 Reilly981 Fitchburg Aortic valve regurgitation (disorder)            4\n 7 Ted955 Reilly981 Fitchburg Myocardial infarction (disorder)                 3\n 8 Ted955 Reilly981 Fitchburg Acute non-ST segment elevation myocardial i…     2\n 9 Ted955 Reilly981 Fitchburg Mitral valve regurgitation (disorder)            2\n10 Ted955 Reilly981 Fitchburg Acute ST segment elevation myocardial infar…     1\n11 Ted955 Reilly981 Fitchburg Stroke                                           1\n\n\nGonna go ahead and say Ted’s a Cardiologist\nMaybe there are other doctors that are in block one that are also cardiologists?\n\nBarbara209 &lt;- encounters_cleaned %&gt;% \n    filter(PROVIDER == \"Barbara209 Maldonado119\") %&gt;% \n    group_by(PROVIDER, CITY.x, REASONDESCRIPTION)%&gt;%\n  summarize(COUNT = n()) \n\n`summarise()` has grouped output by 'PROVIDER', 'CITY.x'. You can override\nusing the `.groups` argument.\n\nBarbara209 %&gt;%\n  arrange(desc(COUNT))\n\n# A tibble: 9 × 4\n# Groups:   PROVIDER, CITY.x [1]\n  PROVIDER                CITY.x     REASONDESCRIPTION                     COUNT\n  &lt;chr&gt;                   &lt;chr&gt;      &lt;chr&gt;                                 &lt;int&gt;\n1 Barbara209 Maldonado119 LEOMINSTER Allergy to substance (finding)            4\n2 Barbara209 Maldonado119 LEOMINSTER &lt;NA&gt;                                      4\n3 Barbara209 Maldonado119 LEOMINSTER Essential hypertension (disorder)         3\n4 Barbara209 Maldonado119 LEOMINSTER Viral sinusitis (disorder)                2\n5 Barbara209 Maldonado119 LEOMINSTER Acute infective cystitis (disorder)       1\n6 Barbara209 Maldonado119 LEOMINSTER Chronic pain                              1\n7 Barbara209 Maldonado119 LEOMINSTER Cow's milk (substance)                    1\n8 Barbara209 Maldonado119 LEOMINSTER Perennial allergic rhinitis with sea…     1\n9 Barbara209 Maldonado119 LEOMINSTER Streptococcal sore throat (disorder)      1\n\n\n\nGisele901 &lt;- encounters_cleaned %&gt;% \n    filter(PROVIDER == \"Gisele901 Lehner980\") %&gt;% \n    group_by(PROVIDER, CITY.x, REASONDESCRIPTION)%&gt;%\n  summarize(COUNT = n()) \n\n`summarise()` has grouped output by 'PROVIDER', 'CITY.x'. You can override\nusing the `.groups` argument.\n\nGisele901 %&gt;%\n  arrange(desc(COUNT))\n\n# A tibble: 9 × 4\n# Groups:   PROVIDER, CITY.x [1]\n  PROVIDER            CITY.x       REASONDESCRIPTION                       COUNT\n  &lt;chr&gt;               &lt;chr&gt;        &lt;chr&gt;                                   &lt;int&gt;\n1 Gisele901 Lehner980 West Roxbury End-stage renal disease (disorder)        117\n2 Gisele901 Lehner980 West Roxbury &lt;NA&gt;                                       91\n3 Gisele901 Lehner980 West Roxbury Chronic kidney disease stage 4 (disord…    50\n4 Gisele901 Lehner980 West Roxbury Acute bronchitis (disorder)                 2\n5 Gisele901 Lehner980 West Roxbury Screening for malignant neoplasm of co…     2\n6 Gisele901 Lehner980 West Roxbury Concussion with no loss of consciousne…     1\n7 Gisele901 Lehner980 West Roxbury Familial Alzheimer's disease of early …     1\n8 Gisele901 Lehner980 West Roxbury Suspected prostate cancer (situation)       1\n9 Gisele901 Lehner980 West Roxbury Viral sinusitis (disorder)                  1\n\n\n\nencounters_reasons &lt;- encounters_cleaned %&gt;% \n    group_by(PROVIDER, CITY.x, REASONDESCRIPTION)%&gt;%\n    summarize(COUNT = n()) \n\n`summarise()` has grouped output by 'PROVIDER', 'CITY.x'. You can override\nusing the `.groups` argument.\n\nencounters_reasons %&gt;%\n  arrange(desc(COUNT))\n\n# A tibble: 938 × 4\n# Groups:   PROVIDER, CITY.x [253]\n   PROVIDER                CITY.x     REASONDESCRIPTION                    COUNT\n   &lt;chr&gt;                   &lt;chr&gt;      &lt;chr&gt;                                &lt;int&gt;\n 1 Alvin56 Crona259        METHUEN    Chronic kidney disease stage 4 (dis…   619\n 2 Rhett759 Padberg411     ROCHDALE   Chronic kidney disease stage 4 (dis…   576\n 3 Rudolf736 Vandervort697 MILTON     Chronic kidney disease stage 4 (dis…   504\n 4 Johna806 Klein929       DARTMOUTH  End-stage renal disease (disorder)     444\n 5 Ross213 Wisozk929       Fairhaven  Chronic kidney disease stage 4 (dis…   418\n 6 Merrilee429 Daugherty69 Boston     Chronic kidney disease stage 4 (dis…   387\n 7 Bea654 Daniel959        OAK BLUFFS Chronic kidney disease stage 4 (dis…   366\n 8 Sulema841 Ryan260       WAREHAM    Chronic kidney disease stage 4 (dis…   319\n 9 Floy720 Greenfelder433  SOMERVILLE End-stage renal disease (disorder)     298\n10 Leopoldo762 Keebler762  CAMBRIDGE  Chronic kidney disease stage 4 (dis…   284\n# ℹ 928 more rows\n\n\n\nAlvin56 &lt;- encounters_cleaned %&gt;% \n    filter(PROVIDER == \"Alvin56 Crona259\") %&gt;% \n    group_by(PROVIDER, PATIENT, CITY.x, REASONDESCRIPTION)%&gt;%\n  summarize(COUNT = n()) \n\n`summarise()` has grouped output by 'PROVIDER', 'PATIENT', 'CITY.x'. You can\noverride using the `.groups` argument.\n\nAlvin56 %&gt;%\n  arrange(desc(COUNT))\n\n# A tibble: 13 × 5\n# Groups:   PROVIDER, PATIENT, CITY.x [2]\n   PROVIDER         PATIENT                CITY.x  REASONDESCRIPTION       COUNT\n   &lt;chr&gt;            &lt;chr&gt;                  &lt;chr&gt;   &lt;chr&gt;                   &lt;int&gt;\n 1 Alvin56 Crona259 Margart214 Bogisich202 METHUEN Chronic kidney disease…   619\n 2 Alvin56 Crona259 Margart214 Bogisich202 METHUEN &lt;NA&gt;                       99\n 3 Alvin56 Crona259 Jesusa437 Mayer370     METHUEN Acute bronchitis (diso…     2\n 4 Alvin56 Crona259 Margart214 Bogisich202 METHUEN Screening for malignan…     2\n 5 Alvin56 Crona259 Margart214 Bogisich202 METHUEN Viral sinusitis (disor…     2\n 6 Alvin56 Crona259 Jesusa437 Mayer370     METHUEN Anemia (disorder)           1\n 7 Alvin56 Crona259 Jesusa437 Mayer370     METHUEN Chronic pain (finding)      1\n 8 Alvin56 Crona259 Jesusa437 Mayer370     METHUEN Fracture of rib             1\n 9 Alvin56 Crona259 Jesusa437 Mayer370     METHUEN Screening for malignan…     1\n10 Alvin56 Crona259 Jesusa437 Mayer370     METHUEN Sterilization requeste…     1\n11 Alvin56 Crona259 Jesusa437 Mayer370     METHUEN Viral sinusitis (disor…     1\n12 Alvin56 Crona259 Jesusa437 Mayer370     METHUEN &lt;NA&gt;                        1\n13 Alvin56 Crona259 Margart214 Bogisich202 METHUEN Tubal pregnancy             1\n\n\n\nMargart214 &lt;- encounters_cleaned %&gt;% \n    filter(PROVIDER == \"Margart214 Bogisich202\") %&gt;% \n    group_by(PROVIDER, PATIENT, CITY.x, REASONDESCRIPTION)%&gt;%\n  summarize(COUNT = n()) \n\n`summarise()` has grouped output by 'PROVIDER', 'PATIENT', 'CITY.x'. You can\noverride using the `.groups` argument.\n\nMargart214 %&gt;%\n  arrange(desc(COUNT))\n\n# A tibble: 0 × 5\n# Groups:   PROVIDER, PATIENT, CITY.x [0]\n# ℹ 5 variables: PROVIDER &lt;chr&gt;, PATIENT &lt;chr&gt;, CITY.x &lt;chr&gt;,\n#   REASONDESCRIPTION &lt;chr&gt;, COUNT &lt;int&gt;"
  },
  {
    "objectID": "posts/Post_Two - Copy/post_2_drug.html",
    "href": "posts/Post_Two - Copy/post_2_drug.html",
    "title": "Network Exploration",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(ggplot2)\nlibrary(patchwork)\nThis post will explore the Synthetic Mass network data in more detail."
  },
  {
    "objectID": "posts/Post_Two - Copy/post_2_drug.html#graphs-with-sna",
    "href": "posts/Post_Two - Copy/post_2_drug.html#graphs-with-sna",
    "title": "Network Exploration",
    "section": "Graphs with sna",
    "text": "Graphs with sna\n\n# load the sna library to get the gplot() function\nlibrary( sna )\n\n# set the seed to reproduce the plot layout\nset.seed( 507 )\n\n# execute the plot\ngplot(\n  encounters.st.3,             \n  gmode = \"twomode\",                     # indicate it is two modes\n  usearrows = FALSE,                     # turn off the arrowheads\n  vertex.cex=2,                          # size the nodes     \n  label.cex=1.2,                         # size the labels\n  main=\"Bipartite Graph of Encounters using SNA\"                 # add a title\n)\n\n\n\n\n\nincidence_graph &lt;- graph_from_biadjacency_matrix(encounters.st.3)\n\ndetach(“package:sna”)"
  },
  {
    "objectID": "posts/Post_Two - Copy/post_2_drug.html#graphs-with-igraph",
    "href": "posts/Post_Two - Copy/post_2_drug.html#graphs-with-igraph",
    "title": "Network Exploration",
    "section": "Graphs with igraph",
    "text": "Graphs with igraph\n\nvertex_colors &lt;- ifelse(attribute_list$GENDER == \"Female\", \"pink\", \"turquoise\")\nV(incidence_graph)$shape &lt;- ifelse(V(incidence_graph)$type, \"square\", \"circle\")\n\n# Define edge colors based on COUNT attribute\nedge_colors &lt;- ifelse(encounters_el$COUNT &lt; 5, \"lightblue\", \n                      ifelse(encounters_el$COUNT &lt;= 20, \"blue\", \n                              ifelse(encounters_el$COUNT &lt;= 100, \"darkblue\", \"red\")))\n\n\n# Check if the length of edge_colors matches the number of edges\nif (length(edge_colors) == ecount(incidence_graph)) {\n  # Set edge attributes based on counts\n  E(incidence_graph)$color &lt;- edge_colors\n} else {\n  print(\"Length of edge_colors does not match the number of edges in the graph.\")\n}\n\nE(incidence_graph)$color &lt;- edge_colors\n\n# set the seed to reproduce the plot layout\nset.seed( 235 )\n\nplot(incidence_graph,\n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 3, \n     vertex.color = vertex_colors,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Patient Provider Incidence Graph\")\n# Define legend for vertex colors\nlegend(\"bottomright\",\n       legend = c(\"Female\", \"Male\"),  # You can customize these labels\n       fill = c(\"pink\", \"turquoise\"),   # Fill colors corresponding to vertex colors\n       title = \"Nodes: Gender\")              # Legend title\n\n# Define legend for vertex shapes\nlegend(\"topright\",\n       legend = c(\"Patient\", \"Provider\"),  # You can customize these labels\n       pch = c(1, 0),                      # Point shapes corresponding to vertex shapes\n       title = \"Nodes: Who\")                     # Legend title\n\n# Define legend for edge colors\nlegend(\"topleft\",\n       legend = c(\"1-4\", \"5-19\", \"20-99\", \"100+\"),  # You can customize these labels\n       col = c(\"lightblue\", \"blue\", \"darkblue\", \"red\"),  # Line colors corresponding to edge colors\n       lwd = 2,                            # Line width\n       title = \"Edges: # of Visits\")              # Legend title\n\n\n\n\n\n#Calculating centrality\ntypes &lt;- V(incidence_graph)$type\ndeg&lt;- igraph::degree(incidence_graph)\nbet &lt;- igraph::betweenness(incidence_graph)\nclos &lt;- igraph::closeness(incidence_graph)\neig &lt;- eigen_centrality(incidence_graph)$vector\nconst &lt;- constraint(incidence_graph)\ncent_df &lt;- data.frame(types, deg, bet, clos, eig, const)\nhead(cent_df[order(cent_df$deg, decreasing = TRUE),], 10)\n\n                       types deg        bet         clos         eig      const\nTed955 Reilly981        TRUE  17 18288.5694 0.0014025245 1.000000000 0.05882353\nJewel43 Kassulke119     TRUE   9  5293.0889 0.0010405827 0.122089385 0.11111111\nRamon749 Kozey370      FALSE   8  5920.4667 0.0011904762 0.314695380 0.12500000\nSabine292 Feil794      FALSE   7  8039.1255 0.0012135922 0.284892155 0.14285714\nTomika243 Walker122    FALSE   7   927.8167 0.0006793478 0.001624020 0.14285714\nGordon377 Marquardt819 FALSE   6  2112.5000 0.0011135857 0.284460108 0.16666667\nLan153 Schmidt332      FALSE   6   941.7033 0.0008726003 0.035407942 0.16666667\nStanley702 Cremin516   FALSE   6   823.4333 0.0006784261 0.001472952 0.16666667\nCortez851 Price929      TRUE   6  4823.0333 0.0007843137 0.004928315 0.16666667\nAnderson154 Lemke654    TRUE   6  2266.9251 0.0009569378 0.231038624 0.16666667\n\n#provider only\npro_cent_df &lt;- cent_df %&gt;%\n  filter(types ==\"TRUE\")\nhead(pro_cent_df[order(pro_cent_df$deg, decreasing = TRUE),], 10)\n\n                      types deg         bet         clos         eig      const\nTed955 Reilly981       TRUE  17 18288.56945 0.0014025245 1.000000000 0.05882353\nJewel43 Kassulke119    TRUE   9  5293.08892 0.0010405827 0.122089385 0.11111111\nCortez851 Price929     TRUE   6  4823.03333 0.0007843137 0.004928315 0.16666667\nAnderson154 Lemke654   TRUE   6  2266.92508 0.0009569378 0.231038624 0.16666667\nRandy380 Bergstrom287  TRUE   6   592.40699 0.0009354537 0.351045458 0.16666667\nKarla801 Cummerata161  TRUE   4   962.23333 0.0009149131 0.150977394 0.25000000\nThanh759 Weber641      TRUE   4   123.18801 0.0007446016 0.023410004 0.25000000\nMertie42 Lakin515      TRUE   4   673.44586 0.0007733952 0.036012291 0.25000000\nFidel864 Swift555      TRUE   3    39.28333 0.0006779661 0.009873917 0.33333333\nVirgen207 Hyatt152     TRUE   3   664.43333 0.0009132420 0.058784103 0.33333333\n\nsummary(pro_cent_df)\n\n  types              deg              bet                clos          \n Mode:logical   Min.   : 1.000   Min.   :    0.00   Min.   :0.0004787  \n TRUE:222       1st Qu.: 1.000   1st Qu.:    0.00   1st Qu.:0.0006925  \n                Median : 1.000   Median :    0.00   Median :0.0009033  \n                Mean   : 1.536   Mean   :  239.29   Mean   :0.0343315  \n                3rd Qu.: 2.000   3rd Qu.:    8.95   3rd Qu.:0.0541667  \n                Max.   :17.000   Max.   :18288.57   Max.   :0.2000000  \n      eig               const        \n Min.   :0.000000   Min.   :0.05882  \n 1st Qu.:0.000000   1st Qu.:0.50000  \n Median :0.003459   Median :1.00000  \n Mean   :0.026668   Mean   :0.82997  \n 3rd Qu.:0.047516   3rd Qu.:1.00000  \n Max.   :1.000000   Max.   :1.00000  \n\n#patient only\npat_cent_df &lt;- cent_df %&gt;%\n  filter(types ==\"FALSE\")\nhead(pat_cent_df[order(pat_cent_df$deg, decreasing = TRUE),], 10)\n\n                        types deg       bet         clos         eig     const\nRamon749 Kozey370       FALSE   8 5920.4667 0.0011904762 0.314695380 0.1250000\nSabine292 Feil794       FALSE   7 8039.1255 0.0012135922 0.284892155 0.1428571\nTomika243 Walker122     FALSE   7  927.8167 0.0006793478 0.001624020 0.1428571\nGordon377 Marquardt819  FALSE   6 2112.5000 0.0011135857 0.284460108 0.1666667\nLan153 Schmidt332       FALSE   6  941.7033 0.0008726003 0.035407942 0.1666667\nStanley702 Cremin516    FALSE   6  823.4333 0.0006784261 0.001472952 0.1666667\nCarl856 Rempel203       FALSE   5  830.0000 0.0008605852 0.030456389 0.2000000\nChanell45 Morissette863 FALSE   5  704.1182 0.0008620690 0.034515722 0.2000000\nCherise743 Prosacco716  FALSE   5  618.7667 0.0006775068 0.001379585 0.2000000\nCindi877 Hane680        FALSE   5  219.5667 0.0007727975 0.099507009 0.2000000\n\nsummary(pat_cent_df)\n\n   types              deg             bet              clos          \n Mode :logical   Min.   :2.000   Min.   :   0.5   Min.   :0.0005319  \n FALSE:86        1st Qu.:3.000   1st Qu.:  15.0   1st Qu.:0.0007770  \n                 Median :4.000   Median : 422.6   Median :0.0008897  \n                 Mean   :3.965   Mean   : 727.9   Mean   :0.0453422  \n                 3rd Qu.:4.000   3rd Qu.: 708.9   3rd Qu.:0.0666667  \n                 Max.   :8.000   Max.   :8039.1   Max.   :0.3333333  \n      eig              const       \n Min.   :0.00000   Min.   :0.1250  \n 1st Qu.:0.00000   1st Qu.:0.2500  \n Median :0.01549   Median :0.2500  \n Mean   :0.07111   Mean   :0.2712  \n 3rd Qu.:0.06090   3rd Qu.:0.3333  \n Max.   :0.36702   Max.   :0.5000  \n\n\n\nV(incidence_graph)$size &lt;- igraph::degree(incidence_graph)\n\n# set the seed to reproduce the plot layout\nset.seed( 235 )\n\nplot(incidence_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.color = vertex_colors,\n     edge.color = \"gray\",\n     edge.label = NA,\n     vertex.label = NA,\n     main = \"Patient Provider Incidence Graph with Degree Information\")\n# Define legend for vertex colors\nlegend(\"bottomright\",\n       legend = c(\"Female\", \"Male\"),  # You can customize these labels\n       fill = c(\"pink\", \"turquoise\"),   # Fill colors corresponding to vertex colors\n       title = \"Nodes: Gender\")              # Legend title\n\n# Define legend for vertex shapes\nlegend(\"topright\",\n       legend = c(\"Patient\", \"Provider\"),  # You can customize these labels\n       pch = c(1, 0),                      # Point shapes corresponding to vertex shapes\n       title = \"Nodes: Who\")                     # Legend title\n\n# Define legend for edge colors\nlegend(\"topleft\", \n       legend = \"Vertex Size\", \n       pch = 1, \n       pt.cex = seq(0.5, 3, length.out = 5), \n       title = \"Degree\")\n\n\n\n\nHere we can see there is one Provider that sees the most patients, with degree centrality = 28. The next largest degree centrality are in the 5 to 7 range and the majority of those nodes are patients.\n\nV(incidence_graph)$size &lt;- igraph::closeness(incidence_graph)\n\n# set the seed to reproduce the plot layout\nset.seed( 235 )\n\nplot(incidence_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.color = vertex_colors,\n     edge.color = \"gray\",\n     edge.label = NA,\n     vertex.label = NA,\n     main = \"Patient Provider Incidence Graph with Closeness Information\")\n# Define legend for vertex colors\nlegend(\"bottomright\",\n       legend = c(\"Female\", \"Male\"),  # You can customize these labels\n       fill = c(\"magenta\", \"blue\"),   # Fill colors corresponding to vertex colors\n       title = \"Nodes: Gender\")              # Legend title\n\n# Define legend for vertex shapes\nlegend(\"topright\",\n       legend = c(\"Patient\", \"Provider\"),  # You can customize these labels\n       pch = c(1, 0),                      # Point shapes corresponding to vertex shapes\n       title = \"Nodes: Who\")                     # Legend title\n\n# Define legend for edge colors\nlegend(\"topleft\", \n       legend = \"Vertex Size\", \n       pch = 1, \n       pt.cex = seq(0.5, 3, length.out = 5), \n       title = \"Closeness\")\n\n\n\n\nHere we see two of the dyads on the outer right side of this incidence graph have the largest closeness score. This is because their network is complete (they are both connected to one another)."
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html",
    "href": "posts/Post_One - Copy/post_1_drug.html",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "",
    "text": "Research Question\nDoes the demographic profile, including factors such as marital status, gender, and income, significantly impact the utilization of healthcare services among people who use drugs (PWUD), and does it influence the structure and strength of social network connections between PWUD and healthcare providers?\nHypothesis\nData Collection\nData for this project were taken from Synthetic Mass, which creates Synthetic patient data from Synthea.\nCriteria for patient download will be set to include patients that have experienced overdose, substance use treatment, and have other indicators in their health records that could be considered substance use.\nWhile a whole host of datasets are available within each download, I will focus this project on three datasets: patients.csv, providers.csv, and encounters.csv.\nData Cleaning\nData for this project will be read in, reduced to only necessary data, cleaned (trim ws, recode variables, match across datasets, and other data cleaning processes)\nData Analysis\nAnalysis will primarily be of a two-mode network, developing an analysis of the patient-provider relationship. Weights will be assigned to the number of visits between patients and providers. Block Modeling analysis will be performed in one-mode networks of patient or providers to understand the structure of the networks. Blocks will be assigned to patients and providers as an attribute for analysis.\nCleaning\nThis post will primarily focus on data cleaning and data exploration with some exploration into social network analysis through transforming the data into an incidence matrix and plotting some attributes.\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(statnet)\nlibrary(ggplot2)\nlibrary(patchwork)"
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html#patient-data",
    "href": "posts/Post_One - Copy/post_1_drug.html#patient-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "PATIENT DATA",
    "text": "PATIENT DATA\nThe following table is the data available in the patient dataset.\n\npatients &lt;- read_csv(\"synthea_sample_data_csv_latest/patients.csv\")\n\nRows: 86 Columns: 27\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (19): Id, SSN, DRIVERS, PASSPORT, PREFIX, FIRST, LAST, SUFFIX, MAIDEN, ...\ndbl   (6): FIPS, LAT, LON, HEALTHCARE_EXPENSES, HEALTHCARE_COVERAGE, INCOME\ndate  (2): BIRTHDATE, DEATHDATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhead(patients)\n\n# A tibble: 6 × 27\n  Id      BIRTHDATE  DEATHDATE SSN    DRIVERS PASSPORT PREFIX FIRST LAST  SUFFIX\n  &lt;chr&gt;   &lt;date&gt;     &lt;date&gt;    &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; \n1 fd7d27… 1986-07-11 NA        999-5… S99942… X400041… Mrs.   Anni… Glea… &lt;NA&gt;  \n2 cb36b3… 1958-12-12 NA        999-7… S99991… X680941… Mrs.   Juli… Barr… &lt;NA&gt;  \n3 757603… 1977-08-09 NA        999-7… S99974… X378787… Mrs.   Ales… Hean… &lt;NA&gt;  \n4 a970cc… 1997-07-04 NA        999-8… S99937… X401363… Ms.    Sand… Rice… &lt;NA&gt;  \n5 298741… 1979-05-05 NA        999-2… S99988… X201473… Mrs.   Mia3… Runt… &lt;NA&gt;  \n6 0863bd… 1997-11-12 NA        999-8… S99962… X675884… Mr.    Dami… Dach… &lt;NA&gt;  \n# ℹ 17 more variables: MAIDEN &lt;chr&gt;, MARITAL &lt;chr&gt;, RACE &lt;chr&gt;,\n#   ETHNICITY &lt;chr&gt;, GENDER &lt;chr&gt;, BIRTHPLACE &lt;chr&gt;, ADDRESS &lt;chr&gt;, CITY &lt;chr&gt;,\n#   STATE &lt;chr&gt;, COUNTY &lt;chr&gt;, FIPS &lt;dbl&gt;, ZIP &lt;chr&gt;, LAT &lt;dbl&gt;, LON &lt;dbl&gt;,\n#   HEALTHCARE_EXPENSES &lt;dbl&gt;, HEALTHCARE_COVERAGE &lt;dbl&gt;, INCOME &lt;dbl&gt;\n\n\n\nstr(patients)\n\nspc_tbl_ [86 × 27] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Id                 : chr [1:86] \"fd7d2777-0aa7-4495-7355-7d57087f73b1\" \"cb36b365-bfa5-aa61-3240-ed97d2c7b7fa\" \"75760354-5f22-c391-cb3a-f7523b73277d\" \"a970cca2-8c88-a67a-8675-00aa26069356\" ...\n $ BIRTHDATE          : Date[1:86], format: \"1986-07-11\" \"1958-12-12\" ...\n $ DEATHDATE          : Date[1:86], format: NA NA ...\n $ SSN                : chr [1:86] \"999-54-2711\" \"999-75-6253\" \"999-70-3855\" \"999-86-9249\" ...\n $ DRIVERS            : chr [1:86] \"S99942559\" \"S99991886\" \"S99974938\" \"S99937640\" ...\n $ PASSPORT           : chr [1:86] \"X40004111X\" \"X68094169X\" \"X37878770X\" \"X40136308X\" ...\n $ PREFIX             : chr [1:86] \"Mrs.\" \"Mrs.\" \"Mrs.\" \"Ms.\" ...\n $ FIRST              : chr [1:86] \"Annice210\" \"Julianne852\" \"Alesha810\" \"Sandee884\" ...\n $ LAST               : chr [1:86] \"Gleason633\" \"Barrows492\" \"Heaney114\" \"Rice937\" ...\n $ SUFFIX             : chr [1:86] NA NA NA NA ...\n $ MAIDEN             : chr [1:86] \"Koss676\" \"Jacobs452\" \"Labadie908\" NA ...\n $ MARITAL            : chr [1:86] \"M\" \"W\" \"D\" NA ...\n $ RACE               : chr [1:86] \"white\" \"white\" \"white\" \"white\" ...\n $ ETHNICITY          : chr [1:86] \"nonhispanic\" \"nonhispanic\" \"nonhispanic\" \"nonhispanic\" ...\n $ GENDER             : chr [1:86] \"F\" \"F\" \"F\" \"F\" ...\n $ BIRTHPLACE         : chr [1:86] \"Wrentham  Massachusetts  US\" \"Yarmouth Port  Massachusetts  US\" \"East Harwich  Massachusetts  US\" \"Springfield  Massachusetts  US\" ...\n $ ADDRESS            : chr [1:86] \"288 Steuber Landing Suite 38\" \"782 Lynch Dale\" \"415 Emmerich Trail\" \"726 Harvey Throughway\" ...\n $ CITY               : chr [1:86] \"Brookline\" \"Hamilton\" \"Framingham\" \"Taunton\" ...\n $ STATE              : chr [1:86] \"Massachusetts\" \"Massachusetts\" \"Massachusetts\" \"Massachusetts\" ...\n $ COUNTY             : chr [1:86] \"Norfolk County\" \"Essex County\" \"Middlesex County\" \"Bristol County\" ...\n $ FIPS               : num [1:86] 25021 NA 25017 25005 NA ...\n $ ZIP                : chr [1:86] \"02446\" \"00000\" \"01701\" \"02767\" ...\n $ LAT                : num [1:86] 42.4 42.6 42.2 41.9 42.6 ...\n $ LON                : num [1:86] -71.1 -70.8 -71.5 -71.1 -71.4 ...\n $ HEALTHCARE_EXPENSES: num [1:86] 13891 1027127 1021095 80365 577671 ...\n $ HEALTHCARE_COVERAGE: num [1:86] 550582 224662 180027 159483 691055 ...\n $ INCOME             : num [1:86] 1565 39537 114339 96256 71238 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Id = col_character(),\n  ..   BIRTHDATE = col_date(format = \"\"),\n  ..   DEATHDATE = col_date(format = \"\"),\n  ..   SSN = col_character(),\n  ..   DRIVERS = col_character(),\n  ..   PASSPORT = col_character(),\n  ..   PREFIX = col_character(),\n  ..   FIRST = col_character(),\n  ..   LAST = col_character(),\n  ..   SUFFIX = col_character(),\n  ..   MAIDEN = col_character(),\n  ..   MARITAL = col_character(),\n  ..   RACE = col_character(),\n  ..   ETHNICITY = col_character(),\n  ..   GENDER = col_character(),\n  ..   BIRTHPLACE = col_character(),\n  ..   ADDRESS = col_character(),\n  ..   CITY = col_character(),\n  ..   STATE = col_character(),\n  ..   COUNTY = col_character(),\n  ..   FIPS = col_double(),\n  ..   ZIP = col_character(),\n  ..   LAT = col_double(),\n  ..   LON = col_double(),\n  ..   HEALTHCARE_EXPENSES = col_double(),\n  ..   HEALTHCARE_COVERAGE = col_double(),\n  ..   INCOME = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nsummary(patients)\n\n      Id              BIRTHDATE            DEATHDATE         \n Length:86          Min.   :1918-12-18   Min.   :1980-02-04  \n Class :character   1st Qu.:1956-09-07   1st Qu.:1999-02-19  \n Mode  :character   Median :1973-07-22   Median :2007-02-09  \n                    Mean   :1971-05-21   Mean   :2005-05-07  \n                    3rd Qu.:1987-07-27   3rd Qu.:2016-01-04  \n                    Max.   :2004-12-24   Max.   :2021-09-26  \n                                         NA's   :73          \n     SSN              DRIVERS            PASSPORT            PREFIX         \n Length:86          Length:86          Length:86          Length:86         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    FIRST               LAST              SUFFIX             MAIDEN         \n Length:86          Length:86          Length:86          Length:86         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   MARITAL              RACE            ETHNICITY            GENDER         \n Length:86          Length:86          Length:86          Length:86         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  BIRTHPLACE          ADDRESS              CITY              STATE          \n Length:86          Length:86          Length:86          Length:86         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    COUNTY               FIPS           ZIP                 LAT       \n Length:86          Min.   :25001   Length:86          Min.   :41.55  \n Class :character   1st Qu.:25009   Class :character   1st Qu.:41.95  \n Mode  :character   Median :25017   Mode  :character   Median :42.31  \n                    Mean   :25015                      Mean   :42.21  \n                    3rd Qu.:25021                      3rd Qu.:42.46  \n                    Max.   :25027                      Max.   :42.82  \n                    NA's   :21                                        \n      LON         HEALTHCARE_EXPENSES HEALTHCARE_COVERAGE     INCOME      \n Min.   :-73.09   Min.   :   9291     Min.   :      0     Min.   :  1565  \n 1st Qu.:-71.45   1st Qu.:  39582     1st Qu.:  65610     1st Qu.: 30205  \n Median :-71.14   Median : 108692     Median : 322025     Median : 69924  \n Mean   :-71.27   Mean   : 206222     Mean   : 471978     Mean   :161151  \n 3rd Qu.:-70.97   3rd Qu.: 262415     3rd Qu.: 690279     3rd Qu.:128855  \n Max.   :-70.17   Max.   :1058955     Max.   :1893513     Max.   :840567  \n                                                                          \n\n\n\n#create NAME column combining FIRST and LAST names\npatients &lt;- patients %&gt;%\n    rename(PATIENT = Id) %&gt;%\n  unite(NAME, FIRST, LAST, sep = \" \")\n\n#trim whitespace NAME\npatients$NAME &lt;- trimws(patients$NAME)\n\n#trim whitespace COUNTY\npatients$CITY &lt;- trimws(patients$CITY)\n\n#clean up GENDER, RACE, ETHNICITY, and INCOME sections\npatients &lt;- patients %&gt;%\n  mutate(\n    GENDER = tolower(GENDER),\n    GENDER = case_when(\n      GENDER %in% c(\"male\", \"m\", \"man\") ~ \"Male\",\n      GENDER %in% c(\"female\", \"f\", \"woman\") ~ \"Female\",\n      TRUE ~ NA_character_  # assign NA to any non-standard values\n    ),\n# city (patient)\n    CITY =tolower(CITY),\n# race (patient)\n    RACE = tolower(RACE),  # convert race to lower case for consistency\n\n# ethnicity (patient)\n    ETHNICITY = tolower(ETHNICITY),  # convert ethnicity to lower case for consistency\n\n# marital (patient)\n    MARITAL = ifelse(MARITAL == \"M\", \"Married\",\n                    ifelse(MARITAL == \"D\", \"Divorced\",\n                    ifelse(MARITAL == \"W\", \"Widowed\",\n                    ifelse(MARITAL == \"S\", \"Single\", MARITAL)))),\n\n# income (patient)\n    INCOME = as.numeric(INCOME)  # convert income to numeric if necessary\n  ) %&gt;%\n  drop_na(GENDER, RACE) \n\nI am only keeping the demographic data below (gender, race, marital status, income, and age) which will be used as an attribute for each patient.\n\n#Create AGE from BIRTHDATE\npatients &lt;- patients %&gt;%\n  mutate(\n    BIRTHDATE = as.Date(BIRTHDATE),  # Ensure 'dob' is in Date format\n    AGE = interval(BIRTHDATE, today()) / years(1)  # Calculate age in years\n  ) %&gt;%\n  mutate(\n    AGE = floor(AGE)  # complete years only, removing decimal\n  )\n# Only keep patient name and demographics. This will be utilized as the attribute data for analysis.\npat_attr &lt;- patients%&gt;% \n  select(NAME, GENDER, RACE, MARITAL, CITY, INCOME, AGE)\nhead(pat_attr)\n\n# A tibble: 6 × 7\n  NAME                   GENDER RACE  MARITAL  CITY       INCOME   AGE\n  &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Annice210 Gleason633   Female white Married  brookline    1565    37\n2 Julianne852 Barrows492 Female white Widowed  hamilton    39537    65\n3 Alesha810 Heaney114    Female white Divorced framingham 114339    46\n4 Sandee884 Rice937      Female white &lt;NA&gt;     taunton     96256    26\n5 Mia349 Runte676        Female white Divorced chelmsford  71238    44\n6 Damian46 Dach178       Male   white &lt;NA&gt;     swansea     74155    26\n\n\n\npat_race &lt;- ggplot(pat_attr,aes(RACE)) + geom_bar()\npat_gender &lt;- ggplot(pat_attr,aes(GENDER)) + geom_bar()\n\npat_race + pat_gender + plot_annotation(title = \"Patient Race and Gender Breakdown\")\n\n\n\nggplot(pat_attr,aes(MARITAL)) + geom_bar() + labs(title = \"Patient Marital Status\")\n\n\n\npat_income &lt;- ggplot(pat_attr, aes(x = 1, y = INCOME)) +\n    geom_jitter(width = 0.2) +\n    labs(x = NULL, y = \"Income\") +\n    theme_minimal() + labs(title = \"Patient Income\")\n\nsummary(pat_attr$INCOME)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1565   30205   69924  161151  128855  840567 \n\npat_age &lt;- ggplot(pat_attr,aes(AGE)) + geom_bar()\n\nggplot(data = patients %&gt;% \n         count(CITY) %&gt;% \n         filter(n &gt; 2),  # Filter for counts higher than 10\n       aes(x = CITY, y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + labs(title = paste(\"Patients Cities\", \"\\n*filtered to show &gt;2 Patients per City\"))"
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html#provider-data",
    "href": "posts/Post_One - Copy/post_1_drug.html#provider-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "PROVIDER DATA",
    "text": "PROVIDER DATA\nThe following table is the data available in the provider dataset.\n\nproviders &lt;- read_csv(\"synthea_sample_data_csv_latest/providers.csv\") %&gt;%\n    rename(PROVIDER = Id)\n\nRows: 815 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (9): Id, ORGANIZATION, NAME, GENDER, SPECIALITY, ADDRESS, CITY, STATE, ZIP\ndbl (4): LAT, LON, ENCOUNTERS, PROCEDURES\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(providers)\n\n# A tibble: 6 × 13\n  PROVIDER  ORGANIZATION NAME  GENDER SPECIALITY ADDRESS CITY  STATE ZIP     LAT\n  &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 86726ad9… 74ab949d-17… Ted9… M      GENERAL P… 881 Ma… Fitc… MA    01420  42.6\n2 47fdff5b… 588f6ce6-b8… Tiff… F      GENERAL P… 461 WA… JAMA… MA    0213…  42.3\n3 b31700a0… 324b4137-57… Herm… F      GENERAL P… 134 NO… NORT… MA    0186…  42.6\n4 0ada8fec… b6398e07-49… Shan… M      GENERAL P… 19 TAC… WORC… MA    0160…  42.3\n5 31214beb… faffaf6a-ee… Jaun… F      GENERAL P… 66 WAS… STOU… MA    0207…  42.1\n6 38a7cc67… 17a4bae5-8b… Olym… F      GENERAL P… 512 MA… SHRE… MA    0154…  42.3\n# ℹ 3 more variables: LON &lt;dbl&gt;, ENCOUNTERS &lt;dbl&gt;, PROCEDURES &lt;dbl&gt;\n\n\nI am only keeping the demographic data below (gender) which will be used as an attribute for each provider.\n\n#trim whitespace NAME\nproviders$NAME &lt;- trimws(providers$NAME)\nproviders &lt;- providers %&gt;%\n  mutate(\n    GENDER = tolower(GENDER),\n    GENDER = case_when(\n      GENDER %in% c(\"male\", \"m\", \"man\") ~ \"Male\",\n      GENDER %in% c(\"female\", \"f\", \"woman\") ~ \"Female\",\n      TRUE ~ NA_character_  # assign NA to any non-standard values\n    ),\n    CITY =tolower(CITY)\n  )"
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html#encounter-data",
    "href": "posts/Post_One - Copy/post_1_drug.html#encounter-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "ENCOUNTER DATA",
    "text": "ENCOUNTER DATA\n\nencounters &lt;- read_csv(\"synthea_sample_data_csv_latest/encounters.csv\")\n\nRows: 6109 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (8): Id, PATIENT, ORGANIZATION, PROVIDER, PAYER, ENCOUNTERCLASS, DESCRI...\ndbl  (5): CODE, BASE_ENCOUNTER_COST, TOTAL_CLAIM_COST, PAYER_COVERAGE, REASO...\ndttm (2): START, STOP\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(encounters)\n\n# A tibble: 6 × 15\n  Id       START               STOP                PATIENT ORGANIZATION PROVIDER\n  &lt;chr&gt;    &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;   \n1 1b544ce… 2000-11-11 13:33:09 2000-11-11 14:33:09 fd7d27… db28cc9a-fd… 715b985…\n2 0d642d8… 2001-03-30 13:33:09 2001-03-30 14:33:09 fd7d27… db28cc9a-fd… 715b985…\n3 99d190e… 2001-11-28 13:33:09 2001-11-28 14:33:09 fd7d27… db28cc9a-fd… 715b985…\n4 cc07637… 2004-09-03 13:33:09 2004-09-03 14:31:19 fd7d27… 3d5fbf38-c7… 2655ff5…\n5 05a2433… 2005-09-09 13:33:09 2005-09-09 14:16:34 fd7d27… 3d5fbf38-c7… 2655ff5…\n6 8844f58… 2008-09-12 13:33:09 2008-09-12 14:28:22 fd7d27… 3d5fbf38-c7… 2655ff5…\n# ℹ 9 more variables: PAYER &lt;chr&gt;, ENCOUNTERCLASS &lt;chr&gt;, CODE &lt;dbl&gt;,\n#   DESCRIPTION &lt;chr&gt;, BASE_ENCOUNTER_COST &lt;dbl&gt;, TOTAL_CLAIM_COST &lt;dbl&gt;,\n#   PAYER_COVERAGE &lt;dbl&gt;, REASONCODE &lt;dbl&gt;, REASONDESCRIPTION &lt;chr&gt;"
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html#combine-patient-provider-and-encounter-data",
    "href": "posts/Post_One - Copy/post_1_drug.html#combine-patient-provider-and-encounter-data",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "Combine Patient, Provider, and Encounter Data",
    "text": "Combine Patient, Provider, and Encounter Data\nI am taking this step here so that I have a master dataset (encounters_attributes) and so that I can create an edgelist more easily.\n\n# Perform a left join to merge encounters with provider_attributes based on PROVIDER\nencounters_cleaning &lt;- left_join(encounters, providers, by = \"PROVIDER\")\n# Replace the PROVIDER column with the corresponding names from the NAME column\nencounters_cleaning$PROVIDER &lt;- encounters_cleaning$NAME\n# Remove the NAME column if no longer needed\nencounters_cleaning &lt;- encounters_cleaning %&gt;%\n  select(-NAME)\n#Repeat for Provider\nencounters_cleaning &lt;- left_join(encounters_cleaning, patients, by = \"PATIENT\")\nencounters_cleaning$PATIENT &lt;- encounters_cleaning$NAME\nencounters_cleaning &lt;- encounters_cleaning %&gt;%\n  select(-NAME) \n#Clearly identify the Encounter ID\nencounters_cleaning &lt;- encounters_cleaning %&gt;%\n  rename(ENCOUNTER_ID = Id)"
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html#check-dimensions-between-datasets",
    "href": "posts/Post_One - Copy/post_1_drug.html#check-dimensions-between-datasets",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "Check Dimensions between Datasets",
    "text": "Check Dimensions between Datasets\nIn later analysis I noticed that while there are more providers in the provider.csv, than there are providers listed in the encounters.csv. I will clean the data to only include providers that appear in the encounters.csv.\n\ncheck_prov &lt;- encounters_cleaning %&gt;%\n  group_by(PROVIDER, GENDER.x) %&gt;%\n  summarize(COUNT = n())\n\n`summarise()` has grouped output by 'PROVIDER'. You can override using the\n`.groups` argument.\n\ncheck_prov_enc &lt;- providers %&gt;% \n  group_by(NAME, PROVIDER)\n\n\ndim(check_prov)\n\n[1] 222   3\n\ndim(check_prov_enc)\n\n[1] 815  13\n\n\n\n# Perform semi-join to keep providers present in both datasets\nproviders_only_in_providers_df &lt;- check_prov_enc %&gt;%\n  anti_join(check_prov, by = c(\"NAME\" = \"PROVIDER\"))\n\n# Print the dimensions of the filtered dataset\nprint(dim(providers_only_in_providers_df))\n\n[1] 592  13\n\nprint(providers_only_in_providers_df)\n\n# A tibble: 592 × 13\n# Groups:   NAME, PROVIDER [592]\n   PROVIDER ORGANIZATION NAME  GENDER SPECIALITY ADDRESS CITY  STATE ZIP     LAT\n   &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 47fdff5… 588f6ce6-b8… Tiff… Female GENERAL P… 461 WA… jama… MA    0213…  42.3\n 2 b31700a… 324b4137-57… Herm… Female GENERAL P… 134 NO… nort… MA    0186…  42.6\n 3 31214be… faffaf6a-ee… Jaun… Female GENERAL P… 66 WAS… stou… MA    0207…  42.1\n 4 38a7cc6… 17a4bae5-8b… Olym… Female GENERAL P… 512 MA… shre… MA    0154…  42.3\n 5 5b8e0a3… 4112b8b1-59… Ambr… Male   GENERAL P… 37 ROU… sand… MA    0256…  41.8\n 6 5cb9747… e76b5eb0-0c… Gise… Female GENERAL P… 1400 V… west… MA    02132  42.3\n 7 633f248… c241b977-41… Kip4… Male   GENERAL P… 94 MAI… hyan… MA    0260…  41.7\n 8 4886d4a… ef5390b4-cb… Mila… Male   GENERAL P… 360 ME… mald… MA    0214…  42.4\n 9 774bf03… 6fafb5d4-ec… Shel… Female GENERAL P… 320 WE… west… MA    02379  42.0\n10 f4e1828… aa682136-a4… Ánge… Female GENERAL P… 501 CO… norw… MA    0206…  42.2\n# ℹ 582 more rows\n# ℹ 3 more variables: LON &lt;dbl&gt;, ENCOUNTERS &lt;dbl&gt;, PROCEDURES &lt;dbl&gt;\n\n\n\n# Perform anti-join to remove providers only present in check_prov_enc from the original dataset\nproviders_filtered &lt;- providers %&gt;%\n  anti_join(providers_only_in_providers_df, by = c(\"NAME\" = \"NAME\"))\n\n# Print the dimensions of the resulting dataset\nprint(dim(providers_filtered))\n\n[1] 223  13\n\n\nResult is 223, though it should be 222.\n\n# Find duplicate rows based on the NAME column\nduplicate_rows &lt;- providers_filtered[duplicated(providers_filtered$NAME) | duplicated(providers_filtered$NAME, fromLast = TRUE), ]\n\n# Print the duplicate rows\nprint(duplicate_rows %&gt;% select(PROVIDER, CITY))\n\n# A tibble: 2 × 2\n  PROVIDER                             CITY      \n  &lt;chr&gt;                                &lt;chr&gt;     \n1 be12b8b5-2618-3d5e-a976-199d56505cd0 leominster\n2 8e8ca291-3456-359b-9a13-0a6dc7016381 reading   \n\n\nAh Maynard.\n\n# Find duplicate rows based on the NAME column\nMaynard_rows &lt;- encounters_cleaning %&gt;% filter (PROVIDER == \"Maynard46 Buckridge80\")\n\n# Print the duplicate rows\nprint(Maynard_rows %&gt;% group_by(CITY.x)) %&gt;% select(PROVIDER, CITY.x)\n\n# A tibble: 22 × 51\n# Groups:   CITY.x [1]\n   ENCOUNTER_ID   START               STOP                PATIENT ORGANIZATION.x\n   &lt;chr&gt;          &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;         \n 1 a4e40cc3-e8e2… 1958-10-16 18:06:02 1958-10-16 18:51:39 Tommy8… 817f4acb-0184…\n 2 64f7e2f4-4fef… 1960-10-27 18:06:02 1960-10-27 18:47:34 Tommy8… 817f4acb-0184…\n 3 c194d751-9164… 1978-11-16 18:06:02 1978-11-16 18:49:04 Tommy8… 817f4acb-0184…\n 4 8f814ff1-65a5… 1979-11-22 18:06:02 1979-11-22 18:47:03 Tommy8… 817f4acb-0184…\n 5 d99e97ef-b857… 1981-12-03 18:06:02 1981-12-03 19:01:22 Tommy8… 817f4acb-0184…\n 6 c3a214d7-4f71… 1982-12-09 18:06:02 1982-12-09 19:00:00 Tommy8… 817f4acb-0184…\n 7 4a9f1c7b-574c… 1985-12-26 18:06:02 1985-12-26 18:51:22 Tommy8… 817f4acb-0184…\n 8 e8e4f402-08a2… 1987-01-01 18:06:02 1987-01-01 18:46:31 Tommy8… 817f4acb-0184…\n 9 24e91e6e-4ec8… 1989-01-12 18:06:02 1989-01-12 18:38:56 Tommy8… 817f4acb-0184…\n10 83cc31e3-4efc… 1991-01-24 18:06:02 1991-01-24 19:02:22 Tommy8… 817f4acb-0184…\n# ℹ 12 more rows\n# ℹ 46 more variables: PROVIDER &lt;chr&gt;, PAYER &lt;chr&gt;, ENCOUNTERCLASS &lt;chr&gt;,\n#   CODE &lt;dbl&gt;, DESCRIPTION &lt;chr&gt;, BASE_ENCOUNTER_COST &lt;dbl&gt;,\n#   TOTAL_CLAIM_COST &lt;dbl&gt;, PAYER_COVERAGE &lt;dbl&gt;, REASONCODE &lt;dbl&gt;,\n#   REASONDESCRIPTION &lt;chr&gt;, ORGANIZATION.y &lt;chr&gt;, GENDER.x &lt;chr&gt;,\n#   SPECIALITY &lt;chr&gt;, ADDRESS.x &lt;chr&gt;, CITY.x &lt;chr&gt;, STATE.x &lt;chr&gt;,\n#   ZIP.x &lt;chr&gt;, LAT.x &lt;dbl&gt;, LON.x &lt;dbl&gt;, ENCOUNTERS &lt;dbl&gt;, …\n\n\n# A tibble: 22 × 2\n# Groups:   CITY.x [1]\n   PROVIDER              CITY.x \n   &lt;chr&gt;                 &lt;chr&gt;  \n 1 Maynard46 Buckridge80 reading\n 2 Maynard46 Buckridge80 reading\n 3 Maynard46 Buckridge80 reading\n 4 Maynard46 Buckridge80 reading\n 5 Maynard46 Buckridge80 reading\n 6 Maynard46 Buckridge80 reading\n 7 Maynard46 Buckridge80 reading\n 8 Maynard46 Buckridge80 reading\n 9 Maynard46 Buckridge80 reading\n10 Maynard46 Buckridge80 reading\n# ℹ 12 more rows\n\n\nI’ll choose the Maynard in Reading and remove the Maynard in Leominster.\n\nproviders_filtered &lt;- providers_filtered %&gt;%\n  filter(PROVIDER != \"be12b8b5-2618-3d5e-a976-199d56505cd0\")\n# Print the dimensions of the resulting dataset\nprint(dim(providers_filtered))\n\n[1] 222  13\n\n\n\ncheck_pat &lt;- encounters_cleaning %&gt;%\n  group_by(PATIENT, GENDER.y) %&gt;%\n  summarize(COUNT = n())\n\n`summarise()` has grouped output by 'PATIENT'. You can override using the\n`.groups` argument.\n\ncheck_pat_enc &lt;- patients %&gt;%\n  group_by(NAME,PATIENT)\n\n\ndim(check_pat)\n\n[1] 86  3\n\ndim(check_pat_enc)\n\n[1] 86 27\n\n\nPatients have the same dimensions."
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html#patient-data-2",
    "href": "posts/Post_One - Copy/post_1_drug.html#patient-data-2",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "PATIENT DATA 2",
    "text": "PATIENT DATA 2\n\nggplot(providers_filtered, aes(GENDER)) +geom_bar() + labs(title = \"Provider Gender Breakdown\")\n\n\n\nggplot(data = providers_filtered %&gt;% \n         count(CITY) %&gt;% \n         filter(n &gt; 5),  # Filter for counts higher than 10\n       aes(x = CITY, y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + labs(title = paste(\"Provider Cities\", \"\\n*filtered to show &gt;5 Providers per City\"))"
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html#encounter-data-2",
    "href": "posts/Post_One - Copy/post_1_drug.html#encounter-data-2",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "ENCOUNTER DATA 2",
    "text": "ENCOUNTER DATA 2\n\nggplot(encounters, aes(ENCOUNTERCLASS)) + geom_bar() + coord_flip()+ labs(title = \"Type of Visit\")\n\n\n\nggplot(data = encounters %&gt;% \n         count(DESCRIPTION) %&gt;% \n         filter(n &gt; 50),  # Filter for counts higher than 10\n       aes(x = DESCRIPTION, y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + labs(title = paste(\"Visit Description\", \"\\n*filtered to show &gt;50 visits\"))\n\n\n\nggplot(data = encounters %&gt;% \n         count(REASONDESCRIPTION) %&gt;% \n         filter(n &gt; 50),  # Filter for counts higher than 10\n       aes(x = reorder(REASONDESCRIPTION, n), y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + labs(title = paste(\"Reason Patient Visited Provider\", \"\\n*filtered to show &gt;50 visits\"))\n\n\n\n\nAside from NA (which does not stand for Narcotics Anonymous) the most frequent reason a patient visits a provider is for “Dependent drug abuse (disorder)”. This is exactly what I would have anticipated seeing in this dataset, considering I called for only patients with a high likelyhood of being drug dependent.\nThe second most frequent reason for visiting a provider is “Chronic kidney disease stage 4 (disorder)”. One insight I have been given is that kidney disease may involve a lot of trips to the doctors for dialysis. I may look into this dataset to see if I’m right, but this is more a side tangent."
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html#join-datasets",
    "href": "posts/Post_One - Copy/post_1_drug.html#join-datasets",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "Join Datasets",
    "text": "Join Datasets\n\n# Perform a left join to merge encounters with provider_attributes based on PROVIDER\nencounters_cleaned &lt;- left_join(encounters, providers_filtered, by = \"PROVIDER\")\n# Replace the PROVIDER column with the corresponding names from the NAME column\nencounters_cleaned$PROVIDER &lt;- encounters_cleaned$NAME\n# Remove the NAME column if no longer needed\nencounters_cleaned &lt;- encounters_cleaned %&gt;%\n  select(-NAME)\n#Repeat for Provider\nencounters_cleaned &lt;- left_join(encounters_cleaned, patients, by = \"PATIENT\")\nencounters_cleaned$PATIENT &lt;- encounters_cleaned$NAME\nencounters_cleaned &lt;- encounters_cleaned %&gt;%\n  select(-NAME) \n#Clearly identify the Encounter ID\nencounters_cleaned &lt;- encounters_cleaned %&gt;%\n  rename(ENCOUNTER_ID = Id)\n\n\nencounter_attributes &lt;- encounters_cleaned %&gt;%\n  select(ENCOUNTER_ID, PATIENT, PROVIDER, GENDER.x, GENDER.y, RACE, MARITAL, ETHNICITY, INCOME, CITY.x, CITY.y)\n# View the updated dataframe\nhead(encounter_attributes)\n\n# A tibble: 6 × 11\n  ENCOUNTER_ID PATIENT PROVIDER GENDER.x GENDER.y RACE  MARITAL ETHNICITY INCOME\n  &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt;\n1 1b544ceb-bf… Annice… Clement… Male     Female   white Married nonhispa…   1565\n2 0d642d81-96… Annice… Clement… Male     Female   white Married nonhispa…   1565\n3 99d190e1-67… Annice… Clement… Male     Female   white Married nonhispa…   1565\n4 cc076374-d3… Annice… Enrique… Female   Female   white Married nonhispa…   1565\n5 05a24332-4d… Annice… Enrique… Female   Female   white Married nonhispa…   1565\n6 8844f58d-3e… Annice… Enrique… Female   Female   white Married nonhispa…   1565\n# ℹ 2 more variables: CITY.x &lt;chr&gt;, CITY.y &lt;chr&gt;"
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html#edgelist",
    "href": "posts/Post_One - Copy/post_1_drug.html#edgelist",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "EDGELIST",
    "text": "EDGELIST\n\n# Create Edgelist & Assign Weight by Count of Encounter\nencounters_el &lt;- encounter_attributes %&gt;%\n  group_by(PATIENT, PROVIDER) %&gt;%\n  summarize(COUNT = n()) \n\n`summarise()` has grouped output by 'PATIENT'. You can override using the\n`.groups` argument.\n\nhead(encounters_el)\n\n# A tibble: 6 × 3\n# Groups:   PATIENT [2]\n  PATIENT             PROVIDER                  COUNT\n  &lt;chr&gt;               &lt;chr&gt;                     &lt;int&gt;\n1 Adam631 Hoppe518    Elijah719 White193            8\n2 Adam631 Hoppe518    Fidel864 Swift555             2\n3 Adam631 Hoppe518    Virgen207 Hyatt152            3\n4 Adam631 Hoppe518    Zachery872 Pagac496          31\n5 Alesha810 Heaney114 Kristopher775 Schiller186    13\n6 Alesha810 Heaney114 Laine739 Torphy630            4\n\ndim(encounters_el)\n\n[1] 341   3"
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html#combined-attribute-list",
    "href": "posts/Post_One - Copy/post_1_drug.html#combined-attribute-list",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "COMBINED ATTRIBUTE LIST",
    "text": "COMBINED ATTRIBUTE LIST\n\n#combine pro and pat attr\npat_attr$type &lt;- \"PATIENT\"\npro_attr &lt;- providers_filtered %&gt;%\n  select(NAME, GENDER, CITY)\npro_attr$type &lt;- \"PROVIDER\"\nboth_attr &lt;- bind_rows(pat_attr, pro_attr)\nhead(both_attr)\n\n# A tibble: 6 × 8\n  NAME                   GENDER RACE  MARITAL  CITY       INCOME   AGE type   \n  &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  \n1 Annice210 Gleason633   Female white Married  brookline    1565    37 PATIENT\n2 Julianne852 Barrows492 Female white Widowed  hamilton    39537    65 PATIENT\n3 Alesha810 Heaney114    Female white Divorced framingham 114339    46 PATIENT\n4 Sandee884 Rice937      Female white &lt;NA&gt;     taunton     96256    26 PATIENT\n5 Mia349 Runte676        Female white Divorced chelmsford  71238    44 PATIENT\n6 Damian46 Dach178       Male   white &lt;NA&gt;     swansea     74155    26 PATIENT\n\n\n\n#create combined attribute list\nattribute_list &lt;- do.call(list, both_attr)"
  },
  {
    "objectID": "posts/Post_One - Copy/post_1_drug.html#network",
    "href": "posts/Post_One - Copy/post_1_drug.html#network",
    "title": "Data Cleaning, Exploration, and Network Analysis",
    "section": "NETWORK",
    "text": "NETWORK\n\n# create bipartite network with attributes\nencounters.st.3 &lt;- network(encounters_el,\n                         directed = FALSE,\n                         bipartite = TRUE,\n                         matrix.type = \"edgelist\",\n                         vertex.attr = attribute_list)\nencounters.st.3\n\n Network attributes:\n  vertices = 308 \n  directed = FALSE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = 86 \n  total edges= 341 \n    missing edges= 0 \n    non-missing edges= 341 \n\n Vertex attribute names: \n    AGE CITY GENDER INCOME MARITAL NAME RACE type vertex.names \n\n Edge attribute names: \n    COUNT"
  },
  {
    "objectID": "posts/Post_Three - Copy/post_3_drug.html",
    "href": "posts/Post_Three - Copy/post_3_drug.html",
    "title": "Network Block Modeling - Patients",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\n\nThis post will explore the Synthetic Mass network data in more detail.\n\nRead in Data\n\npat_attr &lt;- read_csv(\"post1drug_data/pat_attr.csv\", \n    col_types = cols(...1 = col_skip()))\npro_attr &lt;- read_csv(\"post1drug_data/pro_attr.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaning &lt;- read_csv(\"post1drug_data//encounters_cleaning.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaned &lt;- read_csv(\"post1drug_data//encounters_cleaned.csv\", \n    col_types = cols(...1 = col_skip()))\nencounter_attributes &lt;- read_csv(\"post1drug_data/encounter_attributes.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_el  &lt;- read_csv(\"post1drug_data/encounters_el.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_st_3 &lt;- read_csv(\"post1drug_data/encounters.st.3.csv\", \n    col_types = cols(...1 = col_skip()))\nattribute_list &lt;- read.csv(\"post1drug_data/attribute_list.csv\")\n\n\n\nCreate bipartite network with attributes\n\nencounters.stat &lt;- network(encounters_el,\n                         directed = FALSE,\n                         bipartite = TRUE,\n                         matrix.type = \"edgelist\",\n                         vertex.attr = attribute_list)\n\n\n#create igraph\nencounters.ig &lt;- graph_from_biadjacency_matrix(encounters.stat)\n\n\nencounters.stat2 &lt;- asNetwork(encounters.ig)\n\n\nprojected_graph &lt;- bipartite_projection(encounters.ig)\npatient_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj1))\n\npatient.stat &lt;- asNetwork(projected_graph$proj1)\n\npatient.se &lt;- equiv.clust(patient_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\nnames(patient.se)\n\n[1] \"cluster\"        \"metric\"         \"equiv.fun\"      \"cluster.method\"\n[5] \"glabels\"        \"plabels\"       \n\n\n\nplot(patient.se, main = \"patient\")\nrect.hclust(patient.se$cluster, k = 6)\n\n\n\n\n\npat_blk_model.patient.org &lt;- blockmodel(patient_matrix,\n patient.se, k = 6)\n\n\n pat_blk_model.patient.org$block.model\n\n            Block 1    Block 2   Block 3     Block 4   Block 5 Block 6\nBlock 1 0.019557823 0.02678571 0.0127551 0.006802721 0.0000000       0\nBlock 2 0.026785714 1.00000000 0.0000000 0.010416667 0.1458333       1\nBlock 3 0.012755102 0.00000000 1.0000000 0.000000000 0.0625000       1\nBlock 4 0.006802721 0.01041667 0.0000000 1.000000000 0.0000000       0\nBlock 5 0.000000000 0.14583333 0.0625000 0.000000000 0.6000000       0\nBlock 6 0.000000000 1.00000000 1.0000000 0.000000000 0.0000000     NaN\n\n\n\nplot.block&lt;-function(x=pat_blk_mod, main=NULL, cex.lab=.00001,show_labels = FALSE){\n plot.sociomatrix(x$blocked.data, labels=list(x$plabels,x$plabels),\n main=main, drawlines = FALSE, cex.lab=cex.lab)\n for (j in 2:length(x$plabels)) if (x$block.membership[j] !=\n x$block.membership[j-1])\n abline(v = j- 0.5, h = j- 0.5, lty = 3, xpd=FALSE)\n }\n \nplot.block(pat_blk_model.patient.org, main = \"patient\")\n\n\n\n\n\n#pat_blks6 &lt;- blockmodeling::optRandomParC(patient_matrix,k=6, rep=20, approaches=\"ss\", blocks=\"com\")\n\n\n# Save the blks2 object to a file\n#saveRDS(pat_blks6, \"pat_blks6_results.rds\")\n\n# Later, when you want to use it again, you can read it back into R\npat_blks6 &lt;- readRDS(\"pat_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\npat_blk_mod &lt;- blockmodel(patient_matrix, pat_blks6$best$best1$clu,\n                      plabels = rownames(patient_matrix))\n# print blockmodel object\npat_blk_mod$block.model\n\n        Block 1    Block 2    Block 3     Block 4    Block 5     Block 6\nBlock 1       1 1.00000000 0.00000000 0.000000000 1.00000000 0.000000000\nBlock 2       1 0.70000000 0.05000000 0.000000000 0.05333333 0.008000000\nBlock 3       0 0.05000000 1.00000000 0.000000000 0.06666667 0.015000000\nBlock 4       0 0.00000000 0.00000000 1.000000000 0.01111111 0.006666667\nBlock 5       1 0.05333333 0.06666667 0.011111111 1.00000000 0.028000000\nBlock 6       0 0.00800000 0.01500000 0.006666667 0.02800000 0.018775510\n\n\n#assign attributes\n\nglimpse(pat_blk_mod)\n\nList of 11\n $ block.membership: int [1:86] 1 1 2 2 2 2 2 3 3 3 ...\n $ order.vector    : int [1:86] 31 67 19 28 63 75 85 8 9 10 ...\n $ block.content   : chr \"density\"\n $ blocked.data    : num [1:86, 1:86] 0 1 1 1 1 1 1 0 0 0 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:86] \"Johnnie679 Hand679\" \"Rudy520 Hettinger594\" \"Dortha70 Rutherford999\" \"Ivan258 Hills818\" ...\n  .. ..$ : chr [1:86] \"Johnnie679 Hand679\" \"Rudy520 Hettinger594\" \"Dortha70 Rutherford999\" \"Ivan258 Hills818\" ...\n $ block.model     : num [1:6, 1:6] 1 1 0 0 1 0 1 0.7 0.05 0 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n  .. ..$ : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n $ plabels         : chr [1:86] \"Johnnie679 Hand679\" \"Rudy520 Hettinger594\" \"Dortha70 Rutherford999\" \"Ivan258 Hills818\" ...\n $ glabels         : int [1:86] 1 2 3 4 5 6 7 8 9 10 ...\n $ rlabels         : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n $ cluster.method  : chr \"Prespecified\"\n $ equiv.fun       : chr \"None\"\n $ equiv.metric    : chr \"None\"\n - attr(*, \"class\")= chr \"blockmodel\"\n\n\n\npat_attr$block &lt;- pat_blk_mod$block.membership\nhead(pat_attr)\n\n# A tibble: 6 × 9\n  NAME                   GENDER RACE  MARITAL  CITY     INCOME   AGE type  block\n  &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt;\n1 Annice210 Gleason633   Female white Married  brookli…   1565    37 PATI…     1\n2 Julianne852 Barrows492 Female white Widowed  hamilton  39537    65 PATI…     1\n3 Alesha810 Heaney114    Female white Divorced framing… 114339    46 PATI…     2\n4 Sandee884 Rice937      Female white &lt;NA&gt;     taunton   96256    26 PATI…     2\n5 Mia349 Runte676        Female white Divorced chelmsf…  71238    44 PATI…     2\n6 Damian46 Dach178       Male   white &lt;NA&gt;     swansea   74155    26 PATI…     2\n\n#write.csv(pat_attr, \"pat_attr.csv\")\n\n\nplot.block(pat_blk_mod, main = \"patient\",\n           cex.lab = .000001)\n\n\n\n\n\n#assign block membership to vertex attribute\npatient.stat%v%\"role\"&lt;-pat_blk_mod$block.membership[match(patient.stat%v%\"vertex.names\",pat_blk_mod$plabels)]\n#plot network using \"role\" to color nodes\nGGally::ggnet2(patient.stat,\n               node.color=\"role\", \n               node.size=sna::degree(patient.stat, gmode=\"graph\"),\n               node.alpha = .5)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\n\n\nlibrary(ade4)\n\nWarning: package 'ade4' was built under R version 4.3.3\n\n\n\nencounters.adj.ig &lt;- igraph::as_biadjacency_matrix(encounters.ig)\n\npatients_jaccard &lt;- dist.binary(encounters.adj.ig,\n            method = 1, # method=1 Jaccard index\n            upper = TRUE,\n            diag = FALSE)\n\npatients_jaccard &lt;- as.matrix(patients_jaccard)\ndiag(patients_jaccard) &lt;- 0\n\n\n#binarize\npatients_jaccard_bi &lt;- ifelse(patients_jaccard &gt; 0.99, 1, 0)\n\n\n#create igraph object\npatients_jaccard.ig &lt;- graph_from_adjacency_matrix(patients_jaccard_bi, mode = \"undirected\")\nsummary(patients_jaccard.ig)\n\nIGRAPH 905f5e9 UN-- 86 3390 -- \n+ attr: name (v/c)\n\n\n\nplot(patients_jaccard.ig,  edge.width = 0.0002, edge.color = \"lightgray\",  vertex.size = 2, vertex.label = NA)\n\n\n\n\n\n# Load the igraph package\nlibrary(igraph)\n\n# Create an igraph object from the blockmodel\ng &lt;- graph_from_adjacency_matrix(patient_matrix, mode = \"undirected\", weighted = FALSE)\n\n# Plot the graph without labels\nplot(g,      \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 2, \n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Patient Network\")"
  },
  {
    "objectID": "posts/Post_Four - Copy/post_4_drug.html",
    "href": "posts/Post_Four - Copy/post_4_drug.html",
    "title": "Network Block Modeling - Providers",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\n\nThis post will explore the Synthetic Mass network data in more detail.\n\nRead in Data\n\npat_attr &lt;- read_csv(\"post1drug_data/pat_attr.csv\", \n    col_types = cols(...1 = col_skip()))\npro_attr &lt;- read_csv(\"post1drug_data/pro_attr.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaning &lt;- read_csv(\"post1drug_data//encounters_cleaning.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaned &lt;- read_csv(\"post1drug_data//encounters_cleaned.csv\", \n    col_types = cols(...1 = col_skip()))\nencounter_attributes &lt;- read_csv(\"post1drug_data/encounter_attributes.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_el  &lt;- read_csv(\"post1drug_data/encounters_el.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_st_3 &lt;- read_csv(\"post1drug_data/encounters.st.3.csv\", \n    col_types = cols(...1 = col_skip()))\nattribute_list &lt;- read.csv(\"post1drug_data/attribute_list.csv\")\n\n\n\nCreate bipartite network with attributes\n\nencounters.stat &lt;- network(encounters_el,\n                         directed = FALSE,\n                         bipartite = TRUE,\n                         matrix.type = \"edgelist\",\n                         vertex.attr = attribute_list)\n\n\n#create igraph\nencounters.ig &lt;- graph_from_biadjacency_matrix(encounters.stat)\n\n\nencounters.stat2 &lt;- asNetwork(encounters.ig)\n\n\nprojected_graph &lt;- bipartite_projection(encounters.ig)\nprovider_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj2))\n\nprovider.stat &lt;- asNetwork(projected_graph$proj2)\n\nprovider.se &lt;- equiv.clust(provider_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\nnames(provider.se)\n\n[1] \"cluster\"        \"metric\"         \"equiv.fun\"      \"cluster.method\"\n[5] \"glabels\"        \"plabels\"       \n\n\n\nplot(provider.se, main = \"provider\")\nrect.hclust(provider.se$cluster, k = 12)\n\n\n\n\n\nblk_model.provider.org &lt;- blockmodel(provider_matrix,\n provider.se, k = 6)\n\n\n blk_model.provider.org$block.model\n\n            Block 1   Block 2   Block 3     Block 4     Block 5    Block 6\nBlock 1 0.017318436 0.2444444 0.1222222 0.002222222 0.002046784 0.01481481\nBlock 2 0.244444444       NaN 1.0000000 0.000000000 0.210526316 1.00000000\nBlock 3 0.122222222 1.0000000       NaN 0.000000000 0.315789474 0.00000000\nBlock 4 0.002222222 0.0000000 0.0000000 0.466666667 0.000000000 0.01111111\nBlock 5 0.002046784 0.2105263 0.3157895 0.000000000 0.239766082 0.00000000\nBlock 6 0.014814815 1.0000000 0.0000000 0.011111111 0.000000000 1.00000000\n\n\n\nplot.block&lt;-function(x=blk_mod, main=NULL, cex.lab=.00001,show_labels = FALSE){\n plot.sociomatrix(x$blocked.data, labels=list(x$plabels,x$plabels),\n main=main, drawlines = FALSE, cex.lab=cex.lab)\n for (j in 2:length(x$plabels)) if (x$block.membership[j] !=\n x$block.membership[j-1])\n abline(v = j- 0.5, h = j- 0.5, lty = 3, xpd=FALSE)\n }\n \nplot.block(blk_model.provider.org, main = \"provider\")\n\n\n\n\n\n#prov_blks6 &lt;- blockmodeling::optRandomParC(provider_matrix, k=6, rep=10, approaches=\"ss\", blocks=\"com\")\n\n\n# Save the prov_blks6 object to a file\n#saveRDS(prov_blks6, \"prov_blks6_results.rds\")\n\n# Later, when you want to use it again, you can read it back into R\nprov_blks6 &lt;- readRDS(\"prov_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\nprov_blk_mod &lt;- blockmodel(provider_matrix, prov_blks6$best$best1$clu,\n                      plabels = rownames(provider_matrix))\n# print blockmodel object\nprov_blk_mod$block.model\n\n           Block 1   Block 2     Block 3     Block 4    Block 5     Block 6\nBlock 1 1.00000000 1.0000000 0.017204301 0.016666667 0.00000000 0.000000000\nBlock 2 1.00000000       NaN 0.000000000 0.000000000 1.00000000 0.857142857\nBlock 3 0.01720430 0.0000000 0.016841223 0.009032258 0.01080270 0.002764977\nBlock 4 0.01666667 0.0000000 0.009032258 0.733333333 0.00000000 0.000000000\nBlock 5 0.00000000 1.0000000 0.010802701 0.000000000 0.07973422 0.000000000\nBlock 6 0.00000000 0.8571429 0.002764977 0.000000000 0.00000000 0.714285714\n\n\n\nglimpse(prov_blk_mod)\n\nList of 11\n $ block.membership: int [1:222] 1 1 1 1 1 1 2 3 3 3 ...\n $ order.vector    : int [1:222] 104 110 114 175 182 183 9 1 2 4 ...\n $ block.content   : chr \"density\"\n $ blocked.data    : num [1:222, 1:222] 0 1 1 1 1 1 1 0 0 0 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:222] \"Freeda113 Crooks415\" \"Clemente531 Schamberger479\" \"Zachery872 Rau926\" \"Gino587 Block661\" ...\n  .. ..$ : chr [1:222] \"Freeda113 Crooks415\" \"Clemente531 Schamberger479\" \"Zachery872 Rau926\" \"Gino587 Block661\" ...\n $ block.model     : num [1:6, 1:6] 1 1 0.0172 0.0167 0 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n  .. ..$ : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n $ plabels         : chr [1:222] \"Freeda113 Crooks415\" \"Clemente531 Schamberger479\" \"Zachery872 Rau926\" \"Gino587 Block661\" ...\n $ glabels         : int [1:222] 1 2 3 4 5 6 7 8 9 10 ...\n $ rlabels         : chr [1:6] \"Block 1\" \"Block 2\" \"Block 3\" \"Block 4\" ...\n $ cluster.method  : chr \"Prespecified\"\n $ equiv.fun       : chr \"None\"\n $ equiv.metric    : chr \"None\"\n - attr(*, \"class\")= chr \"blockmodel\"\n\n\n\npro_attr$block &lt;- prov_blk_mod$block.membership \n\nhead(pro_attr)\n\n# A tibble: 6 × 5\n  NAME                   GENDER CITY       type     block\n  &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;    &lt;int&gt;\n1 Ted955 Reilly981       Male   fitchburg  PROVIDER     1\n2 Shane235 Lueilwitz711  Male   worcester  PROVIDER     1\n3 Jules135 Emard19       Male   leominster PROVIDER     1\n4 Jarvis643 Ankunding277 Male   fall river PROVIDER     1\n5 Thad495 Leannon79      Male   peabody    PROVIDER     1\n6 Bud153 Parisian75      Male   worcester  PROVIDER     1\n\n#write.csv(pro_attr, \"pro_attr.csv\")\n\n\nplot.block(prov_blk_mod, main = \"Provider 6 Block Model\",\n           cex.lab = .000001)\n\n\n\n\n\n#assign block membership to vertex attribute\nprovider.stat%v%\"role\"&lt;-prov_blk_mod$block.membership[match(provider.stat%v%\"vertex.names\",prov_blk_mod$plabels)]\n#plot network using \"role\" to color nodes\nGGally::ggnet2(provider.stat,\n               node.color=\"role\", \n               node.size=sna::degree(provider.stat, gmode=\"graph\"),\n               node.alpha = .5)  + ggtitle(\"Provider 6 Block Model Network\")\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\n\n#Next Steps Jaccard similarity\n\nlibrary(ade4)\n\nWarning: package 'ade4' was built under R version 4.3.3\n\n\n\nencounters.adj.ig &lt;- igraph::as_biadjacency_matrix(encounters.ig)\n\nproviders_jaccard &lt;- dist.binary(t(encounters.adj.ig),\n            method = 1, # method=1 Jaccard index\n            upper = TRUE,\n            diag = FALSE)\n\n\nproviders_jaccard &lt;- as.matrix(providers_jaccard)\ndiag(providers_jaccard) &lt;- 0\n\n\n#binarize\nproviders_jaccard_bi &lt;- ifelse(providers_jaccard &gt; 0.99, 1, 0)\n\n\n#create igraph object\nproviders_jaccard.ig &lt;- graph_from_adjacency_matrix(providers_jaccard_bi, mode = \"undirected\")\nproviders_jaccard.ig\n\nIGRAPH 2dce25b UN-- 222 24034 -- \n+ attr: name (v/c)\n+ edges from 2dce25b (vertex names):\n [1] Elijah719 White193--Kristopher775 Schiller186\n [2] Elijah719 White193--Laine739 Torphy630       \n [3] Elijah719 White193--Leonarda398 Schumm995    \n [4] Elijah719 White193--Mathew182 Howe413        \n [5] Elijah719 White193--Ted955 Reilly981         \n [6] Elijah719 White193--Vicente970 Armstrong51   \n [7] Elijah719 White193--Daniel959 Wolff180       \n [8] Elijah719 White193--Elmer371 Gusikowski974   \n+ ... omitted several edges\n\n\n\nplot(providers_jaccard.ig,  edge.width = 0.0002, edge.color = \"lightgray\",  vertex.size = 2, vertex.label = NA)\n\n\n\n\n\n# Load the igraph package\nlibrary(igraph)\n\n# Create an igraph object from the blockmodel\ng &lt;- graph_from_adjacency_matrix(provider_matrix, mode = \"undirected\", weighted = FALSE)\n\n# Plot the graph without labels\nplot(g,      layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 2, \n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Provider Network\")"
  },
  {
    "objectID": "posts/Post_Five - Copy/post_5_drug.html",
    "href": "posts/Post_Five - Copy/post_5_drug.html",
    "title": "POST 5",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\nThis post will explore the Provider Network in more including replicating block membership and plotting cities as attributes"
  },
  {
    "objectID": "posts/Post_Five - Copy/post_5_drug.html#patient",
    "href": "posts/Post_Five - Copy/post_5_drug.html#patient",
    "title": "Network Block Modeling - Geographical Comparisson",
    "section": "PATIENT",
    "text": "PATIENT\n\npatient_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj1))\n\npatient.stat &lt;- asNetwork(projected_graph$proj1)\n\npatient.se &lt;- equiv.clust(patient_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\n\npat_blk_model.patient.org &lt;- blockmodel(patient_matrix,\n patient.se, k = 4)\n\n\nplot.block&lt;-function(x=pat_blk_mod, main=NULL, cex.lab=.00001,show_labels = FALSE){\n plot.sociomatrix(x$blocked.data, labels=list(x$plabels,x$plabels),\n main=main, drawlines = FALSE, cex.lab=cex.lab)\n for (j in 2:length(x$plabels)) if (x$block.membership[j] !=\n x$block.membership[j-1])\n abline(v = j- 0.5, h = j- 0.5, lty = 3, xpd=FALSE)\n }\n \nplot.block(pat_blk_model.patient.org, main = \"patient\")\n\n\n\n\n\npat_blks6 &lt;- readRDS(\"pat_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\npat_blk_mod &lt;- blockmodel(patient_matrix, pat_blks6$best$best1$clu,\n                      plabels = rownames(patient_matrix))\n\n\n#assign block membership to vertex attribute\npatient.stat%v%\"role\"&lt;-pat_blk_mod$block.membership[match(patient.stat%v%\"vertex.names\",pat_blk_mod$plabels)]\n#plot network using \"role\" to color nodes\nGGally::ggnet2(patient.stat,\n               node.color=\"role\", \n               node.size=sna::degree(patient.stat, gmode=\"graph\"),\n               node.alpha = .5)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2"
  },
  {
    "objectID": "posts/Post_Five - Copy/post_5_drug.html#provider",
    "href": "posts/Post_Five - Copy/post_5_drug.html#provider",
    "title": "POST 5",
    "section": "PROVIDER",
    "text": "PROVIDER\n\nprovider_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj2))\n\nprovider.stat &lt;- asNetwork(projected_graph$proj2)\n\nprovider.se &lt;- equiv.clust(provider_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\n\nblk_model.provider.org &lt;- blockmodel(provider_matrix,\n provider.se, k = 6)\n\n\nprov_blks6 &lt;- readRDS(\"prov_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\nprov_blk_mod &lt;- blockmodel(provider_matrix, prov_blks6$best$best1$clu,\n                      plabels = rownames(provider_matrix))\n\n\n#assign block membership to vertex attribute\nprovider.stat%v%\"role\"&lt;-prov_blk_mod$block.membership[match(provider.stat%v%\"vertex.names\",prov_blk_mod$plabels)]\n\n#plot network using \"role\" to color nodes\nGGally::ggnet2(provider.stat,\n               node.color=\"role\", \n               node.size=sna::degree(provider.stat, gmode=\"graph\"),\n               node.alpha = .5) + ggtitle(\"Provider 6 Block Model Network\")\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2"
  },
  {
    "objectID": "posts/Post_Five - Copy/post_5_drug.html#create-new-attribute-lists",
    "href": "posts/Post_Five - Copy/post_5_drug.html#create-new-attribute-lists",
    "title": "POST 5",
    "section": "Create New Attribute Lists",
    "text": "Create New Attribute Lists\n\n#Include Block Membership in Provider Attribute List\npro_attr_list &lt;- do.call(list, pro_attr)\n\n\nprovider.st &lt;- network(provider_matrix,\n                       directed = FALSE,\n                       matrix.type = \"adjacency\",\n                       vertex.attr = pro_attr_list)\n\n\nprovider_graph &lt;- graph_from_biadjacency_matrix(provider.st)\n\n\n#assign colors\n#colors &lt;-  c(\"yellow\", \"blue\", \"green\", \"orange\", \"red\", \"purple\")\n#vertex_colors &lt;- colors[pro_attr_list$block]\nvertex_colors &lt;- ifelse(pro_attr_list$CITY == \"boston\", \"red\", \"white\")\n\nvertex_shape &lt;- ifelse(pro_attr_list$CITY == \"boston\", \"circle\", \"square\")\n\n\nplot(provider_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 4, \n     vertex.color = vertex_colors,\n     vertex.shape = vertex_shape,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"SN Graph\")\n\n\n\n\nWhat other cities are on the provider list. Boston is not being properly represented, I have a feeling\n\ntable(sort(pro_attr$CITY))\n\n\n       abington         amherst       attleboro          auburn      auburndale \n              1               2               5               1               2 \n           ayer         beverly          boston       braintree        brighton \n              1               1               2               1               2 \n       brockton       brookline         byfield       cambridge     centerville \n              2               1               1               4               1 \n    charlestown        charlton      chelmsford         chelsea   chestnut hill \n              1               1               1               1               1 \n       chicopee         danvers       dartmouth      dorchester   east sandwich \n              2               2               2               1               1 \n      fairhaven      fall river       fitchburg      foxborough      framingham \n              2               7               4               1               4 \n       franklin         gardner      greenfield          groton          hadley \n              1               2               3               1               1 \n        hanover       holliston         holyoke       hopkinton         hyannis \n              2               1               2               1               3 \n      lakeville      leominster          ludlow            lynn         mashpee \n              3               5               1               6               1 \n       medfield         melrose      middleboro       middleton         milford \n              1               2               1               1               2 \n         milton          natick         needham     new bedford     newburyport \n              2               4               2               4               3 \n         newton     north adams north dartmouth     northampton          norton \n              2               1               1               3               1 \n        norwood         peabody      pittsfield        plymouth          quincy \n              3               3               2               1               1 \n       randolph         raynham         reading        rochdale        rockland \n              2               1               2               1               1 \n     roslindale     s dartmouth      s yarmouth           salem        sandwich \n              1               1               1               1               2 \n         saugus         shirley        somerset      somerville    south boston \n              1               1               2               1               2 \n south hamilton  south yarmouth     springfield        stoneham       stoughton \n              2               2               1               4               1 \n     swampscott         swansea         taunton           upton    w brookfield \n              1               1               6               1               1 \n          waban       wakefield         walpole         waltham            ware \n              1               2               1               7               1 \n        wareham       wellesley wellesley hills    west roxbury   west yarmouth \n              3               2               1               1               1 \n      westfield        westford        westwood        weymouth       wilbraham \n              3               3               1               3               1 \n       winthrop          woburn       worcester        wrentham   yarmouth port \n              1               5              12               1               1 \n\n\nShould have cleaned that earlier, but here we go!\n\nBoston_Neighborhoods &lt;- c(\n  \"ALLSTON\",\n  \"BRIGHTON\",\n  \"BOSTON\",\n  \"CHARLESTOWN\",\n  \"DORCHESTER\",\n  \"HYDE PARK\",\n  \"JAMAICA PLAIN\",\n  \"MATTAPAN\",\n  \"ROSLINDALE\",\n  \"ROXBURY\",\n  \"West Roxbury\",\n  \"WEST ROXBURY\"\n)\nBoston_Neighborhoods &lt;- tolower(Boston_Neighborhoods)\n\n\n#assign colors\nvertex_colors &lt;- ifelse(pro_attr_list$CITY %in% Boston_Neighborhoods, \"red\", \"white\")\nvertex_shape &lt;- ifelse(pro_attr_list$block == \"1\", \"circle\", \"square\")\n\n\nplot(provider_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 4, \n     vertex.color = vertex_colors,\n     vertex.shape = vertex_shape,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Providers - RED = BOSTON\")\n\n\n\n\nSo… the density of providers is not necessarily Boston related, by the looks of this graph\nHow about Highest populations\n\nlargest_pop &lt;- c(\n\"Boston\",\n\"Worcester\",\n\"Springfield\",\n\"Cambridge\",\n\"Lowell\",\n\"Brockton\",\n\"Quincy\",\n\"Lynn\",\n\"New Bedford\",\n\"Fall River\",\n\"Lawrence\",\n\"Newton\",\n\"Somerville\",\n\"Framingham\",\n\"Haverhill\")\nlargest_pop &lt;- tolower(largest_pop)\n\n\n#assign colors\nvertex_color &lt;-  ifelse(pro_attr_list$CITY %in% largest_pop, \"red\", \"gray\")\n\n\nplot(provider_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 4, \n     vertex.color = vertex_color,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Providers - circle = Largest Cities\")\n\n           # Legend title\n\n# Define legend for vertex shapes\nlegend(\"topright\",\n       legend = c(\"Largest City\", \"Other\"),  # You can customize these labels\n       fill = c(\"red\", \"gray\"),                      # Point shapes corresponding to vertex shapes\n       title = \"Nodes: Who\")                     # Legend title\n\n\n\n\n\n#assign colors\nvertex_color &lt;-  ifelse(pro_attr_list$block == \"1\", \"red\",\n                        ifelse(pro_attr_list$block == \"2\", \"orange\",\n                               ifelse(pro_attr_list$block == \"3\", \"yellow\",\n                                      ifelse(pro_attr_list$block == \"4\", \"blue\",\n                                             ifelse(pro_attr_list$block == \"5\", \"green\",\n                                                    ifelse(pro_attr_list$block == \"6\", \"purple\", \"black\"))))))\nvertex_shape &lt;- ifelse(pro_attr_list$CITY %in% largest_pop, \"circle\", \"square\")\n\n\nplot(provider_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 4, \n     vertex.color = vertex_color,\n     vertex.shape = vertex_shape,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Providers - Blocks and Largest Cities\")\n\n\n# Define legend for vertex colors\nlegend(\"bottomright\",\n       legend = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"),  # You can customize these labels\n       fill = c(\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\"),   # Fill colors corresponding to vertex colors\n       title = \"Nodes: Blocks\")              # Legend title\n\n# Define legend for vertex shapes\nlegend(\"topright\",\n       legend = c(\"Largest City\", \"Other\"),  # You can customize these labels\n       pch = c(0, 1),                      # Point shapes corresponding to vertex shapes\n       title = \"Nodes: Who\")                     # Legend title\n\n\n\n\nI’m not sure why some of the colors are missing from this graph. Let’s remove the “Largest City” attribute\n\n#assign colors\nvertex_color &lt;-  ifelse(pro_attr_list$block == \"1\", \"red\",\n                        ifelse(pro_attr_list$block == \"2\", \"orange\",\n                               ifelse(pro_attr_list$block == \"3\", \"yellow\",\n                                      ifelse(pro_attr_list$block == \"4\", \"blue\",\n                                             ifelse(pro_attr_list$block == \"5\", \"green\",\n                                                    ifelse(pro_attr_list$block == \"6\", \"purple\", \"black\"))))))\n\n\nplot(provider_graph, \n     layout = layout.fruchterman.reingold, \n     vertex.label.dist = 2, \n     vertex.size = 4, \n     vertex.color = vertex_color,\n     edge.label = NA,\n     vertex.label = NA,\n     vertex.label.cex = 0.2, \n     main = \"Providers - Blocks\")\n\n\n# Define legend for vertex colors\nlegend(\"bottomright\",\n       legend = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"),  # You can customize these labels\n       fill = c(\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\"),   # Fill colors corresponding to vertex colors\n       title = \"Nodes: Blocks\")              # Legend title"
  },
  {
    "objectID": "posts/Post_Six - Copy/post_6_drug.html",
    "href": "posts/Post_Six - Copy/post_6_drug.html",
    "title": "POST 6",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(tigris)\nlibrary(stplanr)\nThis post will explore block attributes in the Provider Network data."
  },
  {
    "objectID": "posts/Post_Six - Copy/post_6_drug.html#patient",
    "href": "posts/Post_Six - Copy/post_6_drug.html#patient",
    "title": "POST 6",
    "section": "PATIENT",
    "text": "PATIENT\n\npatient_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj1))\n\npatient.stat &lt;- asNetwork(projected_graph$proj1)\n\npatient.se &lt;- equiv.clust(patient_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\n\npat_blk_model.patient.org &lt;- blockmodel(patient_matrix,\n patient.se, k = 4)\n\n\nplot.block&lt;-function(x=pat_blk_mod, main=NULL, cex.lab=.00001,show_labels = FALSE){\n plot.sociomatrix(x$blocked.data, labels=list(x$plabels,x$plabels),\n main=main, drawlines = FALSE, cex.lab=cex.lab)\n for (j in 2:length(x$plabels)) if (x$block.membership[j] !=\n x$block.membership[j-1])\n abline(v = j- 0.5, h = j- 0.5, lty = 3, xpd=FALSE)\n }\n \nplot.block(pat_blk_model.patient.org, main = \"patient\")\n\n\n\n\n\npat_blks6 &lt;- readRDS(\"pat_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\npat_blk_mod &lt;- blockmodel(patient_matrix, pat_blks6$best$best1$clu,\n                      plabels = rownames(patient_matrix))\n\n\n#assign block membership to vertex attribute\npatient.stat%v%\"role\"&lt;-pat_blk_mod$block.membership[match(patient.stat%v%\"vertex.names\",pat_blk_mod$plabels)]\n#plot network using \"role\" to color nodes\nGGally::ggnet2(patient.stat,\n               node.color=\"role\", \n               node.size=sna::degree(patient.stat, gmode=\"graph\"),\n               node.alpha = .5)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2"
  },
  {
    "objectID": "posts/Post_Six - Copy/post_6_drug.html#provider",
    "href": "posts/Post_Six - Copy/post_6_drug.html#provider",
    "title": "POST 6",
    "section": "PROVIDER",
    "text": "PROVIDER\n\nprovider_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj2))\nlibrary(intergraph)\ndetach(\"package:igraph\")\nlibrary(statnet)\nprovider.stat &lt;- asNetwork(projected_graph$proj2)\n\nprovider.se &lt;- equiv.clust(provider_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\n\nblk_model.provider.org &lt;- blockmodel(provider_matrix,\n provider.se, k = 6)\n\n\nprov_blks6 &lt;- readRDS(\"prov_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\nprov_blk_mod &lt;- blockmodel(provider_matrix, prov_blks6$best$best1$clu,\n                      plabels = rownames(provider_matrix))\n\n\n#assign block membership to vertex attribute\nprovider.stat%v%\"role\"&lt;-prov_blk_mod$block.membership[match(provider.stat%v%\"vertex.names\",prov_blk_mod$plabels)]\n\n#plot network using \"role\" to color nodes\nGGally::ggnet2(provider.stat,\n               node.color=\"role\", \n               node.size=sna::degree(provider.stat, gmode=\"graph\"),\n               node.alpha = .5) + ggtitle(\"Provider 6 Block Model Network\")\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\n\n\nGGally::ggnet2(provider.stat,\n               node.color=pro_attr$block, \n               node.size=sna::degree(provider.stat, gmode=\"graph\"),\n               node.alpha = .5) + ggtitle(\"Provider 6 Block Model Network\")\n\n\n\n\nHmm, this doesn’t look at all like the graph showing blocks… Not sure what’s going on here. I’ll attempt to assign attributes a different way.\n\nattributes &lt;- dumpAttr(provider.stat)\n# Extracting roles and vertex names\nroles &lt;- attributes$vertex$role\nvertex_names &lt;- attributes$vertex$vertex.names\n\n# Creating a dataframe\nrole_vertex_df &lt;- data.frame(vertex.names = vertex_names, role = roles)\n\n# Displaying the first few rows of the dataframe\n\nhead(role_vertex_df %&gt;%\n  arrange(desc(vertex.names)))\n\n            vertex.names role\n1      Zachery872 Rau926    1\n2    Zachery872 Pagac496    3\n3     Waylon572 Lakin515    3\n4     Virgen207 Hyatt152    5\n5 Vicente970 Armstrong51    5\n6      Vern731 Casper496    3\n\nhead(pro_attr %&gt;%\n  arrange(desc(NAME)))\n\n# A tibble: 6 × 5\n  NAME                   GENDER CITY       type     block\n  &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt;\n1 Zachery872 Rau926      Male   walpole    PROVIDER     1\n2 Zachery872 Pagac496    Male   melrose    PROVIDER     3\n3 Waylon572 Lakin515     Male   woburn     PROVIDER     3\n4 Virgen207 Hyatt152     Female stoneham   PROVIDER     5\n5 Vicente970 Armstrong51 Male   stoneham   PROVIDER     5\n6 Vern731 Casper496      Male   swampscott PROVIDER     3\n\n\n\n# Extracting vertex attributes\nvertex_data &lt;- data.frame(\n  role = get.vertex.attribute(provider.stat, \"role\"),\n  vertex.names = get.vertex.attribute(provider.stat, \"vertex.names\")\n)\n\n# Displaying the first few rows of the dataframe\nhead(vertex_data)\n\n  role              vertex.names\n1    3        Elijah719 White193\n2    3         Fidel864 Swift555\n3    5        Virgen207 Hyatt152\n4    3       Zachery872 Pagac496\n5    3 Kristopher775 Schiller186\n6    3        Laine739 Torphy630"
  },
  {
    "objectID": "posts/Post_Six - Copy/post_6_drug.html#create-new-attribute-lists",
    "href": "posts/Post_Six - Copy/post_6_drug.html#create-new-attribute-lists",
    "title": "POST 6",
    "section": "Create New Attribute Lists",
    "text": "Create New Attribute Lists\n\npro_attr_list &lt;- do.call(list, pro_attr)\n\n\nprovider.st &lt;- network(provider_matrix,\n                       directed = FALSE,\n                       matrix.type = \"adjacency\",\n                       vertex.attr = pro_attr_list)"
  },
  {
    "objectID": "posts/Post_Seven - Copy/post_7_drug.html",
    "href": "posts/Post_Seven - Copy/post_7_drug.html",
    "title": "POST 7",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(tigris)\nlibrary(stplanr)\nThis post will explore the Synthetic Mass network data in more detail."
  },
  {
    "objectID": "posts/Post_Seven - Copy/post_7_drug.html#provider",
    "href": "posts/Post_Seven - Copy/post_7_drug.html#provider",
    "title": "POST 7",
    "section": "PROVIDER",
    "text": "PROVIDER\n\nprovider_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj2))\nlibrary(intergraph)\ndetach(\"package:igraph\")\nlibrary(statnet)\nprovider.stat &lt;- asNetwork(projected_graph$proj2)\n\nprovider.se &lt;- equiv.clust(provider_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\n\nblk_model.provider.org &lt;- blockmodel(provider_matrix,\n provider.se, k = 6)\n\n\nprov_blks6 &lt;- readRDS(\"prov_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\nprov_blk_mod &lt;- blockmodel(provider_matrix, prov_blks6$best$best1$clu,\n                      plabels = rownames(provider_matrix))\n\n\n#assign block membership to vertex attribute\nprovider.stat%v%\"role\"&lt;-prov_blk_mod$block.membership[match(provider.stat%v%\"vertex.names\",prov_blk_mod$plabels)]\n\n\nattributes &lt;- dumpAttr(provider.stat)\n# Extracting roles and vertex names\nroles &lt;- attributes$vertex$role\nvertex_names &lt;- attributes$vertex$vertex.names\n\n# Creating a dataframe\nrole_vertex_df &lt;- data.frame(vertex.names = vertex_names, role = roles)\n\n# Displaying the first few rows of the dataframe\n\nhead(role_vertex_df %&gt;%\n  arrange(desc(vertex.names)))\n\n            vertex.names role\n1      Zachery872 Rau926    1\n2    Zachery872 Pagac496    3\n3     Waylon572 Lakin515    3\n4     Virgen207 Hyatt152    5\n5 Vicente970 Armstrong51    5\n6      Vern731 Casper496    3\n\nhead(pro_attr %&gt;%\n  arrange(desc(NAME)))\n\n# A tibble: 6 × 5\n  NAME                   GENDER CITY       type     block\n  &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt;\n1 Zachery872 Rau926      Male   walpole    PROVIDER     1\n2 Zachery872 Pagac496    Male   melrose    PROVIDER     3\n3 Waylon572 Lakin515     Male   woburn     PROVIDER     3\n4 Virgen207 Hyatt152     Female stoneham   PROVIDER     5\n5 Vicente970 Armstrong51 Male   stoneham   PROVIDER     5\n6 Vern731 Casper496      Male   swampscott PROVIDER     3\n\n\n\n# Extracting vertex attributes\nvertex_data &lt;- data.frame(\n  role = get.vertex.attribute(provider.stat, \"role\"),\n  vertex.names = get.vertex.attribute(provider.stat, \"vertex.names\")\n)\n\n# Displaying the first few rows of the dataframe\nhead(vertex_data)\n\n  role              vertex.names\n1    3        Elijah719 White193\n2    3         Fidel864 Swift555\n3    5        Virgen207 Hyatt152\n4    3       Zachery872 Pagac496\n5    3 Kristopher775 Schiller186\n6    3        Laine739 Torphy630\n\n\n#So, lets geographically map this network\n\nlibrary(leaflet)\n\nWarning: package 'leaflet' was built under R version 4.3.3\n\n\n#add lat and lon back into the attributes\n\nhead(encounters_cleaned)\n\n# A tibble: 6 × 51\n  ENCOUNTER_ID    START               STOP                PATIENT ORGANIZATION.x\n  &lt;chr&gt;           &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;         \n1 1b544ceb-bfe9-… 2000-11-11 13:33:09 2000-11-11 14:33:09 Annice… db28cc9a-fdfb…\n2 0d642d81-9624-… 2001-03-30 13:33:09 2001-03-30 14:33:09 Annice… db28cc9a-fdfb…\n3 99d190e1-6727-… 2001-11-28 13:33:09 2001-11-28 14:33:09 Annice… db28cc9a-fdfb…\n4 cc076374-d33d-… 2004-09-03 13:33:09 2004-09-03 14:31:19 Annice… 3d5fbf38-c781…\n5 05a24332-4d5a-… 2005-09-09 13:33:09 2005-09-09 14:16:34 Annice… 3d5fbf38-c781…\n6 8844f58d-3e5e-… 2008-09-12 13:33:09 2008-09-12 14:28:22 Annice… 3d5fbf38-c781…\n# ℹ 46 more variables: PROVIDER &lt;chr&gt;, PAYER &lt;chr&gt;, ENCOUNTERCLASS &lt;chr&gt;,\n#   CODE &lt;dbl&gt;, DESCRIPTION &lt;chr&gt;, BASE_ENCOUNTER_COST &lt;dbl&gt;,\n#   TOTAL_CLAIM_COST &lt;dbl&gt;, PAYER_COVERAGE &lt;dbl&gt;, REASONCODE &lt;dbl&gt;,\n#   REASONDESCRIPTION &lt;chr&gt;, ORGANIZATION.y &lt;chr&gt;, GENDER.x &lt;chr&gt;,\n#   SPECIALITY &lt;chr&gt;, ADDRESS.x &lt;chr&gt;, CITY.x &lt;chr&gt;, STATE.x &lt;chr&gt;,\n#   ZIP.x &lt;chr&gt;, LAT.x &lt;dbl&gt;, LON.x &lt;dbl&gt;, ENCOUNTERS &lt;dbl&gt;, PROCEDURES &lt;dbl&gt;,\n#   BIRTHDATE &lt;date&gt;, DEATHDATE &lt;date&gt;, SSN &lt;chr&gt;, DRIVERS &lt;chr&gt;, …\n\n\n\ndf_reconnected &lt;- merge(pro_attr, encounters_cleaned, by.x = \"NAME\", by.y = \"PROVIDER\", all.x = TRUE)\n\ndf_coords&lt;- df_reconnected\n\n\ndf_coords &lt;- df_coords %&gt;%\n  select(NAME, GENDER, CITY, type, block, LAT.x, LON.x) %&gt;%\n  group_by(NAME)\n\n# Keep only one row of each unique \"NAME\"\ndf_coords &lt;- df_coords %&gt;%\n  distinct(NAME, .keep_all = TRUE) %&gt;%\n  rename(LAT = LAT.x) %&gt;%\n  rename(LON = LON.x)\n\n\n# Display the resulting dataframe\nhead(df_coords)\n\n# A tibble: 6 × 7\n# Groups:   NAME [6]\n  NAME                GENDER CITY          type     block   LAT   LON\n  &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;         &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Abdul218 Boyer713   Male   needham       PROVIDER     3  42.3 -71.2\n2 Adán600 Alicea505   Male   centerville   PROVIDER     3  41.6 -70.3\n3 Agnes294 Dooley940  Female fall river    PROVIDER     3  41.7 -71.1\n4 Alberto639 Adame662 Male   saugus        PROVIDER     6  42.5 -71.0\n5 Allyson474 Doyle959 Female west yarmouth PROVIDER     5  41.7 -70.2\n6 Almeta56 Lehner980  Female greenfield    PROVIDER     5  42.6 -72.6\n\n\n\npat_df_coords &lt;- df_reconnected %&gt;%\n  select(PATIENT, GENDER.y, RACE, CITY.y,  LAT.y, LON.y) %&gt;%\n  group_by(PATIENT)\n\n# Keep only one row of each unique \"NAME\"\npat_df_coords &lt;- pat_df_coords %&gt;%\n  rename(NAME = PATIENT) %&gt;%\n  distinct(NAME, .keep_all = TRUE) %&gt;%\n  rename(CITY = CITY.y) %&gt;%\n  rename(GENDER = GENDER.y) %&gt;%\n  rename(LAT = LAT.y) %&gt;%\n  rename(LON = LON.y)\n\n\nhead(pat_df_coords)\n\n# A tibble: 6 × 6\n# Groups:   NAME [6]\n  NAME                    GENDER RACE  CITY            LAT   LON\n  &lt;chr&gt;                   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n1 Dinorah501 Bechtelar572 Female white newton         42.3 -71.3\n2 Cherise743 Prosacco716  Female white newton         42.3 -71.2\n3 Rod343 Prosacco716      Male   white east sandwich  41.7 -70.4\n4 Chaya236 Sporer811      Female asian fall river     41.6 -71.1\n5 Leonel449 Witting912    Male   white lynn           42.5 -71.0\n6 Rudy520 Hettinger594    Male   white yarmouth port  41.7 -70.3\n\npat_df_coords$type &lt;- \"PATIENT\"\npat_attr\n\n# A tibble: 86 × 9\n   NAME                   GENDER RACE  MARITAL  CITY    INCOME   AGE type  block\n   &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 Annice210 Gleason633   Female white Married  brookl…   1565    37 PATI…     6\n 2 Julianne852 Barrows492 Female white Widowed  hamilt…  39537    65 PATI…     6\n 3 Alesha810 Heaney114    Female white Divorced framin… 114339    46 PATI…     6\n 4 Sandee884 Rice937      Female white &lt;NA&gt;     taunton  96256    26 PATI…     6\n 5 Mia349 Runte676        Female white Divorced chelms…  71238    44 PATI…     6\n 6 Damian46 Dach178       Male   white &lt;NA&gt;     swansea  74155    26 PATI…     6\n 7 Nelida367 Emard19      Female white Single   brookl… 501039    30 PATI…     4\n 8 Anthony633 Kutch271    Male   asian &lt;NA&gt;     framin… 671128    26 PATI…     6\n 9 Mose244 Cummerata161   Male   black Single   saugus  125860    46 PATI…     6\n10 Shila857 Heller342     Female white &lt;NA&gt;     marion  134195    22 PATI…     2\n# ℹ 76 more rows\n\n\n\nmerged_df &lt;- merge(pat_df_coords, pat_attr[, c(\"NAME\", \"block\")], by = \"NAME\", all.x = TRUE)\nboth_df &lt;- bind_rows(merged_df, df_coords)\nhead(both_df)\n\n                     NAME GENDER  RACE       CITY      LAT       LON    type\n1        Adam631 Hoppe518   Male white  cambridge 42.41904 -71.07128 PATIENT\n2     Alesha810 Heaney114 Female white framingham 42.23666 -71.46729 PATIENT\n3 Alissa315 Altenwerth646 Female white  wakefield 42.45483 -71.09130 PATIENT\n4    Analisa263 Kohler843 Female white     boston 42.38900 -71.04350 PATIENT\n5    Annice210 Gleason633 Female white  brookline 42.38652 -71.11319 PATIENT\n6     Anthony633 Kutch271   Male asian framingham 42.32681 -71.41111 PATIENT\n  block\n1     6\n2     6\n3     5\n4     6\n5     6\n6     6\n\n\n\npro_attr_list_zip &lt;- do.call(list,df_coords)\npat_attr_list_zip &lt;- do.call(list,pat_df_coords)\nattribute_list_zip &lt;- do.call(list, both_df)\n\n\nencounters.geo.stat &lt;- network(encounters_el,\n                         directed = FALSE,\n                         bipartite = TRUE,\n                         matrix.type = \"edgelist\",\n                         vertex.attr = attribute_list_zip)\n\n\nlibrary(igraph)\n\nWarning: package 'igraph' was built under R version 4.3.2\n\n\n\nAttaching package: 'igraph'\n\n\nThe following object is masked from 'package:tigris':\n\n    blocks\n\n\nThe following objects are masked from 'package:sna':\n\n    betweenness, bonpow, closeness, components, degree, dyad.census,\n    evcent, hierarchy, is.connected, neighborhood, triad.census\n\n\nThe following objects are masked from 'package:network':\n\n    %c%, %s%, add.edges, add.vertices, delete.edges, delete.vertices,\n    get.edge.attribute, get.edges, get.vertex.attribute, is.bipartite,\n    is.directed, list.edge.attributes, list.vertex.attributes,\n    set.edge.attribute, set.vertex.attribute\n\n\nThe following objects are masked from 'package:lubridate':\n\n    %--%, union\n\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\n#create igraph\nencounters.geo.ig &lt;- graph_from_biadjacency_matrix(encounters.geo.stat)\n\n\nencounters.geo.stat2 &lt;- asNetwork(encounters.geo.ig)\n\n\ndetach(\"package:igraph\")\n\n# Extracting the coordinates from the network object\ncoords &lt;- get.vertex.attribute(encounters.geo.stat, \"LAT\" )  # Assuming latitude is stored in an attribute named \"lat\"\ncoords_lon &lt;- get.vertex.attribute(encounters.geo.stat, \"LON\")  # Assuming longitude is stored in an attribute named \"lon\"\n\n# Creating a Leaflet map\nleaflet() %&gt;%\n  addTiles() %&gt;%\n  # Adding markers for each coordinate\n  addMarkers(lng = coords_lon, lat = coords)\n\n\n\n\n\n\nblock &lt;- get.vertex.attribute(encounters.geo.stat, \"block\")\n# Assuming encounters.geo.stat is your network object containing the block attribute\n# Assuming block is the name of the attribute containing block information\n# Assuming coords_lon and coords are your longitude and latitude coordinates\n\n# Define colors based on block values\ncolors &lt;-  ifelse(block == \"1\", \"red\",\n                 ifelse(block == \"2\", \"orange\",\n                  ifelse(block == \"3\", \"yellow\",\n                   ifelse(block == \"4\", \"green\",\n                    ifelse(block == \"5\", \"blue\", \n                      ifelse(block == \"6\", \"purple\", \n                           \"black\")))))) # Add more colors as needed\n\n# Creating a Leaflet map\nleaflet() %&gt;%\n  addTiles() %&gt;%\n  # Adding markers for each coordinate with color based on block attribute\n  addCircleMarkers(lng = coords_lon, lat = coords,\n                   color = colors)\n\n\n\n\n\ntry for providers only?\n\nprovider.geo.stat &lt;- network(provider_matrix,\n                       directed = FALSE,\n                       matrix.type = \"adjacency\",\n                       vertex.attr = pro_attr_list_zip)\n\n\n# Extracting the coordinates from the network object\npro_coords &lt;- get.vertex.attribute(provider.geo.stat, \"LAT\")  # Assuming latitude is stored in an attribute named \"lat\"\npro_coords_lon &lt;- get.vertex.attribute(provider.geo.stat, \"LON\")  # Assuming longitude is stored in an attribute named \"lon\"\n\n# Creating a Leaflet map\nleaflet() %&gt;%\n  addTiles() %&gt;%\n  # Adding markers for each coordinate\n  addMarkers(lng = pro_coords_lon, lat = pro_coords)\n\n\n\n\n\n\npro_block &lt;- get.vertex.attribute(provider.geo.stat, \"block\")\n# Assuming encounters.geo.stat is your network object containing the block attribute\n# Assuming block is the name of the attribute containing block information\n# Assuming coords_lon and coords are your longitude and latitude coordinates\n\n# Define colors based on block values\npro_colors &lt;- ifelse(block == \"1\", \"red\",\n                 ifelse(block == \"2\", \"orange\",\n                  ifelse(block == \"3\", \"yellow\",\n                   ifelse(block == \"4\", \"green\",\n                    ifelse(block == \"5\", \"blue\", \n                      ifelse(block == \"6\", \"purple\", \n                           \"black\"))))))  # Add more colors as needed\n\n# Creating a Leaflet map\nleaflet() %&gt;%\n  addTiles() %&gt;%\n  # Adding markers for each coordinate with color based on block attribute\n  addCircleMarkers(lng = pro_coords_lon, lat = pro_coords,\n                   color = pro_colors)"
  },
  {
    "objectID": "posts/Post_Seven - Copy/post_7_drug.html#create-new-attribute-lists",
    "href": "posts/Post_Seven - Copy/post_7_drug.html#create-new-attribute-lists",
    "title": "POST 7",
    "section": "Create New Attribute Lists",
    "text": "Create New Attribute Lists\n\npat_attr_list &lt;- do.call(list, pat_attr)\npro_attr_list &lt;- do.call(list, pro_attr)\nboth_attr &lt;- bind_rows(pat_attr, pro_attr)\nattribute_list &lt;- do.call(list, both_attr)\n\n\nprovider.st &lt;- network(provider_matrix,\n                       directed = FALSE,\n                       matrix.type = \"adjacency\",\n                       vertex.attr = pro_attr_list)\nprovider.st\n\n Network attributes:\n  vertices = 222 \n  directed = FALSE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = FALSE \n  total edges= 497 \n    missing edges= 0 \n    non-missing edges= 497 \n\n Vertex attribute names: \n    block CITY GENDER NAME type vertex.names \n\nNo edge attributes\n\n\n\nlibrary(igraph)\nprovider_graph &lt;- graph_from_biadjacency_matrix(provider.st)\n\n\nBoston_Neighborhoods &lt;- c(\n  \"ALLSTON\",\n  \"BRIGHTON\",\n  \"BOSTON\",\n  \"CHARLESTOWN\",\n  \"DORCHESTER\",\n  \"HYDE PARK\",\n  \"JAMAICA PLAIN\",\n  \"MATTAPAN\",\n  \"ROSLINDALE\",\n  \"ROXBURY\",\n  \"West Roxbury\",\n  \"WEST ROXBURY\"\n)\nBoston_Neighborhoods &lt;- tolower(Boston_Neighborhoods)\n\nHow about Highest populations\n\nlargest_pop &lt;- c(\n\"Boston\",\n\"Worcester\",\n\"Springfield\",\n\"Cambridge\",\n\"Lowell\",\n\"Brockton\",\n\"Quincy\",\n\"Lynn\",\n\"New Bedford\",\n\"Fall River\",\n\"Lawrence\",\n\"Newton\",\n\"Somerville\",\n\"Framingham\",\n\"Haverhill\")\nlargest_pop &lt;- tolower(largest_pop)"
  },
  {
    "objectID": "posts/Post_Eight- Copy/post_8_drug.html",
    "href": "posts/Post_Eight- Copy/post_8_drug.html",
    "title": "POST 7",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(tigris)\nlibrary(stplanr)\n\nThis post will explore the Synthetic Mass network data in more detail.\n\nRead in Data\n\npat_attr &lt;- read_csv(\"post5drug_data/pat_attr.csv\", \n    col_types = cols(...1 = col_skip()))\npro_attr &lt;- read_csv(\"post5drug_data/pro_attr.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaning &lt;- read_csv(\"post5drug_data//encounters_cleaning.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaned &lt;- read_csv(\"post5drug_data//encounters_cleaned.csv\", \n    col_types = cols(...1 = col_skip()))\nencounter_attributes &lt;- read_csv(\"post5drug_data/encounter_attributes.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_el  &lt;- read_csv(\"post5drug_data/encounters_el.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_st_3 &lt;- read_csv(\"post5drug_data/encounters.st.3.csv\", \n    col_types = cols(...1 = col_skip()))\nattribute_list &lt;- read.csv(\"post5drug_data/attribute_list.csv\")\npat_blks6 &lt;- readRDS(\"pat_blks6_results.rds\")\nprov_blks6 &lt;- readRDS(\"prov_blks6_results.rds\")\n\n\n\nCreate bipartite network with attributes\n\nencounters.stat &lt;- network(encounters_el,\n                         directed = FALSE,\n                         bipartite = TRUE,\n                         matrix.type = \"edgelist\",\n                         vertex.attr = attribute_list)\n\nencounters.ig &lt;- graph_from_biadjacency_matrix(encounters.stat)\n\nprojected_graph &lt;- bipartite_projection(encounters.ig)\n\n\nprovider_matrix &lt;- as.matrix(as_adjacency_matrix(projected_graph$proj2))\nlibrary(statnet)\n\nWarning: package 'statnet' was built under R version 4.3.2\n\n\nLoading required package: tergm\n\n\nWarning: package 'tergm' was built under R version 4.3.2\n\n\nLoading required package: ergm\n\n\nWarning: package 'ergm' was built under R version 4.3.2\n\n\n\n'ergm' 4.6.0 (2023-12-17), part of the Statnet Project\n* 'news(package=\"ergm\")' for changes since last version\n* 'citation(\"ergm\")' for citation information\n* 'https://statnet.org' for help, support, and other information\n\n\n'ergm' 4 is a major update that introduces some backwards-incompatible\nchanges. Please type 'news(package=\"ergm\")' for a list of major\nchanges.\n\n\n\nAttaching package: 'ergm'\n\n\nThe following object is masked from 'package:statnet.common':\n\n    snctrl\n\n\nLoading required package: networkDynamic\n\n\nWarning: package 'networkDynamic' was built under R version 4.3.2\n\n\n\n'networkDynamic' 0.11.4 (2023-12-10?), part of the Statnet Project\n* 'news(package=\"networkDynamic\")' for changes since last version\n* 'citation(\"networkDynamic\")' for citation information\n* 'https://statnet.org' for help, support, and other information\n\n\nRegistered S3 method overwritten by 'tergm':\n  method                   from\n  simulate_formula.network ergm\n\n\n\n'tergm' 4.2.0 (2023-05-30), part of the Statnet Project\n* 'news(package=\"tergm\")' for changes since last version\n* 'citation(\"tergm\")' for citation information\n* 'https://statnet.org' for help, support, and other information\n\n\n\nAttaching package: 'tergm'\n\n\nThe following object is masked from 'package:ergm':\n\n    snctrl\n\n\nThe following object is masked from 'package:statnet.common':\n\n    snctrl\n\n\nLoading required package: ergm.count\n\n\nWarning: package 'ergm.count' was built under R version 4.3.2\n\n\n\n'ergm.count' 4.1.1 (2022-05-24), part of the Statnet Project\n* 'news(package=\"ergm.count\")' for changes since last version\n* 'citation(\"ergm.count\")' for citation information\n* 'https://statnet.org' for help, support, and other information\n\n\nLoading required package: tsna\n\n\nWarning: package 'tsna' was built under R version 4.3.2\n\n\n\n'statnet' 2019.6 (2019-06-13), part of the Statnet Project\n* 'news(package=\"statnet\")' for changes since last version\n* 'citation(\"statnet\")' for citation information\n* 'https://statnet.org' for help, support, and other information\n\n\nunable to reach CRAN\n\nprovider.stat &lt;- asNetwork(projected_graph$proj2)\nprovider.ig &lt;- graph_from_biadjacency_matrix(provider.stat)\ndetach(\"package:igraph\")\nprovider.se &lt;- equiv.clust(provider_matrix,\n equiv.fun = \"sedist\",\n method = \"hamming\",\n mode = \"graph\",\n cluster.method = \"complete\")\n\n\nblk_model.provider.org &lt;- blockmodel(provider_matrix,\n provider.se, k = 6)\n\n\nprov_blks6 &lt;- readRDS(\"prov_blks6_results.rds\")\n\n\n# blockmodel with optimized partition\nprov_blk_mod &lt;- blockmodel(provider_matrix, prov_blks6$best$best1$clu,\n                      plabels = rownames(provider_matrix))\n\n\n#assign block membership to vertex attribute\nprovider.stat%v%\"role\"&lt;-prov_blk_mod$block.membership[match(provider.stat%v%\"vertex.names\",prov_blk_mod$plabels)]\n\n#plot network using \"role\" to color nodes\nGGally::ggnet2(provider.stat,\n               node.color=\"role\", \n               node.size=sna::degree(provider.stat, gmode=\"graph\"),\n               node.alpha = .5)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\n\n\ngden(provider.stat)\n\n[1] 0.02026008\n\n\n\ngtrans(provider.stat)\n\n[1] 0.3677613\n\n\n\nigraph::components(provider.ig)$no\n\n[1] 17\n\n\n\nsummary(provider.stat %e%\"dist\")\n\nLength  Class   Mode \n     0   NULL   NULL \n\n\n\nprovider.nodes &lt;- data.frame(\n  name = provider.stat%v%\"vertex.names\",\n  degree=sna::degree(provider.stat, gmode = \"digraph\"),\n  degree.wt = igraph::strength(provider.ig),\n  betweenness = sna::betweenness(provider.stat, gmode=\"digraph\"),\n  close=sna::closeness(provider.stat, cmode = \"suminvdir\"),\n  constraint=igraph::constraint(provider.ig)\n)\n\nprovider.nodes\n\n                          name degree degree.wt  betweenness       close\n1           Elijah719 White193      6         3     0.000000 0.200904977\n2            Fidel864 Swift555     16         8    32.833333 0.212971342\n3           Virgen207 Hyatt152     12         6   471.833333 0.274811463\n4          Zachery872 Pagac496     12         6    11.500000 0.208446456\n5    Kristopher775 Schiller186      4         2     0.000000 0.013574661\n6           Laine739 Torphy630      4         2     0.000000 0.013574661\n7        Leonarda398 Schumm995      8         4     8.000000 0.018099548\n8            Mathew182 Howe413      8         4    93.500000 0.268778281\n9             Ted955 Reilly981    110        55 18266.492186 0.442684766\n10      Vicente970 Armstrong51      6         3     0.000000 0.265761689\n11          Daniel959 Wolff180      6         3     0.000000 0.199396682\n12      Elmer371 Gusikowski974      6         3     0.000000 0.199396682\n13          Janet238 Crooks415      6         3     0.000000 0.199396682\n14       Karla801 Cummerata161     20        10   950.666667 0.282352941\n15        Clement78 Gleason633      8         4   147.000000 0.266515837\n16      Enriqueta274 Barton704      4         2     0.000000 0.191478130\n17             Kim439 Hyatt152      8         4   147.000000 0.266515837\n18            Janey243 Schoen8      4         2     0.000000 0.013574661\n19            Luna60 Littel644      4         2     0.000000 0.013574661\n20         Numbers230 Stehr398      6         3     0.000000 0.013574661\n21          Waylon572 Lakin515      6         3     0.000000 0.013574661\n22           Ina660 Hermann103      8         4     0.000000 0.226018100\n23         Jewel43 Kassulke119     58        29  5332.577167 0.345324284\n24           Josef103 Klein929      8         4     0.000000 0.226018100\n25      Majorie11 Bergstrom287      8         4     0.000000 0.226018100\n26         Salvador46 Wolff180      8         4     0.000000 0.226018100\n27      Cyrstal592 Mosciski958      8         4     0.000000 0.226018100\n28      Gerardo48 Bergstrom287      8         4     0.000000 0.226018100\n29         Shawn523 Padberg411      8         4     0.000000 0.226018100\n30           Thanh759 Weber641     16         8    37.666667 0.238838612\n31          Agnes294 Dooley940      4         2     0.000000 0.221493213\n32            Cody889 Ratke343      4         2     0.000000 0.221493213\n33           Abdul218 Boyer713     12         6     2.666667 0.195248869\n34          Cortez851 Price929     42        21  5155.666667 0.271870287\n35            Gene733 Ratke343      8         4     0.000000 0.190723982\n36          Lola232 Collado928     12         6     2.666667 0.195248869\n37     Marcelino726 Hilpert278      8         4     0.000000 0.190723982\n38        Delbert384 Carter549      8         4     0.000000 0.201659125\n39          Eddie505 Keeling57     14         7    74.666667 0.275565611\n40           Louis204 Hauck852     10         5    70.000000 0.271040724\n41           Thad495 Leannon79     10         5    70.000000 0.271040724\n42        Darlene91 Collier206     16         8   293.666667 0.249396682\n43           Jolynn62 Adams676      6         3     0.000000 0.227526395\n44        Junior695 Kuhlman484      6         3     0.000000 0.223755656\n45          Justin359 Hayes766      6         3     0.000000 0.223755656\n46         Cristi782 Miller503      8         4     8.000000 0.018099548\n47       Nevada145 Schmeler639      4         2     0.000000 0.013574661\n48          Shayla126 White193      4         2     0.000000 0.013574661\n49    Celestina960 Reichert620      8         4     0.000000 0.190723982\n50         Dante562 Reinger292     18         9    15.000000 0.202036199\n51        Junior695 Pacocha935      4         2     0.000000 0.009049774\n52      Latoria810 Eichmann909      4         2     0.000000 0.009049774\n53         Maryann106 Hintz995      4         2     0.000000 0.009049774\n54           Dusty207 Lynch190     12         6    22.800000 0.236576169\n55            Rhonda22 Bins636      6         3     0.000000 0.223755656\n56          Shonna561 Feest103      6         3     0.000000 0.223755656\n57        Anderson154 Lemke654     30        15  2096.363004 0.301583710\n58    Felicidad691 Luettgen772      6         3     0.000000 0.217722474\n59       Jettie913 Rodriguez71      8         4    78.857143 0.219984917\n60           Mertie42 Lakin515     20        10   575.174481 0.252790347\n61       Charley358 Effertz744      6         3     0.000000 0.013574661\n62      Cleveland582 Kuphal363      6         3     0.000000 0.013574661\n63         Lauretta754 Dare640      6         3     0.000000 0.013574661\n64      Sparkle906 Bernhard322      6         3     0.000000 0.013574661\n65        Arminda86 Trantow673     12         6    18.000000 0.027149321\n66       Arturo47 Maldonado119      6         3     0.000000 0.020361991\n67          Mickey576 Borer986      6         3     0.000000 0.020361991\n68         Rhett759 Padberg411      6         3     0.000000 0.020361991\n69          Almeta56 Lehner980      6         3     0.000000 0.263499246\n70         Ellie521 Nicolas769      6         3     0.000000 0.263499246\n71            Marth98 Mayer370      6         3     0.000000 0.263499246\n72            Cleo27 Lehner980      4         2     0.000000 0.013574661\n73         Hong136 Kassulke119      4         2     0.000000 0.013574661\n74       Nathanael908 Rogahn59      8         4     8.000000 0.018099548\n75            Aubrey96 Emard19      4         2     0.000000 0.180176686\n76           Bud153 Parisian75     18         9   308.000000 0.279713424\n77         Darrick836 Hoppe518     12         6   292.000000 0.273680241\n78            Jules135 Emard19     14         7   288.000000 0.275188537\n79         Mateo562 Barajas558     12         6   292.000000 0.273680241\n80          Monroe732 Mills423     10         5     0.000000 0.270663650\n81       Carmelita854 Tromp100      6         3     0.000000 0.264253394\n82           Lezlie553 Koss676      2         1     0.000000 0.151669899\n83     Rayford811 Bashirian201      6         3   296.000000 0.197360483\n84         Assunta351 Haley279      6         3     0.000000 0.217722474\n85           Ross213 Wisozk929     12         6    54.000000 0.224509804\n86      Augustine565 Brekke496     10         5     9.000000 0.209879336\n87         Joanna347 Abbott774     16         8  1113.000000 0.283484163\n88         Lauri399 Keebler762      4         2     0.000000 0.198567119\n89           Jorge203 Harvey63      6         3     0.000000 0.020361991\n90         King743 Predovic534      6         3     0.000000 0.020361991\n91          Logan497 Fisher429      6         3     0.000000 0.020361991\n92       Delicia67 Bernhard322     10         5    62.617094 0.275942685\n93       Randy380 Bergstrom287     18         9   373.355189 0.284992459\n94           Elisha578 Conn188      6         3     0.000000 0.267269985\n95        Emory494 Schuster709     12         6   654.833333 0.274811463\n96    Sherwood961 Aufderhar910     12         6   468.500000 0.274811463\n97          Buck819 Johnson679      6         3     0.000000 0.163510019\n98      Madelaine318 Walker122      6         3     0.000000 0.163510019\n99      Soledad678 Calderón210     14         7   876.000000 0.214404223\n100          Vern731 Casper496      6         3     0.000000 0.163510019\n101      Annelle169 Schmidt332      4         2     0.000000 0.149159664\n102     Chantell995 Krajcik437     10         5   588.000000 0.194494721\n103         Chery887 Kohler843      4         2     0.000000 0.149159664\n104        Freeda113 Crooks415     16         8   588.000000 0.291478130\n105           Sam879 Rippin620      4         2     0.000000 0.203167421\n106      Sharron285 Okuneva707      4         2     0.000000 0.203167421\n107         Jamel269 Hudson301      4         2     0.000000 0.009049774\n108           Mana631 Boehm581      4         2     0.000000 0.009049774\n109         Sharron285 Batz141      4         2     0.000000 0.009049774\n110 Clemente531 Schamberger479     20        10   479.315385 0.297511312\n111        Guillermo498 Fay398     10         5     0.000000 0.221870287\n112  Miguel Ángel46 Delgado712     10         5     0.000000 0.221870287\n113          Shasta644 King743     10         5     0.000000 0.221870287\n114          Zachery872 Rau926     20        10   479.315385 0.297511312\n115        Shayne60 Gutmann970     12         6    70.688523 0.278205128\n116      January966 Roberts511     10         5     4.000000 0.203544495\n117          Kyle55 Collier206      6         3     0.000000 0.199019608\n118          Lacy523 Littel644      6         3     0.000000 0.199019608\n119       Roberto515 Macías944     18         9  1444.000000 0.280844646\n120  Harland508 Breitenberg711      6         3     0.000000 0.199019608\n121    Sherwood961 O'Conner199      6         3     0.000000 0.199019608\n122        Alberto639 Adame662      8         4     0.000000 0.268778281\n123         Lady554 Kovacek682      8         4     0.000000 0.268778281\n124    Cristopher265 Heaney114      6         3     0.000000 0.223755656\n125       Estella474 O'Hara248      6         3     0.000000 0.223755656\n126          Alonso270 Hand679      4         2     0.000000 0.009049774\n127        Estell607 Barton704      4         2     0.000000 0.009049774\n128        Lanette41 Murray856      4         2     0.000000 0.009049774\n129         Houston994 Funk324      8         4     0.000000 0.269532428\n130         Rebeca548 García15      8         4     0.000000 0.269532428\n131           Sid118 Hammes673      8         4     0.000000 0.269532428\n132            Ezra452 Torp761      6         3     0.000000 0.013574661\n133      Tracy345 Wilderman619      6         3     0.000000 0.013574661\n134   Christopher407 Fisher429      8         4     0.000000 0.272171946\n135      Heather971 Goldner995      8         4     0.000000 0.272171946\n136           Saul605 Ratke343     20        10  1704.000000 0.288009050\n137      Antonette454 Tromp100      6         3   147.000000 0.264253394\n138        Sasha806 D'Amore443      6         3   147.000000 0.264253394\n139           Bryon392 Mann644      6         3     0.000000 0.013574661\n140       Joslyn677 Friesen796      6         3     0.000000 0.013574661\n141  Margene509 Schamberger479      6         3     0.000000 0.013574661\n142      Patricia625 Aragón562      6         3     0.000000 0.013574661\n143          Kristin64 Will178      4         2     0.000000 0.015837104\n144          Leo278 Strosin214     10         5    12.000000 0.022624434\n145         Lonnie913 Ferry570      4         2     0.000000 0.015837104\n146         Jess275 Gutmann970      6         3     0.000000 0.200904977\n147      Florencia449 Araña824      6         3     0.000000 0.020361991\n148       Gordon377 Monahan736      6         3     0.000000 0.020361991\n149           Leah288 Sauer652      6         3     0.000000 0.020361991\n150    Rudolf736 Vandervort697     12         6    18.000000 0.027149321\n151      Maurice742 Pollich983      6         3     0.000000 0.189969834\n152       Rocky100 Schmeler639      6         3     0.000000 0.189969834\n153     Charles364 Prosacco716      6         3     0.000000 0.020361991\n154 Kimbra238 Runolfsdottir785      6         3     0.000000 0.020361991\n155       Laurie826 Pacocha935      6         3     0.000000 0.020361991\n156         Mario764 Aranda843      6         3     0.000000 0.018099548\n157        Miyoko154 Paucek755     10         5    12.000000 0.022624434\n158      Rosanna866 DuBuque211      6         3     0.000000 0.018099548\n159         Shemeka786 Conn188      6         3     0.000000 0.018099548\n160        Columbus656 Koch169      4         2     0.000000 0.190723982\n161          Derick144 King743     14         7     0.000000 0.289517345\n162        Eliana466 Wehner319     14         7     0.000000 0.289517345\n163        Jane262 Schmeler639     18         9   230.777778 0.294042232\n164     Jarvis643 Ankunding277     14         7     0.000000 0.289517345\n165           Maude482 Veum823     14         7     0.000000 0.289517345\n166        Parker433 Bailey598     14         7     0.000000 0.289517345\n167    Brooks264 Williamson769      8         4     0.000000 0.210935143\n168          Adán600 Alicea505      4         2     0.000000 0.013574661\n169         Isiah14 Nikolaus26      4         2     0.000000 0.013574661\n170          Cherish740 Toy286      6         3     0.000000 0.265007541\n171             Fae378 Wiza601      6         3     0.000000 0.265007541\n172       Anderson154 Kunze215      8         4     0.000000 0.231900452\n173      Calandra120 Hackett68      8         4     0.000000 0.231900452\n174      Cedrick207 Gleason633      8         4     0.000000 0.231900452\n175           Gino587 Block661     26        13  6534.000000 0.316365008\n176        Allyson474 Doyle959      8         4     0.000000 0.273680241\n177       Junior695 Leffler128      8         4     0.000000 0.273680241\n178   Jacinta658 Wintheiser220      6         3     0.000000 0.265007541\n179          Nilda678 Crona259      4         2     0.000000 0.013574661\n180      Shane235 Lueilwitz711      4         2     0.000000 0.013574661\n181      Jonathan639 Sporer811      8         4     0.000000 0.207616893\n182        Jeanie708 Turner526     12         6     0.000000 0.286953243\n183   Josefina523 O'Connell601     12         6     0.000000 0.286953243\n184       Dale454 Wilderman619      4         2     0.000000 0.009049774\n185      Olevia458 Hermiston71      4         2     0.000000 0.009049774\n186     Valentine262 Corwin846      4         2     0.000000 0.009049774\n187            Carl856 King743      8         4     0.000000 0.232051282\n188       Edwardo860 Larkin917      8         4     0.000000 0.232051282\n189    Enrique929 Caraballo427      6         3     0.000000 0.198491704\n190       Melvin857 Nikolaus26      6         3     0.000000 0.198491704\n191          Errol226 Kiehn525      8         4     0.000000 0.209426848\n192         Harland508 Ryan260      8         4     0.000000 0.209426848\n193    Sharyl439 Williamson769      8         4     0.000000 0.209426848\n194       Dana512 Wilkinson796      4         2     0.000000 0.015837104\n195       Quentin28 Fritsch593      4         2     0.000000 0.015837104\n196       Darnell564 Leannon79     18         9     8.000000 0.202036199\n197           Lynsey2 Lemke654     10         5     0.000000 0.192986425\n198         Neville893 Schoen8     10         5     0.000000 0.192986425\n199        Norah104 Jenkins714     10         5     0.000000 0.192986425\n200      Patrina117 Strosin214     18         9     8.000000 0.202036199\n201     Erwin847 Stiedemann542      4         2     0.000000 0.009049774\n202     Laurena366 Anderson154      4         2     0.000000 0.009049774\n203          Orpha286 Marks830      4         2     0.000000 0.009049774\n204      Antonia30 Elizondo706      6         3     0.000000 0.013574661\n205         Drew592 Streich926      6         3     0.000000 0.013574661\n206       Hellen346 Roberts511      6         3     0.000000 0.013574661\n207          Levi940 Abbott774      6         3     0.000000 0.013574661\n208       Harland508 Rippin620     12         6     0.000000 0.195248869\n209         Kati243 Ruecker817     12         6     0.000000 0.195248869\n210      Lizette501 Lebsack687     12         6     0.000000 0.195248869\n211       Latrisha74 Rippin620      6         3     0.000000 0.200150830\n212      Maynard46 Buckridge80      6         3     0.000000 0.200150830\n213           Azzie965 Feil794      6         3     0.000000 0.018099548\n214          Eldon28 Cassin499      6         3     0.000000 0.018099548\n215        Kaila152 Dibbert990      6         3     0.000000 0.018099548\n216          Ellyn26 Windler79      6         3     0.000000 0.216063348\n217         Fritz267 Kirlin939      6         3     0.000000 0.216063348\n218   María José279 Godínez202      6         3     0.000000 0.216063348\n219    Elvera717 Gusikowski974      2         1     0.000000 0.196606335\n220      Kareem959 Schaefer657      6         3     0.000000 0.202337858\n221         Silva841 Grimes165      6         3     0.000000 0.202337858\n222         Tracie996 Lesch175      6         3     0.000000 0.202337858\n223         Elijah719 White193      6         3     0.000000 0.200904977\n224          Fidel864 Swift555     16         8    32.833333 0.212971342\n225         Virgen207 Hyatt152     12         6   471.833333 0.274811463\n226        Zachery872 Pagac496     12         6    11.500000 0.208446456\n227  Kristopher775 Schiller186      4         2     0.000000 0.013574661\n228         Laine739 Torphy630      4         2     0.000000 0.013574661\n229      Leonarda398 Schumm995      8         4     8.000000 0.018099548\n230          Mathew182 Howe413      8         4    93.500000 0.268778281\n231           Ted955 Reilly981    110        55 18266.492186 0.442684766\n232     Vicente970 Armstrong51      6         3     0.000000 0.265761689\n233         Daniel959 Wolff180      6         3     0.000000 0.199396682\n234     Elmer371 Gusikowski974      6         3     0.000000 0.199396682\n235         Janet238 Crooks415      6         3     0.000000 0.199396682\n236      Karla801 Cummerata161     20        10   950.666667 0.282352941\n237       Clement78 Gleason633      8         4   147.000000 0.266515837\n238     Enriqueta274 Barton704      4         2     0.000000 0.191478130\n239            Kim439 Hyatt152      8         4   147.000000 0.266515837\n240           Janey243 Schoen8      4         2     0.000000 0.013574661\n241           Luna60 Littel644      4         2     0.000000 0.013574661\n242        Numbers230 Stehr398      6         3     0.000000 0.013574661\n243         Waylon572 Lakin515      6         3     0.000000 0.013574661\n244          Ina660 Hermann103      8         4     0.000000 0.226018100\n245        Jewel43 Kassulke119     58        29  5332.577167 0.345324284\n246          Josef103 Klein929      8         4     0.000000 0.226018100\n247     Majorie11 Bergstrom287      8         4     0.000000 0.226018100\n248        Salvador46 Wolff180      8         4     0.000000 0.226018100\n249     Cyrstal592 Mosciski958      8         4     0.000000 0.226018100\n250     Gerardo48 Bergstrom287      8         4     0.000000 0.226018100\n251        Shawn523 Padberg411      8         4     0.000000 0.226018100\n252          Thanh759 Weber641     16         8    37.666667 0.238838612\n253         Agnes294 Dooley940      4         2     0.000000 0.221493213\n254           Cody889 Ratke343      4         2     0.000000 0.221493213\n255          Abdul218 Boyer713     12         6     2.666667 0.195248869\n256         Cortez851 Price929     42        21  5155.666667 0.271870287\n257           Gene733 Ratke343      8         4     0.000000 0.190723982\n258         Lola232 Collado928     12         6     2.666667 0.195248869\n259    Marcelino726 Hilpert278      8         4     0.000000 0.190723982\n260       Delbert384 Carter549      8         4     0.000000 0.201659125\n261         Eddie505 Keeling57     14         7    74.666667 0.275565611\n262          Louis204 Hauck852     10         5    70.000000 0.271040724\n263          Thad495 Leannon79     10         5    70.000000 0.271040724\n264       Darlene91 Collier206     16         8   293.666667 0.249396682\n265          Jolynn62 Adams676      6         3     0.000000 0.227526395\n266       Junior695 Kuhlman484      6         3     0.000000 0.223755656\n267         Justin359 Hayes766      6         3     0.000000 0.223755656\n268        Cristi782 Miller503      8         4     8.000000 0.018099548\n269      Nevada145 Schmeler639      4         2     0.000000 0.013574661\n270         Shayla126 White193      4         2     0.000000 0.013574661\n271   Celestina960 Reichert620      8         4     0.000000 0.190723982\n272        Dante562 Reinger292     18         9    15.000000 0.202036199\n273       Junior695 Pacocha935      4         2     0.000000 0.009049774\n274     Latoria810 Eichmann909      4         2     0.000000 0.009049774\n275        Maryann106 Hintz995      4         2     0.000000 0.009049774\n276          Dusty207 Lynch190     12         6    22.800000 0.236576169\n277           Rhonda22 Bins636      6         3     0.000000 0.223755656\n278         Shonna561 Feest103      6         3     0.000000 0.223755656\n279       Anderson154 Lemke654     30        15  2096.363004 0.301583710\n280   Felicidad691 Luettgen772      6         3     0.000000 0.217722474\n281      Jettie913 Rodriguez71      8         4    78.857143 0.219984917\n282          Mertie42 Lakin515     20        10   575.174481 0.252790347\n283      Charley358 Effertz744      6         3     0.000000 0.013574661\n284     Cleveland582 Kuphal363      6         3     0.000000 0.013574661\n285        Lauretta754 Dare640      6         3     0.000000 0.013574661\n286     Sparkle906 Bernhard322      6         3     0.000000 0.013574661\n287       Arminda86 Trantow673     12         6    18.000000 0.027149321\n288      Arturo47 Maldonado119      6         3     0.000000 0.020361991\n289         Mickey576 Borer986      6         3     0.000000 0.020361991\n290        Rhett759 Padberg411      6         3     0.000000 0.020361991\n291         Almeta56 Lehner980      6         3     0.000000 0.263499246\n292        Ellie521 Nicolas769      6         3     0.000000 0.263499246\n293           Marth98 Mayer370      6         3     0.000000 0.263499246\n294           Cleo27 Lehner980      4         2     0.000000 0.013574661\n295        Hong136 Kassulke119      4         2     0.000000 0.013574661\n296      Nathanael908 Rogahn59      8         4     8.000000 0.018099548\n297           Aubrey96 Emard19      4         2     0.000000 0.180176686\n298          Bud153 Parisian75     18         9   308.000000 0.279713424\n299        Darrick836 Hoppe518     12         6   292.000000 0.273680241\n300           Jules135 Emard19     14         7   288.000000 0.275188537\n301        Mateo562 Barajas558     12         6   292.000000 0.273680241\n302         Monroe732 Mills423     10         5     0.000000 0.270663650\n303      Carmelita854 Tromp100      6         3     0.000000 0.264253394\n304          Lezlie553 Koss676      2         1     0.000000 0.151669899\n305    Rayford811 Bashirian201      6         3   296.000000 0.197360483\n306        Assunta351 Haley279      6         3     0.000000 0.217722474\n307          Ross213 Wisozk929     12         6    54.000000 0.224509804\n308     Augustine565 Brekke496     10         5     9.000000 0.209879336\n309        Joanna347 Abbott774     16         8  1113.000000 0.283484163\n310        Lauri399 Keebler762      4         2     0.000000 0.198567119\n311          Jorge203 Harvey63      6         3     0.000000 0.020361991\n312        King743 Predovic534      6         3     0.000000 0.020361991\n313         Logan497 Fisher429      6         3     0.000000 0.020361991\n314      Delicia67 Bernhard322     10         5    62.617094 0.275942685\n315      Randy380 Bergstrom287     18         9   373.355189 0.284992459\n316          Elisha578 Conn188      6         3     0.000000 0.267269985\n317       Emory494 Schuster709     12         6   654.833333 0.274811463\n318   Sherwood961 Aufderhar910     12         6   468.500000 0.274811463\n319         Buck819 Johnson679      6         3     0.000000 0.163510019\n320     Madelaine318 Walker122      6         3     0.000000 0.163510019\n321     Soledad678 Calderón210     14         7   876.000000 0.214404223\n322          Vern731 Casper496      6         3     0.000000 0.163510019\n323      Annelle169 Schmidt332      4         2     0.000000 0.149159664\n324     Chantell995 Krajcik437     10         5   588.000000 0.194494721\n325         Chery887 Kohler843      4         2     0.000000 0.149159664\n326        Freeda113 Crooks415     16         8   588.000000 0.291478130\n327           Sam879 Rippin620      4         2     0.000000 0.203167421\n328      Sharron285 Okuneva707      4         2     0.000000 0.203167421\n329         Jamel269 Hudson301      4         2     0.000000 0.009049774\n330           Mana631 Boehm581      4         2     0.000000 0.009049774\n331         Sharron285 Batz141      4         2     0.000000 0.009049774\n332 Clemente531 Schamberger479     20        10   479.315385 0.297511312\n333        Guillermo498 Fay398     10         5     0.000000 0.221870287\n334  Miguel Ángel46 Delgado712     10         5     0.000000 0.221870287\n335          Shasta644 King743     10         5     0.000000 0.221870287\n336          Zachery872 Rau926     20        10   479.315385 0.297511312\n337        Shayne60 Gutmann970     12         6    70.688523 0.278205128\n338      January966 Roberts511     10         5     4.000000 0.203544495\n339          Kyle55 Collier206      6         3     0.000000 0.199019608\n340          Lacy523 Littel644      6         3     0.000000 0.199019608\n341       Roberto515 Macías944     18         9  1444.000000 0.280844646\n342  Harland508 Breitenberg711      6         3     0.000000 0.199019608\n343    Sherwood961 O'Conner199      6         3     0.000000 0.199019608\n344        Alberto639 Adame662      8         4     0.000000 0.268778281\n345         Lady554 Kovacek682      8         4     0.000000 0.268778281\n346    Cristopher265 Heaney114      6         3     0.000000 0.223755656\n347       Estella474 O'Hara248      6         3     0.000000 0.223755656\n348          Alonso270 Hand679      4         2     0.000000 0.009049774\n349        Estell607 Barton704      4         2     0.000000 0.009049774\n350        Lanette41 Murray856      4         2     0.000000 0.009049774\n351         Houston994 Funk324      8         4     0.000000 0.269532428\n352         Rebeca548 García15      8         4     0.000000 0.269532428\n353           Sid118 Hammes673      8         4     0.000000 0.269532428\n354            Ezra452 Torp761      6         3     0.000000 0.013574661\n355      Tracy345 Wilderman619      6         3     0.000000 0.013574661\n356   Christopher407 Fisher429      8         4     0.000000 0.272171946\n357      Heather971 Goldner995      8         4     0.000000 0.272171946\n358           Saul605 Ratke343     20        10  1704.000000 0.288009050\n359      Antonette454 Tromp100      6         3   147.000000 0.264253394\n360        Sasha806 D'Amore443      6         3   147.000000 0.264253394\n361           Bryon392 Mann644      6         3     0.000000 0.013574661\n362       Joslyn677 Friesen796      6         3     0.000000 0.013574661\n363  Margene509 Schamberger479      6         3     0.000000 0.013574661\n364      Patricia625 Aragón562      6         3     0.000000 0.013574661\n365          Kristin64 Will178      4         2     0.000000 0.015837104\n366          Leo278 Strosin214     10         5    12.000000 0.022624434\n367         Lonnie913 Ferry570      4         2     0.000000 0.015837104\n368         Jess275 Gutmann970      6         3     0.000000 0.200904977\n369      Florencia449 Araña824      6         3     0.000000 0.020361991\n370       Gordon377 Monahan736      6         3     0.000000 0.020361991\n371           Leah288 Sauer652      6         3     0.000000 0.020361991\n372    Rudolf736 Vandervort697     12         6    18.000000 0.027149321\n373      Maurice742 Pollich983      6         3     0.000000 0.189969834\n374       Rocky100 Schmeler639      6         3     0.000000 0.189969834\n375     Charles364 Prosacco716      6         3     0.000000 0.020361991\n376 Kimbra238 Runolfsdottir785      6         3     0.000000 0.020361991\n377       Laurie826 Pacocha935      6         3     0.000000 0.020361991\n378         Mario764 Aranda843      6         3     0.000000 0.018099548\n379        Miyoko154 Paucek755     10         5    12.000000 0.022624434\n380      Rosanna866 DuBuque211      6         3     0.000000 0.018099548\n381         Shemeka786 Conn188      6         3     0.000000 0.018099548\n382        Columbus656 Koch169      4         2     0.000000 0.190723982\n383          Derick144 King743     14         7     0.000000 0.289517345\n384        Eliana466 Wehner319     14         7     0.000000 0.289517345\n385        Jane262 Schmeler639     18         9   230.777778 0.294042232\n386     Jarvis643 Ankunding277     14         7     0.000000 0.289517345\n387           Maude482 Veum823     14         7     0.000000 0.289517345\n388        Parker433 Bailey598     14         7     0.000000 0.289517345\n389    Brooks264 Williamson769      8         4     0.000000 0.210935143\n390          Adán600 Alicea505      4         2     0.000000 0.013574661\n391         Isiah14 Nikolaus26      4         2     0.000000 0.013574661\n392          Cherish740 Toy286      6         3     0.000000 0.265007541\n393             Fae378 Wiza601      6         3     0.000000 0.265007541\n394       Anderson154 Kunze215      8         4     0.000000 0.231900452\n395      Calandra120 Hackett68      8         4     0.000000 0.231900452\n396      Cedrick207 Gleason633      8         4     0.000000 0.231900452\n397           Gino587 Block661     26        13  6534.000000 0.316365008\n398        Allyson474 Doyle959      8         4     0.000000 0.273680241\n399       Junior695 Leffler128      8         4     0.000000 0.273680241\n400   Jacinta658 Wintheiser220      6         3     0.000000 0.265007541\n401          Nilda678 Crona259      4         2     0.000000 0.013574661\n402      Shane235 Lueilwitz711      4         2     0.000000 0.013574661\n403      Jonathan639 Sporer811      8         4     0.000000 0.207616893\n404        Jeanie708 Turner526     12         6     0.000000 0.286953243\n405   Josefina523 O'Connell601     12         6     0.000000 0.286953243\n406       Dale454 Wilderman619      4         2     0.000000 0.009049774\n407      Olevia458 Hermiston71      4         2     0.000000 0.009049774\n408     Valentine262 Corwin846      4         2     0.000000 0.009049774\n409            Carl856 King743      8         4     0.000000 0.232051282\n410       Edwardo860 Larkin917      8         4     0.000000 0.232051282\n411    Enrique929 Caraballo427      6         3     0.000000 0.198491704\n412       Melvin857 Nikolaus26      6         3     0.000000 0.198491704\n413          Errol226 Kiehn525      8         4     0.000000 0.209426848\n414         Harland508 Ryan260      8         4     0.000000 0.209426848\n415    Sharyl439 Williamson769      8         4     0.000000 0.209426848\n416       Dana512 Wilkinson796      4         2     0.000000 0.015837104\n417       Quentin28 Fritsch593      4         2     0.000000 0.015837104\n418       Darnell564 Leannon79     18         9     8.000000 0.202036199\n419           Lynsey2 Lemke654     10         5     0.000000 0.192986425\n420         Neville893 Schoen8     10         5     0.000000 0.192986425\n421        Norah104 Jenkins714     10         5     0.000000 0.192986425\n422      Patrina117 Strosin214     18         9     8.000000 0.202036199\n423     Erwin847 Stiedemann542      4         2     0.000000 0.009049774\n424     Laurena366 Anderson154      4         2     0.000000 0.009049774\n425          Orpha286 Marks830      4         2     0.000000 0.009049774\n426      Antonia30 Elizondo706      6         3     0.000000 0.013574661\n427         Drew592 Streich926      6         3     0.000000 0.013574661\n428       Hellen346 Roberts511      6         3     0.000000 0.013574661\n429          Levi940 Abbott774      6         3     0.000000 0.013574661\n430       Harland508 Rippin620     12         6     0.000000 0.195248869\n431         Kati243 Ruecker817     12         6     0.000000 0.195248869\n432      Lizette501 Lebsack687     12         6     0.000000 0.195248869\n433       Latrisha74 Rippin620      6         3     0.000000 0.200150830\n434      Maynard46 Buckridge80      6         3     0.000000 0.200150830\n435           Azzie965 Feil794      6         3     0.000000 0.018099548\n436          Eldon28 Cassin499      6         3     0.000000 0.018099548\n437        Kaila152 Dibbert990      6         3     0.000000 0.018099548\n438          Ellyn26 Windler79      6         3     0.000000 0.216063348\n439         Fritz267 Kirlin939      6         3     0.000000 0.216063348\n440   María José279 Godínez202      6         3     0.000000 0.216063348\n441    Elvera717 Gusikowski974      2         1     0.000000 0.196606335\n442      Kareem959 Schaefer657      6         3     0.000000 0.202337858\n443         Silva841 Grimes165      6         3     0.000000 0.202337858\n444         Tracie996 Lesch175      6         3     0.000000 0.202337858\n    constraint\n1   0.33333333\n2   0.12500000\n3   0.16666667\n4   0.16666667\n5   0.50000000\n6   0.50000000\n7   0.25000000\n8   0.25000000\n9   0.01818182\n10  0.33333333\n11  0.33333333\n12  0.33333333\n13  0.33333333\n14  0.10000000\n15  0.25000000\n16  0.50000000\n17  0.25000000\n18  0.50000000\n19  0.50000000\n20  0.33333333\n21  0.33333333\n22  0.25000000\n23  0.03448276\n24  0.25000000\n25  0.25000000\n26  0.25000000\n27  0.25000000\n28  0.25000000\n29  0.25000000\n30  0.12500000\n31  0.50000000\n32  0.50000000\n33  0.16666667\n34  0.04761905\n35  0.25000000\n36  0.16666667\n37  0.25000000\n38  0.25000000\n39  0.14285714\n40  0.20000000\n41  0.20000000\n42  0.12500000\n43  0.33333333\n44  0.33333333\n45  0.33333333\n46  0.25000000\n47  0.50000000\n48  0.50000000\n49  0.25000000\n50  0.11111111\n51  0.50000000\n52  0.50000000\n53  0.50000000\n54  0.16666667\n55  0.33333333\n56  0.33333333\n57  0.06666667\n58  0.33333333\n59  0.25000000\n60  0.10000000\n61  0.33333333\n62  0.33333333\n63  0.33333333\n64  0.33333333\n65  0.16666667\n66  0.33333333\n67  0.33333333\n68  0.33333333\n69  0.33333333\n70  0.33333333\n71  0.33333333\n72  0.50000000\n73  0.50000000\n74  0.25000000\n75  0.50000000\n76  0.11111111\n77  0.16666667\n78  0.14285714\n79  0.16666667\n80  0.20000000\n81  0.33333333\n82  1.00000000\n83  0.33333333\n84  0.33333333\n85  0.16666667\n86  0.20000000\n87  0.12500000\n88  0.50000000\n89  0.33333333\n90  0.33333333\n91  0.33333333\n92  0.20000000\n93  0.11111111\n94  0.33333333\n95  0.16666667\n96  0.16666667\n97  0.33333333\n98  0.33333333\n99  0.14285714\n100 0.33333333\n101 0.50000000\n102 0.20000000\n103 0.50000000\n104 0.12500000\n105 0.50000000\n106 0.50000000\n107 0.50000000\n108 0.50000000\n109 0.50000000\n110 0.10000000\n111 0.20000000\n112 0.20000000\n113 0.20000000\n114 0.10000000\n115 0.16666667\n116 0.20000000\n117 0.33333333\n118 0.33333333\n119 0.11111111\n120 0.33333333\n121 0.33333333\n122 0.25000000\n123 0.25000000\n124 0.33333333\n125 0.33333333\n126 0.50000000\n127 0.50000000\n128 0.50000000\n129 0.25000000\n130 0.25000000\n131 0.25000000\n132 0.33333333\n133 0.33333333\n134 0.25000000\n135 0.25000000\n136 0.10000000\n137 0.33333333\n138 0.33333333\n139 0.33333333\n140 0.33333333\n141 0.33333333\n142 0.33333333\n143 0.50000000\n144 0.20000000\n145 0.50000000\n146 0.33333333\n147 0.33333333\n148 0.33333333\n149 0.33333333\n150 0.16666667\n151 0.33333333\n152 0.33333333\n153 0.33333333\n154 0.33333333\n155 0.33333333\n156 0.33333333\n157 0.20000000\n158 0.33333333\n159 0.33333333\n160 0.50000000\n161 0.14285714\n162 0.14285714\n163 0.11111111\n164 0.14285714\n165 0.14285714\n166 0.14285714\n167 0.25000000\n168 0.50000000\n169 0.50000000\n170 0.33333333\n171 0.33333333\n172 0.25000000\n173 0.25000000\n174 0.25000000\n175 0.07692308\n176 0.25000000\n177 0.25000000\n178 0.33333333\n179 0.50000000\n180 0.50000000\n181 0.25000000\n182 0.16666667\n183 0.16666667\n184 0.50000000\n185 0.50000000\n186 0.50000000\n187 0.25000000\n188 0.25000000\n189 0.33333333\n190 0.33333333\n191 0.25000000\n192 0.25000000\n193 0.25000000\n194 0.50000000\n195 0.50000000\n196 0.11111111\n197 0.20000000\n198 0.20000000\n199 0.20000000\n200 0.11111111\n201 0.50000000\n202 0.50000000\n203 0.50000000\n204 0.33333333\n205 0.33333333\n206 0.33333333\n207 0.33333333\n208 0.16666667\n209 0.16666667\n210 0.16666667\n211 0.33333333\n212 0.33333333\n213 0.33333333\n214 0.33333333\n215 0.33333333\n216 0.33333333\n217 0.33333333\n218 0.33333333\n219 1.00000000\n220 0.33333333\n221 0.33333333\n222 0.33333333\n223 0.33333333\n224 0.12500000\n225 0.16666667\n226 0.16666667\n227 0.50000000\n228 0.50000000\n229 0.25000000\n230 0.25000000\n231 0.01818182\n232 0.33333333\n233 0.33333333\n234 0.33333333\n235 0.33333333\n236 0.10000000\n237 0.25000000\n238 0.50000000\n239 0.25000000\n240 0.50000000\n241 0.50000000\n242 0.33333333\n243 0.33333333\n244 0.25000000\n245 0.03448276\n246 0.25000000\n247 0.25000000\n248 0.25000000\n249 0.25000000\n250 0.25000000\n251 0.25000000\n252 0.12500000\n253 0.50000000\n254 0.50000000\n255 0.16666667\n256 0.04761905\n257 0.25000000\n258 0.16666667\n259 0.25000000\n260 0.25000000\n261 0.14285714\n262 0.20000000\n263 0.20000000\n264 0.12500000\n265 0.33333333\n266 0.33333333\n267 0.33333333\n268 0.25000000\n269 0.50000000\n270 0.50000000\n271 0.25000000\n272 0.11111111\n273 0.50000000\n274 0.50000000\n275 0.50000000\n276 0.16666667\n277 0.33333333\n278 0.33333333\n279 0.06666667\n280 0.33333333\n281 0.25000000\n282 0.10000000\n283 0.33333333\n284 0.33333333\n285 0.33333333\n286 0.33333333\n287 0.16666667\n288 0.33333333\n289 0.33333333\n290 0.33333333\n291 0.33333333\n292 0.33333333\n293 0.33333333\n294 0.50000000\n295 0.50000000\n296 0.25000000\n297 0.50000000\n298 0.11111111\n299 0.16666667\n300 0.14285714\n301 0.16666667\n302 0.20000000\n303 0.33333333\n304 1.00000000\n305 0.33333333\n306 0.33333333\n307 0.16666667\n308 0.20000000\n309 0.12500000\n310 0.50000000\n311 0.33333333\n312 0.33333333\n313 0.33333333\n314 0.20000000\n315 0.11111111\n316 0.33333333\n317 0.16666667\n318 0.16666667\n319 0.33333333\n320 0.33333333\n321 0.14285714\n322 0.33333333\n323 0.50000000\n324 0.20000000\n325 0.50000000\n326 0.12500000\n327 0.50000000\n328 0.50000000\n329 0.50000000\n330 0.50000000\n331 0.50000000\n332 0.10000000\n333 0.20000000\n334 0.20000000\n335 0.20000000\n336 0.10000000\n337 0.16666667\n338 0.20000000\n339 0.33333333\n340 0.33333333\n341 0.11111111\n342 0.33333333\n343 0.33333333\n344 0.25000000\n345 0.25000000\n346 0.33333333\n347 0.33333333\n348 0.50000000\n349 0.50000000\n350 0.50000000\n351 0.25000000\n352 0.25000000\n353 0.25000000\n354 0.33333333\n355 0.33333333\n356 0.25000000\n357 0.25000000\n358 0.10000000\n359 0.33333333\n360 0.33333333\n361 0.33333333\n362 0.33333333\n363 0.33333333\n364 0.33333333\n365 0.50000000\n366 0.20000000\n367 0.50000000\n368 0.33333333\n369 0.33333333\n370 0.33333333\n371 0.33333333\n372 0.16666667\n373 0.33333333\n374 0.33333333\n375 0.33333333\n376 0.33333333\n377 0.33333333\n378 0.33333333\n379 0.20000000\n380 0.33333333\n381 0.33333333\n382 0.50000000\n383 0.14285714\n384 0.14285714\n385 0.11111111\n386 0.14285714\n387 0.14285714\n388 0.14285714\n389 0.25000000\n390 0.50000000\n391 0.50000000\n392 0.33333333\n393 0.33333333\n394 0.25000000\n395 0.25000000\n396 0.25000000\n397 0.07692308\n398 0.25000000\n399 0.25000000\n400 0.33333333\n401 0.50000000\n402 0.50000000\n403 0.25000000\n404 0.16666667\n405 0.16666667\n406 0.50000000\n407 0.50000000\n408 0.50000000\n409 0.25000000\n410 0.25000000\n411 0.33333333\n412 0.33333333\n413 0.25000000\n414 0.25000000\n415 0.25000000\n416 0.50000000\n417 0.50000000\n418 0.11111111\n419 0.20000000\n420 0.20000000\n421 0.20000000\n422 0.11111111\n423 0.50000000\n424 0.50000000\n425 0.50000000\n426 0.33333333\n427 0.33333333\n428 0.33333333\n429 0.33333333\n430 0.16666667\n431 0.16666667\n432 0.16666667\n433 0.33333333\n434 0.33333333\n435 0.33333333\n436 0.33333333\n437 0.33333333\n438 0.33333333\n439 0.33333333\n440 0.33333333\n441 1.00000000\n442 0.33333333\n443 0.33333333\n444 0.33333333\n\n\n\n# To use cug.test, we need an adjacency matrix:\nprovider.mat &lt;- provider.stat[,]\n\n# compare network transitivity to null conditional on size\ntrans.cug &lt;- cug.test(provider.mat,\n                      FUN = gtrans,\n                      mode = \"digraph\",\n                      cmode = \"size\")\n\ntrans.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: size \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 1000 \n\nObserved Value: 0.3677613 \nPr(X&gt;=Obs): 1 \nPr(X&lt;=Obs): 0 \n\n\nHistogram with observed comp. replication statistics:\n\n# plot observed vs. simulation results\nplot(trans.cug)\n\n\n\n\n\n# t-stst between observed and simulated networks\n(trans.cug$obs.stat - mean(trans.cug$rep.stat))/sd(trans.cug$rep.stat)\n\n[1] -58.93684\n\n\nLet’s create an easy function to return the t-stat for cug.test:\n\ncug.t &lt;- function(cug.object){\n  (cug.object$obs.stat - mean(cug.object$rep.stat))/sd(cug.object$rep.stat)\n}\n\n\n# comapre network transitivity to null conditional on size\ntrans.cug &lt;- cug.test(provider.mat,\n                      FUN = gtrans,\n                      mode = \"digraph\",\n                      cmode = \"size\",\n                      reps = 100)\ntrans.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: size \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 100 \n\nObserved Value: 0.3677613 \nPr(X&gt;=Obs): 1 \nPr(X&lt;=Obs): 0 \n\n\n\n# plot observed vs. simulated\nplot(trans.cug)\n\n\n\n\n\n# t-stat between observed and simulated networks\ncug.t(trans.cug)\n\n[1] -55.6083\n\n\n\n# compare network degree centralization to null conditional on size\nc.degree.cug &lt;- cug.test(provider.stat,\n                         FUN = centralization,\n                         FUN.args = list(FUN = degree,\n                                      cmode = \"indegree\"),\n                         mode=\"digraph\",\n                         cmode=\"size\")\nc.degree.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: size \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 1000 \n\nObserved Value: 0.2296431 \nPr(X&gt;=Obs): 0 \nPr(X&lt;=Obs): 1 \n\n\n\n# plot\nplot(c.degree.cug)\n\n\n\n\n\n# t-stat\ncug.t(c.degree.cug)\n\n[1] 10.26402\n\n\n\nb.degree.cug &lt;- cug.test(provider.stat,\n                         FUN = centralization,\n                         FUN.arg = list(FUN=betweenness,\n                                        cmode = \"directed\"),\n                         mode = \"digraph\",\n                         cmode = \"size\",\n                         reps = 100)\n\nb.degree.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: size \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 100 \n\nObserved Value: 0.3726014 \nPr(X&gt;=Obs): 0 \nPr(X&lt;=Obs): 1 \n\n\nobs value of the tstatistic is extremely unlikely to occur under the null hypothesis, suggesting statistical significance\n\nplot(b.degree.cug)\n\n\n\n\n\n# t-stat\ncug.t(b.degree.cug)\n\n[1] 3850.261\n\n\n\n# compare network transitivity to null conditional on dyads\ntrans.cug &lt;- cug.test(provider.stat,\n                      FUN = gtrans,\n                      mode = \"digraph\",\n                      cmode = \"dyad\")\ntrans.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: dyad.census \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 1000 \n\nObserved Value: 0.3677613 \nPr(X&gt;=Obs): 0 \nPr(X&lt;=Obs): 1 \n\n\n\nplot(trans.cug)\n\n\n\n\n\n# t-stat\ncug.t(trans.cug)\n\n[1] 68.94248\n\n\nThe edges property is also built into the cug.test() function. Here we run it with only 100 reps, because this is clearly not a random network!\n\n# compare network transitivity to null conditional on edges (density)\ntrans.cug &lt;- cug.test(provider.stat,\n                      FUN=gtrans,\n                      mode = \"digraph\",\n                      cmode = \"edges\",\n                      reps = 100)\n\ntrans.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: edges \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 100 \n\nObserved Value: 0.3677613 \nPr(X&gt;=Obs): 0 \nPr(X&lt;=Obs): 1 \n\n\n\nplot(trans.cug)\n\n\n\n\n\ncug.t(trans.cug)\n\n[1] 166.6866\n\n\n#ENCOUNTER LEVEL DATA\n\n# To use cug.test, we need an adjacency matrix:\nencounter.mat &lt;- encounters.stat[,]\n\n# compare network transitivity to null conditional on size\nenc.trans.cug &lt;- cug.test(encounter.mat,\n                      FUN = gtrans,\n                      mode = \"digraph\",\n                      cmode = \"size\")\n\nenc.trans.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: size \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 1000 \n\nObserved Value: 0 \nPr(X&gt;=Obs): 1 \nPr(X&lt;=Obs): 0 \n\n\n\n# plot observed vs. simulation results\nplot(enc.trans.cug)\n\n\n\n\n\ngden(encounters.stat)\n\n[1] 0.007212657\n\n\n\nigraph::components(encounters.ig)$no\n\n[1] 17\n\n\n\nsummary(encounters.stat %e%\"dist\")\n\nLength  Class   Mode \n     0   NULL   NULL \n\n\n\nencounters.nodes &lt;- data.frame(\n  name = encounters.stat%v%\"vertex.names\",\n  degree=sna::degree(encounters.stat, gmode = \"digraph\"),\n  degree.wt = igraph::strength(encounters.ig),\n  betweenness = sna::betweenness(encounters.stat, gmode=\"digraph\"),\n  close=sna::closeness(encounters.stat, cmode = \"suminvdir\"),\n  constraint=igraph::constraint(encounters.ig)\n)\n\nencounters.nodes\n\n                                                 name degree degree.wt\nAdam631 Hoppe518                     Adam631 Hoppe518      8         4\nAlesha810 Heaney114               Alesha810 Heaney114      6         3\nAlissa315 Altenwerth646       Alissa315 Altenwerth646      8         4\nAnalisa263 Kohler843             Analisa263 Kohler843      8         4\nAnnice210 Gleason633             Annice210 Gleason633      6         3\nAnthony633 Kutch271               Anthony633 Kutch271      6         3\nBenedict104 Hintz995             Benedict104 Hintz995      4         2\nCarl856 Rempel203                   Carl856 Rempel203     10         5\nChanell45 Morissette863       Chanell45 Morissette863     10         5\nChaya236 Sporer811                 Chaya236 Sporer811      6         3\nCherise743 Prosacco716         Cherise743 Prosacco716     10         5\nCindi877 Hane680                     Cindi877 Hane680     10         5\nCruz300 Wilderman619             Cruz300 Wilderman619      8         4\nDamian46 Dach178                     Damian46 Dach178      4         2\nDiana207 Stamm704                   Diana207 Stamm704      6         3\nDinorah501 Bechtelar572       Dinorah501 Bechtelar572     10         5\nDonald774 Krajcik437             Donald774 Krajcik437      6         3\nDorothea248 Fritsch593         Dorothea248 Fritsch593      8         4\nDortha70 Rutherford999         Dortha70 Rutherford999      8         4\nDusti191 Maggio310                 Dusti191 Maggio310      8         4\nElease461 Boehm581                 Elease461 Boehm581      8         4\nEsther279 Schroeder447         Esther279 Schroeder447      8         4\nEverette494 O'Hara248           Everette494 O'Hara248      6         3\nGino587 Vandervort697           Gino587 Vandervort697      6         3\nGordon377 Marquardt819         Gordon377 Marquardt819     12         6\nGuadalupe206 Wuckert783       Guadalupe206 Wuckert783      8         4\nGwen761 Keeling57                   Gwen761 Keeling57      4         2\nIvan258 Hills818                     Ivan258 Hills818      8         4\nJeanelle736 Simonis280         Jeanelle736 Simonis280      6         3\nJeanette800 Schinner682       Jeanette800 Schinner682      8         4\nJohnnie679 Hand679                 Johnnie679 Hand679      8         4\nJohnny786 Smith67                   Johnny786 Smith67      6         3\nJorge203 Ferry570                   Jorge203 Ferry570      8         4\nJulianne852 Barrows492         Julianne852 Barrows492      8         4\nKandis954 Koepp521                 Kandis954 Koepp521      6         3\nKathlyn335 Wisozk929             Kathlyn335 Wisozk929      6         3\nKathrine376 Bosco882             Kathrine376 Bosco882      6         3\nKrystina167 Muller251           Krystina167 Muller251      6         3\nLan153 Schmidt332                   Lan153 Schmidt332     12         6\nLani848 Cole117                       Lani848 Cole117      8         4\nLawerence6 Grimes165             Lawerence6 Grimes165      8         4\nLeland44 Huels583                   Leland44 Huels583      6         3\nLemuel304 Mante251                 Lemuel304 Mante251     10         5\nLeonel449 Witting912             Leonel449 Witting912     10         5\nLorina403 Cronin387               Lorina403 Cronin387      6         3\nLorretta561 Metz686               Lorretta561 Metz686      8         4\nLou594 Krajcik437                   Lou594 Krajcik437      6         3\nMadelyn308 Schumm995             Madelyn308 Schumm995     10         5\nMarcos263 Mills423                 Marcos263 Mills423      6         3\nMargarito178 Schulist381     Margarito178 Schulist381      8         4\nMario764 Glover433                 Mario764 Glover433     10         5\nMaryellen651 Conn188             Maryellen651 Conn188      6         3\nMia349 Runte676                       Mia349 Runte676      8         4\nMonroe732 Fritsch593             Monroe732 Fritsch593      6         3\nMose244 Cummerata161             Mose244 Cummerata161      8         4\nMozelle144 Zboncak558           Mozelle144 Zboncak558      8         4\nNelida367 Emard19                   Nelida367 Emard19      8         4\nOdilia72 Upton904                   Odilia72 Upton904      8         4\nOla364 Kreiger457                   Ola364 Kreiger457      8         4\nOliva247 Braun514                   Oliva247 Braun514      8         4\nOuida808 Carroll471               Ouida808 Carroll471      6         3\nRamon749 Kozey370                   Ramon749 Kozey370     16         8\nRegan713 Kertzmann286           Regan713 Kertzmann286     10         5\nRod343 Prosacco716                 Rod343 Prosacco716      6         3\nRolland302 Kassulke119         Rolland302 Kassulke119      8         4\nRosamaria757 Orn563               Rosamaria757 Orn563     10         5\nRudy520 Hettinger594             Rudy520 Hettinger594     10         5\nRupert654 Jenkins714             Rupert654 Jenkins714      8         4\nRussell422 Stracke611           Russell422 Stracke611      6         3\nRyann170 Spencer878               Ryann170 Spencer878     10         5\nSabine292 Feil794                   Sabine292 Feil794     14         7\nSandee884 Rice937                   Sandee884 Rice937      6         3\nSerena400 Powlowski563         Serena400 Powlowski563     10         5\nShara355 Bruen238                   Shara355 Bruen238      8         4\nShila857 Heller342                 Shila857 Heller342     10         5\nSpencer878 Bailey598             Spencer878 Bailey598      6         3\nStanley702 Cremin516             Stanley702 Cremin516     12         6\nStephan15 Auer97                     Stephan15 Auer97      6         3\nTera136 Swift555                     Tera136 Swift555      8         4\nTheodore876 Thiel172             Theodore876 Thiel172      8         4\nTomika243 Walker122               Tomika243 Walker122     14         7\nTommy814 Miller503                 Tommy814 Miller503      8         4\nTroy560 Kohler843                   Troy560 Kohler843      8         4\nTyler508 Ankunding277           Tyler508 Ankunding277      8         4\nWilburn655 Sipes176               Wilburn655 Sipes176      4         2\nWilfred787 Nienow652             Wilfred787 Nienow652      8         4\nElijah719 White193                 Elijah719 White193      2         1\nFidel864 Swift555                   Fidel864 Swift555      6         3\nVirgen207 Hyatt152                 Virgen207 Hyatt152      6         3\nZachery872 Pagac496               Zachery872 Pagac496      6         3\nKristopher775 Schiller186   Kristopher775 Schiller186      2         1\nLaine739 Torphy630                 Laine739 Torphy630      2         1\nLeonarda398 Schumm995           Leonarda398 Schumm995      4         2\nMathew182 Howe413                   Mathew182 Howe413      4         2\nTed955 Reilly981                     Ted955 Reilly981     34        17\nVicente970 Armstrong51         Vicente970 Armstrong51      2         1\nDaniel959 Wolff180                 Daniel959 Wolff180      2         1\nElmer371 Gusikowski974         Elmer371 Gusikowski974      2         1\nJanet238 Crooks415                 Janet238 Crooks415      2         1\nKarla801 Cummerata161           Karla801 Cummerata161      8         4\nClement78 Gleason633             Clement78 Gleason633      4         2\nEnriqueta274 Barton704         Enriqueta274 Barton704      2         1\nKim439 Hyatt152                       Kim439 Hyatt152      4         2\nJaney243 Schoen8                     Janey243 Schoen8      2         1\nLuna60 Littel644                     Luna60 Littel644      2         1\nNumbers230 Stehr398               Numbers230 Stehr398      4         2\nWaylon572 Lakin515                 Waylon572 Lakin515      4         2\nIna660 Hermann103                   Ina660 Hermann103      2         1\nJewel43 Kassulke119               Jewel43 Kassulke119     18         9\nJosef103 Klein929                   Josef103 Klein929      2         1\nMajorie11 Bergstrom287         Majorie11 Bergstrom287      2         1\nSalvador46 Wolff180               Salvador46 Wolff180      2         1\nCyrstal592 Mosciski958         Cyrstal592 Mosciski958      2         1\nGerardo48 Bergstrom287         Gerardo48 Bergstrom287      2         1\nShawn523 Padberg411               Shawn523 Padberg411      2         1\nThanh759 Weber641                   Thanh759 Weber641      8         4\nAgnes294 Dooley940                 Agnes294 Dooley940      2         1\nCody889 Ratke343                     Cody889 Ratke343      2         1\nAbdul218 Boyer713                   Abdul218 Boyer713      4         2\nCortez851 Price929                 Cortez851 Price929     12         6\nGene733 Ratke343                     Gene733 Ratke343      2         1\nLola232 Collado928                 Lola232 Collado928      4         2\nMarcelino726 Hilpert278       Marcelino726 Hilpert278      2         1\nDelbert384 Carter549             Delbert384 Carter549      2         1\nEddie505 Keeling57                 Eddie505 Keeling57      6         3\nLouis204 Hauck852                   Louis204 Hauck852      4         2\nThad495 Leannon79                   Thad495 Leannon79      4         2\nDarlene91 Collier206             Darlene91 Collier206      6         3\nJolynn62 Adams676                   Jolynn62 Adams676      4         2\nJunior695 Kuhlman484             Junior695 Kuhlman484      4         2\nJustin359 Hayes766                 Justin359 Hayes766      4         2\nCristi782 Miller503               Cristi782 Miller503      4         2\nNevada145 Schmeler639           Nevada145 Schmeler639      2         1\nShayla126 White193                 Shayla126 White193      2         1\nCelestina960 Reichert620     Celestina960 Reichert620      2         1\nDante562 Reinger292               Dante562 Reinger292      4         2\nJunior695 Pacocha935             Junior695 Pacocha935      2         1\nLatoria810 Eichmann909         Latoria810 Eichmann909      2         1\nMaryann106 Hintz995               Maryann106 Hintz995      2         1\nDusty207 Lynch190                   Dusty207 Lynch190      4         2\nRhonda22 Bins636                     Rhonda22 Bins636      2         1\nShonna561 Feest103                 Shonna561 Feest103      2         1\nAnderson154 Lemke654             Anderson154 Lemke654     12         6\nFelicidad691 Luettgen772     Felicidad691 Luettgen772      2         1\nJettie913 Rodriguez71           Jettie913 Rodriguez71      4         2\nMertie42 Lakin515                   Mertie42 Lakin515      8         4\nCharley358 Effertz744           Charley358 Effertz744      4         2\nCleveland582 Kuphal363         Cleveland582 Kuphal363      4         2\nLauretta754 Dare640               Lauretta754 Dare640      2         1\nSparkle906 Bernhard322         Sparkle906 Bernhard322      4         2\nArminda86 Trantow673             Arminda86 Trantow673      4         2\nArturo47 Maldonado119           Arturo47 Maldonado119      2         1\nMickey576 Borer986                 Mickey576 Borer986      2         1\nRhett759 Padberg411               Rhett759 Padberg411      2         1\nAlmeta56 Lehner980                 Almeta56 Lehner980      2         1\nEllie521 Nicolas769               Ellie521 Nicolas769      2         1\nMarth98 Mayer370                     Marth98 Mayer370      2         1\nCleo27 Lehner980                     Cleo27 Lehner980      2         1\nHong136 Kassulke119               Hong136 Kassulke119      2         1\nNathanael908 Rogahn59           Nathanael908 Rogahn59      4         2\nAubrey96 Emard19                     Aubrey96 Emard19      2         1\nBud153 Parisian75                   Bud153 Parisian75      6         3\nDarrick836 Hoppe518               Darrick836 Hoppe518      4         2\nJules135 Emard19                     Jules135 Emard19      4         2\nMateo562 Barajas558               Mateo562 Barajas558      4         2\nMonroe732 Mills423                 Monroe732 Mills423      2         1\nCarmelita854 Tromp100           Carmelita854 Tromp100      2         1\nLezlie553 Koss676                   Lezlie553 Koss676      2         1\nRayford811 Bashirian201       Rayford811 Bashirian201      4         2\nAssunta351 Haley279               Assunta351 Haley279      2         1\nRoss213 Wisozk929                   Ross213 Wisozk929      4         2\nAugustine565 Brekke496         Augustine565 Brekke496      4         2\nJoanna347 Abbott774               Joanna347 Abbott774      6         3\nLauri399 Keebler762               Lauri399 Keebler762      2         1\nJorge203 Harvey63                   Jorge203 Harvey63      2         1\nKing743 Predovic534               King743 Predovic534      2         1\nLogan497 Fisher429                 Logan497 Fisher429      2         1\nDelicia67 Bernhard322           Delicia67 Bernhard322      6         3\nRandy380 Bergstrom287           Randy380 Bergstrom287     12         6\nElisha578 Conn188                   Elisha578 Conn188      2         1\nEmory494 Schuster709             Emory494 Schuster709      4         2\nSherwood961 Aufderhar910     Sherwood961 Aufderhar910      4         2\nBuck819 Johnson679                 Buck819 Johnson679      2         1\nMadelaine318 Walker122         Madelaine318 Walker122      2         1\nSoledad678 Calderón210         Soledad678 Calderón210      4         2\nVern731 Casper496                   Vern731 Casper496      2         1\nAnnelle169 Schmidt332           Annelle169 Schmidt332      2         1\nChantell995 Krajcik437         Chantell995 Krajcik437      4         2\nChery887 Kohler843                 Chery887 Kohler843      2         1\nFreeda113 Crooks415               Freeda113 Crooks415      4         2\nSam879 Rippin620                     Sam879 Rippin620      2         1\nSharron285 Okuneva707           Sharron285 Okuneva707      2         1\nJamel269 Hudson301                 Jamel269 Hudson301      2         1\nMana631 Boehm581                     Mana631 Boehm581      2         1\nSharron285 Batz141                 Sharron285 Batz141      2         1\nClemente531 Schamberger479 Clemente531 Schamberger479      4         2\nGuillermo498 Fay398               Guillermo498 Fay398      2         1\nMiguel Ángel46 Delgado712   Miguel Ángel46 Delgado712      2         1\nShasta644 King743                   Shasta644 King743      2         1\nZachery872 Rau926                   Zachery872 Rau926      4         2\nShayne60 Gutmann970               Shayne60 Gutmann970      6         3\nJanuary966 Roberts511           January966 Roberts511      6         3\nKyle55 Collier206                   Kyle55 Collier206      2         1\nLacy523 Littel644                   Lacy523 Littel644      2         1\nRoberto515 Macías944             Roberto515 Macías944      6         3\nHarland508 Breitenberg711   Harland508 Breitenberg711      4         2\nSherwood961 O'Conner199       Sherwood961 O'Conner199      4         2\nAlberto639 Adame662               Alberto639 Adame662      2         1\nLady554 Kovacek682                 Lady554 Kovacek682      2         1\nCristopher265 Heaney114       Cristopher265 Heaney114      2         1\nEstella474 O'Hara248             Estella474 O'Hara248      2         1\nAlonso270 Hand679                   Alonso270 Hand679      2         1\nEstell607 Barton704               Estell607 Barton704      2         1\nLanette41 Murray856               Lanette41 Murray856      2         1\nHouston994 Funk324                 Houston994 Funk324      2         1\nRebeca548 García15                 Rebeca548 García15      2         1\nSid118 Hammes673                     Sid118 Hammes673      2         1\nEzra452 Torp761                       Ezra452 Torp761      2         1\nTracy345 Wilderman619           Tracy345 Wilderman619      2         1\nChristopher407 Fisher429     Christopher407 Fisher429      2         1\nHeather971 Goldner995           Heather971 Goldner995      2         1\nSaul605 Ratke343                     Saul605 Ratke343      6         3\nAntonette454 Tromp100           Antonette454 Tromp100      4         2\nSasha806 D'Amore443               Sasha806 D'Amore443      4         2\nBryon392 Mann644                     Bryon392 Mann644      2         1\nJoslyn677 Friesen796             Joslyn677 Friesen796      2         1\nMargene509 Schamberger479   Margene509 Schamberger479      2         1\nPatricia625 Aragón562           Patricia625 Aragón562      2         1\nKristin64 Will178                   Kristin64 Will178      2         1\nLeo278 Strosin214                   Leo278 Strosin214      4         2\nLonnie913 Ferry570                 Lonnie913 Ferry570      2         1\nJess275 Gutmann970                 Jess275 Gutmann970      2         1\nFlorencia449 Araña824           Florencia449 Araña824      2         1\nGordon377 Monahan736             Gordon377 Monahan736      2         1\nLeah288 Sauer652                     Leah288 Sauer652      2         1\nRudolf736 Vandervort697       Rudolf736 Vandervort697      4         2\nMaurice742 Pollich983           Maurice742 Pollich983      2         1\nRocky100 Schmeler639             Rocky100 Schmeler639      2         1\nCharles364 Prosacco716         Charles364 Prosacco716      2         1\nKimbra238 Runolfsdottir785 Kimbra238 Runolfsdottir785      2         1\nLaurie826 Pacocha935             Laurie826 Pacocha935      2         1\nMario764 Aranda843                 Mario764 Aranda843      2         1\nMiyoko154 Paucek755               Miyoko154 Paucek755      4         2\nRosanna866 DuBuque211           Rosanna866 DuBuque211      2         1\nShemeka786 Conn188                 Shemeka786 Conn188      2         1\nColumbus656 Koch169               Columbus656 Koch169      2         1\nDerick144 King743                   Derick144 King743      2         1\nEliana466 Wehner319               Eliana466 Wehner319      2         1\nJane262 Schmeler639               Jane262 Schmeler639      4         2\nJarvis643 Ankunding277         Jarvis643 Ankunding277      2         1\nMaude482 Veum823                     Maude482 Veum823      2         1\nParker433 Bailey598               Parker433 Bailey598      2         1\nBrooks264 Williamson769       Brooks264 Williamson769      2         1\nAdán600 Alicea505                   Adán600 Alicea505      2         1\nIsiah14 Nikolaus26                 Isiah14 Nikolaus26      2         1\nCherish740 Toy286                   Cherish740 Toy286      2         1\nFae378 Wiza601                         Fae378 Wiza601      2         1\nAnderson154 Kunze215             Anderson154 Kunze215      2         1\nCalandra120 Hackett68           Calandra120 Hackett68      2         1\nCedrick207 Gleason633           Cedrick207 Gleason633      2         1\nGino587 Block661                     Gino587 Block661      6         3\nAllyson474 Doyle959               Allyson474 Doyle959      2         1\nJunior695 Leffler128             Junior695 Leffler128      2         1\nJacinta658 Wintheiser220     Jacinta658 Wintheiser220      2         1\nNilda678 Crona259                   Nilda678 Crona259      2         1\nShane235 Lueilwitz711           Shane235 Lueilwitz711      2         1\nJonathan639 Sporer811           Jonathan639 Sporer811      2         1\nJeanie708 Turner526               Jeanie708 Turner526      2         1\nJosefina523 O'Connell601     Josefina523 O'Connell601      2         1\nDale454 Wilderman619             Dale454 Wilderman619      2         1\nOlevia458 Hermiston71           Olevia458 Hermiston71      2         1\nValentine262 Corwin846         Valentine262 Corwin846      2         1\nCarl856 King743                       Carl856 King743      2         1\nEdwardo860 Larkin917             Edwardo860 Larkin917      2         1\nEnrique929 Caraballo427       Enrique929 Caraballo427      2         1\nMelvin857 Nikolaus26             Melvin857 Nikolaus26      2         1\nErrol226 Kiehn525                   Errol226 Kiehn525      2         1\nHarland508 Ryan260                 Harland508 Ryan260      2         1\nSharyl439 Williamson769       Sharyl439 Williamson769      2         1\nDana512 Wilkinson796             Dana512 Wilkinson796      2         1\nQuentin28 Fritsch593             Quentin28 Fritsch593      2         1\nDarnell564 Leannon79             Darnell564 Leannon79      4         2\nLynsey2 Lemke654                     Lynsey2 Lemke654      2         1\nNeville893 Schoen8                 Neville893 Schoen8      2         1\nNorah104 Jenkins714               Norah104 Jenkins714      2         1\nPatrina117 Strosin214           Patrina117 Strosin214      4         2\nErwin847 Stiedemann542         Erwin847 Stiedemann542      2         1\nLaurena366 Anderson154         Laurena366 Anderson154      2         1\nOrpha286 Marks830                   Orpha286 Marks830      2         1\nAntonia30 Elizondo706           Antonia30 Elizondo706      2         1\nDrew592 Streich926                 Drew592 Streich926      2         1\nHellen346 Roberts511             Hellen346 Roberts511      2         1\nLevi940 Abbott774                   Levi940 Abbott774      2         1\nHarland508 Rippin620             Harland508 Rippin620      2         1\nKati243 Ruecker817                 Kati243 Ruecker817      2         1\nLizette501 Lebsack687           Lizette501 Lebsack687      2         1\nLatrisha74 Rippin620             Latrisha74 Rippin620      2         1\nMaynard46 Buckridge80           Maynard46 Buckridge80      2         1\nAzzie965 Feil794                     Azzie965 Feil794      2         1\nEldon28 Cassin499                   Eldon28 Cassin499      2         1\nKaila152 Dibbert990               Kaila152 Dibbert990      2         1\nEllyn26 Windler79                   Ellyn26 Windler79      2         1\nFritz267 Kirlin939                 Fritz267 Kirlin939      2         1\nMaría José279 Godínez202     María José279 Godínez202      2         1\nElvera717 Gusikowski974       Elvera717 Gusikowski974      2         1\nKareem959 Schaefer657           Kareem959 Schaefer657      2         1\nSilva841 Grimes165                 Silva841 Grimes165      2         1\nTracie996 Lesch175                 Tracie996 Lesch175      2         1\n                            betweenness       close constraint\nAdam631 Hoppe518             687.133333 0.132174114 0.25000000\nAlesha810 Heaney114           18.000000 0.013572204 0.33333333\nAlissa315 Altenwerth646     2789.233333 0.187481257 0.25000000\nAnalisa263 Kohler843        1248.000000 0.130010317 0.25000000\nAnnice210 Gleason633         419.000000 0.122774394 0.33333333\nAnthony633 Kutch271           18.000000 0.013572204 0.33333333\nBenedict104 Hintz995           1.000000 0.010314875 0.50000000\nCarl856 Rempel203           1660.000000 0.153112794 0.20000000\nChanell45 Morissette863     1408.236453 0.153927126 0.20000000\nChaya236 Sporer811           834.000000 0.148769689 0.33333333\nCherise743 Prosacco716      1237.533333 0.123409408 0.20000000\nCindi877 Hane680             439.133333 0.132181870 0.20000000\nCruz300 Wilderman619        1120.676026 0.154741458 0.25000000\nDamian46 Dach178               1.000000 0.104213331 0.50000000\nDiana207 Stamm704             18.000000 0.013572204 0.33333333\nDinorah501 Bechtelar572     1031.966667 0.123409408 0.20000000\nDonald774 Krajcik437           6.000000 0.009771987 0.33333333\nDorothea248 Fritsch593      1017.880952 0.150941241 0.25000000\nDortha70 Rutherford999      1395.970434 0.146590380 0.25000000\nDusti191 Maggio310            11.000000 0.014657980 0.25000000\nElease461 Boehm581            36.000000 0.017915309 0.25000000\nEsther279 Schroeder447      1248.000000 0.184549661 0.25000000\nEverette494 O'Hara248         18.000000 0.013572204 0.33333333\nGino587 Vandervort697        457.833333 0.116398585 0.33333333\nGordon377 Marquardt819      4225.000000 0.192281940 0.16666667\nGuadalupe206 Wuckert783     2059.000000 0.185798304 0.25000000\nGwen761 Keeling57            418.000000 0.093873897 0.50000000\nIvan258 Hills818            1143.000571 0.146590380 0.25000000\nJeanelle736 Simonis280       549.000000 0.128261442 0.33333333\nJeanette800 Schinner682       36.000000 0.017915309 0.25000000\nJohnnie679 Hand679          2798.225813 0.193422005 0.25000000\nJohnny786 Smith67            217.466667 0.127885298 0.33333333\nJorge203 Ferry570           3503.800000 0.188349878 0.25000000\nJulianne852 Barrows492      1248.000000 0.102687839 0.25000000\nKandis954 Koepp521           834.000000 0.091899866 0.33333333\nKathlyn335 Wisozk929         834.000000 0.130344863 0.33333333\nKathrine376 Bosco882        1243.000000 0.126232074 0.33333333\nKrystina167 Muller251          6.000000 0.009771987 0.33333333\nLan153 Schmidt332           1883.406623 0.147386381 0.16666667\nLani848 Cole117              853.312446 0.187046947 0.25000000\nLawerence6 Grimes165        1138.500000 0.130169306 0.25000000\nLeland44 Huels583              7.000000 0.098409716 0.33333333\nLemuel304 Mante251          2518.866667 0.190087121 0.20000000\nLeonel449 Witting912        2282.000000 0.190087121 0.20000000\nLorina403 Cronin387          107.600000 0.118398151 0.33333333\nLorretta561 Metz686          994.236453 0.151755573 0.25000000\nLou594 Krajcik437              6.000000 0.009771987 0.33333333\nMadelyn308 Schumm995        4812.000000 0.190792875 0.20000000\nMarcos263 Mills423             3.000000 0.012486428 0.33333333\nMargarito178 Schulist381      15.000000 0.014657980 0.25000000\nMario764 Glover433          6989.666667 0.193034228 0.20000000\nMaryellen651 Conn188        1649.000000 0.183626751 0.33333333\nMia349 Runte676               12.000000 0.013029316 0.25000000\nMonroe732 Fritsch593          22.000000 0.014657980 0.33333333\nMose244 Cummerata161         680.366667 0.132174114 0.25000000\nMozelle144 Zboncak558         36.000000 0.017915309 0.25000000\nNelida367 Emard19           2466.000000 0.122920809 0.25000000\nOdilia72 Upton904           1330.500000 0.130169306 0.25000000\nOla364 Kreiger457             36.000000 0.017915309 0.25000000\nOliva247 Braun514             30.000000 0.016829533 0.25000000\nOuida808 Carroll471          419.000000 0.122340083 0.33333333\nRamon749 Kozey370          11840.933483 0.210305827 0.12500000\nRegan713 Kertzmann286        538.050586 0.142751385 0.20000000\nRod343 Prosacco716            18.000000 0.013572204 0.33333333\nRolland302 Kassulke119      1419.000000 0.186232615 0.25000000\nRosamaria757 Orn563        10660.000000 0.154636523 0.20000000\nRudy520 Hettinger594        3356.276211 0.195593558 0.20000000\nRupert654 Jenkins714        1014.363853 0.187046947 0.25000000\nRussell422 Stracke611         18.000000 0.013572204 0.33333333\nRyann170 Spencer878         2747.333333 0.136839075 0.20000000\nSabine292 Feil794          16078.251067 0.205103149 0.14285714\nSandee884 Rice937              6.000000 0.009771987 0.33333333\nSerena400 Powlowski563      1981.890138 0.159449074 0.20000000\nShara355 Bruen238            837.000000 0.128814671 0.25000000\nShila857 Heller342          1413.855556 0.139439768 0.20000000\nSpencer878 Bailey598          22.000000 0.014657980 0.33333333\nStanley702 Cremin516        1646.866667 0.125580961 0.16666667\nStephan15 Auer97               6.000000 0.009771987 0.33333333\nTera136 Swift555              12.000000 0.013029316 0.25000000\nTheodore876 Thiel172        1279.000000 0.151755573 0.25000000\nTomika243 Walker122         1855.633333 0.127752514 0.14285714\nTommy814 Miller503           978.000000 0.130925472 0.25000000\nTroy560 Kohler843             30.000000 0.016829533 0.25000000\nTyler508 Ankunding277       1248.000000 0.140366320 0.25000000\nWilburn655 Sipes176          418.000000 0.129031826 0.50000000\nWilfred787 Nienow652        1248.000000 0.131301616 0.25000000\nElijah719 White193             0.000000 0.107643207 1.00000000\nFidel864 Swift555             78.566667 0.116763728 0.33333333\nVirgen207 Hyatt152          1328.866667 0.151951812 0.33333333\nZachery872 Pagac496           41.866667 0.115135064 0.33333333\nKristopher775 Schiller186      0.000000 0.009229099 1.00000000\nLaine739 Torphy630             0.000000 0.009229099 1.00000000\nLeonarda398 Schumm995         18.000000 0.013029316 0.50000000\nMathew182 Howe413            296.100000 0.147174396 0.50000000\nTed955 Reilly981           36577.138890 0.257088568 0.05882353\nVicente970 Armstrong51         0.000000 0.143482757 1.00000000\nDaniel959 Wolff180             0.000000 0.106293742 1.00000000\nElmer371 Gusikowski974         0.000000 0.106293742 1.00000000\nJanet238 Crooks415             0.000000 0.106293742 1.00000000\nKarla801 Cummerata161       1924.466667 0.155969185 0.25000000\nClement78 Gleason633         414.000000 0.145491443 0.50000000\nEnriqueta274 Barton704         0.000000 0.102388825 1.00000000\nKim439 Hyatt152              414.000000 0.145491443 0.50000000\nJaney243 Schoen8               0.000000 0.009229099 1.00000000\nLuna60 Littel644               0.000000 0.009229099 1.00000000\nNumbers230 Stehr398            3.000000 0.011400651 0.50000000\nWaylon572 Lakin515             3.000000 0.011400651 0.50000000\nIna660 Hermann103              0.000000 0.120591090 1.00000000\nJewel43 Kassulke119        10586.177835 0.195262654 0.11111111\nJosef103 Klein929              0.000000 0.120591090 1.00000000\nMajorie11 Bergstrom287         0.000000 0.120591090 1.00000000\nSalvador46 Wolff180            0.000000 0.120591090 1.00000000\nCyrstal592 Mosciski958         0.000000 0.121025401 1.00000000\nGerardo48 Bergstrom287         0.000000 0.121025401 1.00000000\nShawn523 Padberg411            0.000000 0.121025401 1.00000000\nThanh759 Weber641            246.376026 0.132588919 0.25000000\nAgnes294 Dooley940             0.000000 0.118962426 1.00000000\nCody889 Ratke343               0.000000 0.118962426 1.00000000\nAbdul218 Boyer713              5.500000 0.103441464 0.50000000\nCortez851 Price929          9646.066667 0.147687555 0.16666667\nGene733 Ratke343               0.000000 0.099641247 1.00000000\nLola232 Collado928             5.500000 0.103441464 0.50000000\nMarcelino726 Hilpert278        0.000000 0.099641247 1.00000000\nDelbert384 Carter549           0.000000 0.107108075 1.00000000\nEddie505 Keeling57           276.466667 0.151354635 0.33333333\nLouis204 Hauck852            132.333333 0.147554418 0.50000000\nThad495 Leannon79            132.333333 0.147554418 0.50000000\nDarlene91 Collier206         745.543076 0.135793134 0.33333333\nJolynn62 Adams676             48.236453 0.124174152 0.50000000\nJunior695 Kuhlman484         208.000000 0.122382621 0.50000000\nJustin359 Hayes766           208.000000 0.122382621 0.50000000\nCristi782 Miller503           18.000000 0.013029316 0.50000000\nNevada145 Schmeler639          0.000000 0.009229099 1.00000000\nShayla126 White193             0.000000 0.009229099 1.00000000\nCelestina960 Reichert620       0.000000 0.099641247 1.00000000\nDante562 Reinger292           17.600000 0.105884461 0.50000000\nJunior695 Pacocha935           0.000000 0.006514658 1.00000000\nLatoria810 Eichmann909         0.000000 0.006514658 1.00000000\nMaryann106 Hintz995            0.000000 0.006514658 1.00000000\nDusty207 Lynch190             48.714286 0.128238058 0.50000000\nRhonda22 Bins636               0.000000 0.119776758 1.00000000\nShonna561 Feest103             0.000000 0.119776758 1.00000000\nAnderson154 Lemke654        4533.850156 0.169591800 0.16666667\nFelicidad691 Luettgen772       0.000000 0.117170895 1.00000000\nJettie913 Rodriguez71        187.520602 0.120156780 0.50000000\nMertie42 Lakin515           1346.891716 0.140340586 0.25000000\nCharley358 Effertz744          1.333333 0.011400651 0.50000000\nCleveland582 Kuphal363         1.333333 0.011400651 0.50000000\nLauretta754 Dare640            0.000000 0.009229099 1.00000000\nSparkle906 Bernhard322         1.333333 0.011400651 0.50000000\nArminda86 Trantow673          32.000000 0.016286645 0.50000000\nArturo47 Maldonado119          0.000000 0.011672096 1.00000000\nMickey576 Borer986             0.000000 0.011672096 1.00000000\nRhett759 Padberg411            0.000000 0.011672096 1.00000000\nAlmeta56 Lehner980             0.000000 0.141799804 1.00000000\nEllie521 Nicolas769            0.000000 0.141799804 1.00000000\nMarth98 Mayer370               0.000000 0.141799804 1.00000000\nCleo27 Lehner980               0.000000 0.009229099 1.00000000\nHong136 Kassulke119            0.000000 0.009229099 1.00000000\nNathanael908 Rogahn59         18.000000 0.013029316 0.50000000\nAubrey96 Emard19               0.000000 0.096694294 1.00000000\nBud153 Parisian75            850.000000 0.153033711 0.33333333\nDarrick836 Hoppe518          820.000000 0.149124916 0.50000000\nJules135 Emard19             414.000000 0.149233494 0.50000000\nMateo562 Barajas558          820.000000 0.149124916 0.50000000\nMonroe732 Mills423             0.000000 0.145433276 1.00000000\nCarmelita854 Tromp100          0.000000 0.142505558 1.00000000\nLezlie553 Koss676              0.000000 0.081566045 1.00000000\nRayford811 Bashirian201      832.000000 0.107587626 0.50000000\nAssunta351 Haley279            0.000000 0.117170895 1.00000000\nRoss213 Wisozk929             68.572961 0.121785444 0.50000000\nAugustine565 Brekke496        20.666667 0.113148352 0.50000000\nJoanna347 Abbott774         2432.333333 0.155259552 0.33333333\nLauri399 Keebler762            0.000000 0.106036517 1.00000000\nJorge203 Harvey63              0.000000 0.011672096 1.00000000\nKing743 Predovic534            0.000000 0.011672096 1.00000000\nLogan497 Fisher429             0.000000 0.011672096 1.00000000\nDelicia67 Bernhard322        150.303965 0.152979422 0.33333333\nRandy380 Bergstrom287       1184.813977 0.162751409 0.16666667\nElisha578 Conn188              0.000000 0.144025645 1.00000000\nEmory494 Schuster709        1312.866667 0.149345949 0.50000000\nSherwood961 Aufderhar910    1021.100000 0.149780260 0.50000000\nBuck819 Johnson679             0.000000 0.086303391 1.00000000\nMadelaine318 Walker122         0.000000 0.086303391 1.00000000\nSoledad678 Calderón210      1648.000000 0.114777016 0.50000000\nVern731 Casper496              0.000000 0.086303391 1.00000000\nAnnelle169 Schmidt332          0.000000 0.078573842 1.00000000\nChantell995 Krajcik437      1242.000000 0.103604331 0.50000000\nChery887 Kohler843             0.000000 0.078573842 1.00000000\nFreeda113 Crooks415         1242.000000 0.156999380 0.50000000\nSam879 Rippin620               0.000000 0.107840856 1.00000000\nSharron285 Okuneva707          0.000000 0.107840856 1.00000000\nJamel269 Hudson301             0.000000 0.006514658 1.00000000\nMana631 Boehm581               0.000000 0.006514658 1.00000000\nSharron285 Batz141             0.000000 0.006514658 1.00000000\nClemente531 Schamberger479   942.225534 0.160039553 0.50000000\nGuillermo498 Fay398            0.000000 0.117323303 1.00000000\nMiguel Ángel46 Delgado712      0.000000 0.117323303 1.00000000\nShasta644 King743              0.000000 0.117323303 1.00000000\nZachery872 Rau926            942.225534 0.160039553 0.50000000\nShayne60 Gutmann970          160.026737 0.153793754 0.33333333\nJanuary966 Roberts511        220.666667 0.112419331 0.33333333\nKyle55 Collier206              0.000000 0.106447561 1.00000000\nLacy523 Littel644              0.000000 0.106447561 1.00000000\nRoberto515 Macías944        3239.000000 0.153875187 0.33333333\nHarland508 Breitenberg711    102.166667 0.108619113 0.50000000\nSherwood961 O'Conner199      102.166667 0.108619113 0.50000000\nAlberto639 Adame662            0.000000 0.144568533 1.00000000\nLady554 Kovacek682             0.000000 0.144568533 1.00000000\nCristopher265 Heaney114        0.000000 0.120211068 1.00000000\nEstella474 O'Hara248           0.000000 0.120211068 1.00000000\nAlonso270 Hand679              0.000000 0.006514658 1.00000000\nEstell607 Barton704            0.000000 0.006514658 1.00000000\nLanette41 Murray856            0.000000 0.006514658 1.00000000\nHouston994 Funk324             0.000000 0.145026110 1.00000000\nRebeca548 García15             0.000000 0.145026110 1.00000000\nSid118 Hammes673               0.000000 0.145026110 1.00000000\nEzra452 Torp761                0.000000 0.009229099 1.00000000\nTracy345 Wilderman619          0.000000 0.009229099 1.00000000\nChristopher407 Fisher429       0.000000 0.146410475 1.00000000\nHeather971 Goldner995          0.000000 0.146410475 1.00000000\nSaul605 Ratke343            3143.000000 0.156888217 0.33333333\nAntonette454 Tromp100        414.000000 0.144677111 0.50000000\nSasha806 D'Amore443          414.000000 0.144677111 0.50000000\nBryon392 Mann644               0.000000 0.008143322 1.00000000\nJoslyn677 Friesen796           0.000000 0.008143322 1.00000000\nMargene509 Schamberger479      0.000000 0.008143322 1.00000000\nPatricia625 Aragón562          0.000000 0.008143322 1.00000000\nKristin64 Will178              0.000000 0.010043431 1.00000000\nLeo278 Strosin214             24.000000 0.014657980 0.50000000\nLonnie913 Ferry570             0.000000 0.010043431 1.00000000\nJess275 Gutmann970             0.000000 0.107643207 1.00000000\nFlorencia449 Araña824          0.000000 0.011672096 1.00000000\nGordon377 Monahan736           0.000000 0.011672096 1.00000000\nLeah288 Sauer652               0.000000 0.011672096 1.00000000\nRudolf736 Vandervort697       32.000000 0.016286645 0.50000000\nMaurice742 Pollich983          0.000000 0.099804114 1.00000000\nRocky100 Schmeler639           0.000000 0.099804114 1.00000000\nCharles364 Prosacco716         0.000000 0.011672096 1.00000000\nKimbra238 Runolfsdottir785     0.000000 0.011672096 1.00000000\nLaurie826 Pacocha935           0.000000 0.011672096 1.00000000\nMario764 Aranda843             0.000000 0.010857763 1.00000000\nMiyoko154 Paucek755           24.000000 0.014657980 0.50000000\nRosanna866 DuBuque211          0.000000 0.010857763 1.00000000\nShemeka786 Conn188             0.000000 0.010857763 1.00000000\nColumbus656 Koch169            0.000000 0.102117381 1.00000000\nDerick144 King743              0.000000 0.155197508 1.00000000\nEliana466 Wehner319            0.000000 0.155197508 1.00000000\nJane262 Schmeler639          648.415584 0.159432036 0.50000000\nJarvis643 Ankunding277         0.000000 0.155197508 1.00000000\nMaude482 Veum823               0.000000 0.155197508 1.00000000\nParker433 Bailey598            0.000000 0.155197508 1.00000000\nBrooks264 Williamson769        0.000000 0.113652462 1.00000000\nAdán600 Alicea505              0.000000 0.009229099 1.00000000\nIsiah14 Nikolaus26             0.000000 0.009229099 1.00000000\nCherish740 Toy286              0.000000 0.142777002 1.00000000\nFae378 Wiza601                 0.000000 0.142777002 1.00000000\nAnderson154 Kunze215           0.000000 0.122008945 1.00000000\nCalandra120 Hackett68          0.000000 0.122008945 1.00000000\nCedrick207 Gleason633          0.000000 0.122008945 1.00000000\nGino587 Block661           12208.000000 0.170486273 0.33333333\nAllyson474 Doyle959            0.000000 0.147821984 1.00000000\nJunior695 Leffler128           0.000000 0.147821984 1.00000000\nJacinta658 Wintheiser220       0.000000 0.143211313 1.00000000\nNilda678 Crona259              0.000000 0.009229099 1.00000000\nShane235 Lueilwitz711          0.000000 0.009229099 1.00000000\nJonathan639 Sporer811          0.000000 0.110162467 1.00000000\nJeanie708 Turner526            0.000000 0.153199162 1.00000000\nJosefina523 O'Connell601       0.000000 0.153199162 1.00000000\nDale454 Wilderman619           0.000000 0.006514658 1.00000000\nOlevia458 Hermiston71          0.000000 0.006514658 1.00000000\nValentine262 Corwin846         0.000000 0.006514658 1.00000000\nCarl856 King743                0.000000 0.124437840 1.00000000\nEdwardo860 Larkin917           0.000000 0.124437840 1.00000000\nEnrique929 Caraballo427        0.000000 0.105637106 1.00000000\nMelvin857 Nikolaus26           0.000000 0.105637106 1.00000000\nErrol226 Kiehn525              0.000000 0.111806643 1.00000000\nHarland508 Ryan260             0.000000 0.111806643 1.00000000\nSharyl439 Williamson769        0.000000 0.111806643 1.00000000\nDana512 Wilkinson796           0.000000 0.010043431 1.00000000\nQuentin28 Fritsch593           0.000000 0.010043431 1.00000000\nDarnell564 Leannon79          12.666667 0.105884461 0.50000000\nLynsey2 Lemke654               0.000000 0.100455580 1.00000000\nNeville893 Schoen8             0.000000 0.100455580 1.00000000\nNorah104 Jenkins714            0.000000 0.100455580 1.00000000\nPatrina117 Strosin214         12.666667 0.105884461 0.50000000\nErwin847 Stiedemann542         0.000000 0.006514658 1.00000000\nLaurena366 Anderson154         0.000000 0.006514658 1.00000000\nOrpha286 Marks830              0.000000 0.006514658 1.00000000\nAntonia30 Elizondo706          0.000000 0.008143322 1.00000000\nDrew592 Streich926             0.000000 0.008143322 1.00000000\nHellen346 Roberts511           0.000000 0.008143322 1.00000000\nLevi940 Abbott774              0.000000 0.008143322 1.00000000\nHarland508 Rippin620           0.000000 0.101269912 1.00000000\nKati243 Ruecker817             0.000000 0.101269912 1.00000000\nLizette501 Lebsack687          0.000000 0.101269912 1.00000000\nLatrisha74 Rippin620           0.000000 0.106937453 1.00000000\nMaynard46 Buckridge80          0.000000 0.106937453 1.00000000\nAzzie965 Feil794               0.000000 0.010857763 1.00000000\nEldon28 Cassin499              0.000000 0.010857763 1.00000000\nKaila152 Dibbert990            0.000000 0.010857763 1.00000000\nEllyn26 Windler79              0.000000 0.113950933 1.00000000\nFritz267 Kirlin939             0.000000 0.113950933 1.00000000\nMaría José279 Godínez202       0.000000 0.113950933 1.00000000\nElvera717 Gusikowski974        0.000000 0.106819827 1.00000000\nKareem959 Schaefer657          0.000000 0.107393737 1.00000000\nSilva841 Grimes165             0.000000 0.107393737 1.00000000\nTracie996 Lesch175             0.000000 0.107393737 1.00000000\n\n\n\n# To use cug.test, we need an adjacency matrix:\nencounters.mat &lt;- encounters.stat[,]\n\n# compare network transitivity to null conditional on size\ntrans.cug &lt;- cug.test(encounters.mat,\n                      FUN = gtrans,\n                      mode = \"digraph\",\n                      cmode = \"size\",\n                      reps = 100)\n\ntrans.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: size \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 100 \n\nObserved Value: 0 \nPr(X&gt;=Obs): 1 \nPr(X&lt;=Obs): 0 \n\n\nHistogram with observed comp. replication statistics:\n\n# plot observed vs. simulation results\nplot(trans.cug)\n\n\n\n\n\n# t-stst between observed and simulated networks\n(trans.cug$obs.stat - mean(trans.cug$rep.stat))/sd(trans.cug$rep.stat)\n\n[1] -309.8798\n\n\nLet’s create an easy function to return the t-stat for cug.test:\n\ncug.t &lt;- function(cug.object){\n  (cug.object$obs.stat - mean(cug.object$rep.stat))/sd(cug.object$rep.stat)\n}\n\n\n# comapre network transitivity to null conditional on size\ntrans.cug &lt;- cug.test(encounters.mat,\n                      FUN = gtrans,\n                      mode = \"digraph\",\n                      cmode = \"size\",\n                      reps = 100)\ntrans.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: size \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 100 \n\nObserved Value: 0 \nPr(X&gt;=Obs): 1 \nPr(X&lt;=Obs): 0 \n\n\n\n# plot observed vs. simulated\nplot(trans.cug)\n\n\n\n\n\n# t-stat between observed and simulated networks\ncug.t(trans.cug)\n\n[1] -307.3921\n\n\n\n# compare network degree centralization to null conditional on size\nc.degree.cug &lt;- cug.test(encounters.stat,\n                         FUN = centralization,\n                         FUN.args = list(FUN = degree,\n                                      cmode = \"indegree\"),\n                         mode=\"digraph\",\n                         cmode=\"size\")\nc.degree.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: size \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 1000 \n\nObserved Value: 0.04831882 \nPr(X&gt;=Obs): 1 \nPr(X&lt;=Obs): 0 \n\n\n\n# plot\nplot(c.degree.cug)\n\n\n\n\n\n# t-stat\ncug.t(c.degree.cug)\n\n[1] -3.186288\n\n\n\nb.degree.cug &lt;- cug.test(encounters.stat,\n                         FUN = centralization,\n                         FUN.arg = list(FUN=betweenness,\n                                        cmode = \"directed\"),\n                         mode = \"digraph\",\n                         cmode = \"size\",\n                         reps = 100)\n\nb.degree.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: size \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 100 \n\nObserved Value: 0.3826019 \nPr(X&gt;=Obs): 0 \nPr(X&lt;=Obs): 1 \n\n\nobs value of the tstatistic is extremely unlikely to occur under the null hypothesis, suggesting statistical significance\n\nplot(b.degree.cug)\n\n\n\n\n\n# t-stat\ncug.t(b.degree.cug)\n\n[1] 6271.259\n\n\n\n# compare network transitivity to null conditional on dyads\ntrans.cug &lt;- cug.test(encounters.stat,\n                      FUN = gtrans,\n                      mode = \"digraph\",\n                      cmode = \"dyad\")\ntrans.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: dyad.census \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 1000 \n\nObserved Value: 0 \nPr(X&gt;=Obs): 1 \nPr(X&lt;=Obs): 0.158 \n\n\n\nplot(trans.cug)\n\n\n\n\n\n# t-stat\ncug.t(trans.cug)\n\n[1] -1.345567\n\n\nThe edges property is also built into the cug.test() function. Here we run it with only 100 reps, because this is clearly not a random network!\n\n# compare network transitivity to null conditional on edges (density)\ntrans.cug &lt;- cug.test(encounters.stat,\n                      FUN=gtrans,\n                      mode = \"digraph\",\n                      cmode = \"edges\",\n                      reps = 100)\n\ntrans.cug\n\n\nUnivariate Conditional Uniform Graph Test\n\nConditioning Method: edges \nGraph Type: digraph \nDiagonal Used: FALSE \nReplications: 100 \n\nObserved Value: 0 \nPr(X&gt;=Obs): 1 \nPr(X&lt;=Obs): 0 \n\n\n\nplot(trans.cug)\n\n\n\n\n\ncug.t(trans.cug)\n\n[1] -3.304684"
  },
  {
    "objectID": "posts/Post_Nine- Copy/post_9_drug.html",
    "href": "posts/Post_Nine- Copy/post_9_drug.html",
    "title": "POST 9",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(tigris)\nlibrary(stplanr)\n\nThis post will explore the Synthetic Mass network data in more detail.\n\nRead in Data\n\npat_attr &lt;- read_csv(\"post5drug_data/pat_attr.csv\", \n    col_types = cols(...1 = col_skip()))\npro_attr &lt;- read_csv(\"post5drug_data/pro_attr.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaning &lt;- read_csv(\"post5drug_data//encounters_cleaning.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_cleaned &lt;- read_csv(\"post5drug_data//encounters_cleaned.csv\", \n    col_types = cols(...1 = col_skip()))\nencounter_attributes &lt;- read_csv(\"post5drug_data/encounter_attributes.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_el  &lt;- read_csv(\"post5drug_data/encounters_el.csv\", \n    col_types = cols(...1 = col_skip()))\nencounters_st_3 &lt;- read_csv(\"post5drug_data/encounters.st.3.csv\", \n    col_types = cols(...1 = col_skip()))\nattribute_list &lt;- read.csv(\"post5drug_data/attribute_list.csv\")\npat_blks6 &lt;- readRDS(\"pat_blks6_results.rds\")\nprov_blks6 &lt;- readRDS(\"prov_blks6_results.rds\")\n\n\n\nCreate bipartite network with attributes\n\nencounters.stat &lt;- network(encounters_el,\n                         directed = FALSE,\n                         bipartite = TRUE,\n                         matrix.type = \"edgelist\",\n                         vertex.attr = attribute_list)\n\nencounters.ig &lt;- graph_from_biadjacency_matrix(encounters.stat)\n\nattributes &lt;- bind_rows(pat_attr, pro_attr)\n\n\n\ncreate an adjacency matrix using sna\n\nencounters.sna &lt;- network(as.matrix(encounters.stat), directed = F)\nencounters.m &lt;- encounters.sna[,] # extract an adjacency matrix from the network object\n\n\n\nMatrix Multiplication - For Overlap Count\nCross-Product Method with manual matrix multiplication Multiply a two-mode matrix by its transpose to produce a one-mode network that reflects the ties between the nodes in one of the two modes\n\npatient.m &lt;- t(encounters.m) %*% encounters.m\ndiag(patient.m) &lt;- 0\n\n\nprovider.m &lt;-   encounters.m %*% t(encounters.m)\ndiag(provider.m) &lt;- 0\n\n\npatient.ig &lt;- graph_from_adjacency_matrix(patient.m, \n                                        mode = \"undirected\", \n                                        weighted = TRUE)\npatient.ig\n\nIGRAPH 5d3c26e UNW- 222 497 -- \n+ attr: name (v/c), weight (e/n)\n+ edges from 5d3c26e (vertex names):\n [1] Elijah719 White193--Fidel864 Swift555       \n [2] Elijah719 White193--Virgen207 Hyatt152      \n [3] Elijah719 White193--Zachery872 Pagac496     \n [4] Fidel864 Swift555 --Virgen207 Hyatt152      \n [5] Fidel864 Swift555 --Zachery872 Pagac496     \n [6] Fidel864 Swift555 --Emory494 Schuster709    \n [7] Fidel864 Swift555 --Sherwood961 Aufderhar910\n [8] Fidel864 Swift555 --Jess275 Gutmann970      \n+ ... omitted several edges\n\n\n\nprovider.ig &lt;- graph_from_adjacency_matrix(provider.m, \n                                        mode = \"undirected\", \n                                        weighted = TRUE)\nprovider.ig\n\nIGRAPH 5d42e38 UNW- 86 265 -- \n+ attr: name (v/c), weight (e/n)\n+ edges from 5d42e38 (vertex names):\n [1] Adam631 Hoppe518       --Alissa315 Altenwerth646\n [2] Adam631 Hoppe518       --Johnny786 Smith67      \n [3] Adam631 Hoppe518       --Mose244 Cummerata161   \n [4] Adam631 Hoppe518       --Tommy814 Miller503     \n [5] Alesha810 Heaney114    --Anthony633 Kutch271    \n [6] Alissa315 Altenwerth646--Esther279 Schroeder447 \n [7] Alissa315 Altenwerth646--Gordon377 Marquardt819 \n [8] Alissa315 Altenwerth646--Guadalupe206 Wuckert783\n+ ... omitted several edges\n\n\n\nE(patient.ig)$weight\n\n  [1] 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 2\n [38] 1 1 1 1 1 1 2 4 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [75] 1 1 1 1 1 1 1 1 1 1 3 2 2 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3\n[112] 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 2\n[149] 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2\n[186] 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 3 1 1\n[223] 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[260] 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1\n[297] 3 2 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[334] 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 2 1 1 1\n[371] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\n\nE(provider.ig)$weight\n\n  [1] 1 2 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2\n [38] 1 1 2 1 1 1 1 1 1 1 1 1 3 1 1 1 1 4 2 1 1 3 2 1 1 1 2 1 1 1 1 2 1 1 2 1 2\n [75] 2 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n[112] 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 3 1 1 1 1 1 1 3 1 3\n[149] 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 3 1 2 3 1 1 1 1\n[186] 2 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n[223] 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n[260] 1 1 1 1 1 3\n\n\nSO providers it seems overlap with the same patients with the most being 4 times an overlap.\n\nlibrary(ade4) \n\nWarning: package 'ade4' was built under R version 4.3.3\n\ng &lt;- graph_from_data_frame(encounters_cleaned, directed=FALSE)\nbipartite_matrix &lt;- as_biadjacency_matrix(encounters.ig)  # Extract the matrix\n\npatient_jaccard &lt;- dist.binary(bipartite_matrix, method=1, upper=TRUE, diag = FALSE) # Method #1 is \"Jaccard Index\"\nprovider_jaccard &lt;- dist.binary(t(bipartite_matrix), method=1, upper=TRUE, diag = FALSE) \n\npatient_jaccard &lt;- as.matrix(patient_jaccard)   \ndiag(patient_jaccard)&lt;-0\n\n# women_jaccard          # Look at the matrix before you binarize\npatient_jaccard &lt;- ifelse(patient_jaccard&gt;0.95, 1, 0)     # Binarize\n\n# jaccard_women      # Take a look at the matrix if you like.\n\njacc_patient &lt;- graph_from_adjacency_matrix(patient_jaccard,    # Create an igraph network\n                                        mode = \"undirected\")\nplot(jacc_patient,vertex.label = NA,      vertex.label.dist = 2, \n     vertex.size = 3, vertex.label.cex = 0.2,)\n\n\n\n\n\npatient_correl &lt;- cor(t(bipartite_matrix))\nprovider_correl &lt;- cor(bipartite_matrix)\n\npatient_correl &lt;- as.matrix(patient_correl)   \n# patient_correl          # Look at the matrix before you binarize\ncorrel_patient &lt;- ifelse(patient_correl&gt;0.6, 1, 0)    # Binarize \ndiag(correl_patient)&lt;-0\n\ncorr_patient &lt;- graph_from_adjacency_matrix(correl_patient, \n                                        mode = \"undirected\")\nplot(corr_patient,     vertex.label.dist = .5, \n     vertex.size = 3, vertex.label.cex = .8)\n\n\n\n\n\nlibrary(psych)\n\nWarning: package 'psych' was built under R version 4.3.3\n\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\npatient_Q &lt;-YuleCor(t(bipartite_matrix))$rho\nprovider_Q &lt;-YuleCor(bipartite_matrix)$rho\n\npatient_Q &lt;- as.matrix(patient_Q) \nhead(patient_Q, 10,10)\n\n                        Adam631 Hoppe518 Alesha810 Heaney114\nAdam631 Hoppe518             0.999977634           0.2571596\nAlesha810 Heaney114          0.257159556           0.9999706\nAlissa315 Altenwerth646      0.921939729           0.2571596\nAnalisa263 Kohler843         0.120355835           0.2571596\nAnnice210 Gleason633         0.257159556           0.3843690\nAnthony633 Kutch271          0.257159556           0.9637365\nBenedict104 Hintz995         0.430178690           0.5386251\nCarl856 Rempel203            0.009474183           0.1504567\nChanell45 Morissette863      0.009474183           0.1504567\nChaya236 Sporer811           0.257159556           0.3843690\n                        Alissa315 Altenwerth646 Analisa263 Kohler843\nAdam631 Hoppe518                    0.921939729          0.120355835\nAlesha810 Heaney114                 0.257159556          0.257159556\nAlissa315 Altenwerth646             0.999977634          0.120355835\nAnalisa263 Kohler843                0.120355835          0.999977634\nAnnice210 Gleason633                0.257159556          0.257159556\nAnthony633 Kutch271                 0.257159556          0.257159556\nBenedict104 Hintz995                0.430178690          0.430178690\nCarl856 Rempel203                   0.009474183          0.009474183\nChanell45 Morissette863             0.009474183          0.009474183\nChaya236 Sporer811                  0.257159556          0.257159556\n                        Annice210 Gleason633 Anthony633 Kutch271\nAdam631 Hoppe518                   0.2571596           0.2571596\nAlesha810 Heaney114                0.3843690           0.9637365\nAlissa315 Altenwerth646            0.2571596           0.2571596\nAnalisa263 Kohler843               0.2571596           0.2571596\nAnnice210 Gleason633               0.9999706           0.3843690\nAnthony633 Kutch271                0.3843690           0.9999706\nBenedict104 Hintz995               0.5386251           0.5386251\nCarl856 Rempel203                  0.1504567           0.1504567\nChanell45 Morissette863            0.1504567           0.1504567\nChaya236 Sporer811                 0.3843690           0.3843690\n                        Benedict104 Hintz995 Carl856 Rempel203\nAdam631 Hoppe518                   0.4301787       0.009474183\nAlesha810 Heaney114                0.5386251       0.150456744\nAlissa315 Altenwerth646            0.4301787       0.009474183\nAnalisa263 Kohler843               0.4301787       0.009474183\nAnnice210 Gleason633               0.5386251       0.150456744\nAnthony633 Kutch271                0.5386251       0.150456744\nBenedict104 Hintz995               0.9999567       0.335195531\nCarl856 Rempel203                  0.3351955       0.999981937\nChanell45 Morissette863            0.3351955       0.866173075\nChaya236 Sporer811                 0.5386251       0.929777343\n                        Chanell45 Morissette863 Chaya236 Sporer811\nAdam631 Hoppe518                    0.009474183          0.2571596\nAlesha810 Heaney114                 0.150456744          0.3843690\nAlissa315 Altenwerth646             0.009474183          0.2571596\nAnalisa263 Kohler843                0.009474183          0.2571596\nAnnice210 Gleason633                0.150456744          0.3843690\nAnthony633 Kutch271                 0.150456744          0.3843690\nBenedict104 Hintz995                0.335195531          0.5386251\nCarl856 Rempel203                   0.866173075          0.9297773\nChanell45 Morissette863             0.999981937          0.9297773\nChaya236 Sporer811                  0.929777343          0.9999706\n                        Cherise743 Prosacco716 Cindi877 Hane680\nAdam631 Hoppe518                   0.009474183      0.009474183\nAlesha810 Heaney114                0.150456744      0.150456744\nAlissa315 Altenwerth646            0.009474183      0.009474183\nAnalisa263 Kohler843               0.009474183      0.897590847\nAnnice210 Gleason633               0.150456744      0.150456744\nAnthony633 Kutch271                0.150456744      0.150456744\nBenedict104 Hintz995               0.335195531      0.335195531\nCarl856 Rempel203                 -0.101651842     -0.101651842\nChanell45 Morissette863           -0.101651842     -0.101651842\nChaya236 Sporer811                 0.150456744      0.150456744\n                        Cruz300 Wilderman619 Damian46 Dach178 Diana207 Stamm704\nAdam631 Hoppe518                   0.1203558        0.4301787         0.2571596\nAlesha810 Heaney114                0.2571596        0.5386251         0.3843690\nAlissa315 Altenwerth646            0.1203558        0.4301787         0.2571596\nAnalisa263 Kohler843               0.1203558        0.4301787         0.2571596\nAnnice210 Gleason633               0.2571596        0.5386251         0.3843690\nAnthony633 Kutch271                0.2571596        0.5386251         0.3843690\nBenedict104 Hintz995               0.4301787        0.6636156         0.5386251\nCarl856 Rempel203                  0.8975908        0.3351955         0.1504567\nChanell45 Morissette863            0.9715857        0.3351955         0.1504567\nChaya236 Sporer811                 0.9466874        0.5386251         0.3843690\n                        Dinorah501 Bechtelar572 Donald774 Krajcik437\nAdam631 Hoppe518                    0.009474183            0.2571596\nAlesha810 Heaney114                 0.150456744            0.3843690\nAlissa315 Altenwerth646             0.009474183            0.2571596\nAnalisa263 Kohler843                0.009474183            0.2571596\nAnnice210 Gleason633                0.150456744            0.3843690\nAnthony633 Kutch271                 0.150456744            0.3843690\nBenedict104 Hintz995                0.335195531            0.5386251\nCarl856 Rempel203                  -0.101651842            0.1504567\nChanell45 Morissette863            -0.101651842            0.1504567\nChaya236 Sporer811                  0.150456744            0.3843690\n                        Dorothea248 Fritsch593 Dortha70 Rutherford999\nAdam631 Hoppe518                     0.1203558            0.120355835\nAlesha810 Heaney114                  0.2571596            0.257159556\nAlissa315 Altenwerth646              0.1203558            0.120355835\nAnalisa263 Kohler843                 0.1203558            0.120355835\nAnnice210 Gleason633                 0.2571596            0.257159556\nAnthony633 Kutch271                  0.2571596            0.257159556\nBenedict104 Hintz995                 0.4301787            0.430178690\nCarl856 Rempel203                    0.8975908            0.009474183\nChanell45 Morissette863              0.8975908            0.009474183\nChaya236 Sporer811                   0.9466874            0.257159556\n                        Dusti191 Maggio310 Elease461 Boehm581\nAdam631 Hoppe518               0.120355835        0.120355835\nAlesha810 Heaney114            0.257159556        0.257159556\nAlissa315 Altenwerth646        0.120355835        0.120355835\nAnalisa263 Kohler843           0.120355835        0.120355835\nAnnice210 Gleason633           0.257159556        0.257159556\nAnthony633 Kutch271            0.257159556        0.257159556\nBenedict104 Hintz995           0.430178690        0.430178690\nCarl856 Rempel203              0.009474183        0.009474183\nChanell45 Morissette863        0.009474183        0.009474183\nChaya236 Sporer811             0.257159556        0.257159556\n                        Esther279 Schroeder447 Everette494 O'Hara248\nAdam631 Hoppe518                   0.120355835             0.2571596\nAlesha810 Heaney114                0.257159556             0.3843690\nAlissa315 Altenwerth646            0.921939729             0.2571596\nAnalisa263 Kohler843               0.120355835             0.2571596\nAnnice210 Gleason633               0.257159556             0.3843690\nAnthony633 Kutch271                0.257159556             0.3843690\nBenedict104 Hintz995               0.430178690             0.5386251\nCarl856 Rempel203                  0.009474183             0.1504567\nChanell45 Morissette863            0.009474183             0.1504567\nChaya236 Sporer811                 0.257159556             0.3843690\n                        Gino587 Vandervort697 Gordon377 Marquardt819\nAdam631 Hoppe518                    0.2571596            -0.08221549\nAlesha810 Heaney114                 0.3843690             0.05967181\nAlissa315 Altenwerth646             0.2571596             0.87363120\nAnalisa263 Kohler843                0.2571596            -0.08221549\nAnnice210 Gleason633                0.3843690             0.05967181\nAnthony633 Kutch271                 0.3843690             0.05967181\nBenedict104 Hintz995                0.5386251             0.25131502\nCarl856 Rempel203                   0.1504567            -0.19149751\nChanell45 Morissette863             0.1504567            -0.19149751\nChaya236 Sporer811                  0.3843690             0.05967181\n                        Guadalupe206 Wuckert783 Gwen761 Keeling57\nAdam631 Hoppe518                    0.120355835         0.4301787\nAlesha810 Heaney114                 0.257159556         0.5386251\nAlissa315 Altenwerth646             0.921939729         0.4301787\nAnalisa263 Kohler843                0.120355835         0.4301787\nAnnice210 Gleason633                0.989917507         0.5386251\nAnthony633 Kutch271                 0.257159556         0.5386251\nBenedict104 Hintz995                0.430178690         0.6636156\nCarl856 Rempel203                   0.009474183         0.3351955\nChanell45 Morissette863             0.009474183         0.3351955\nChaya236 Sporer811                  0.257159556         0.5386251\n                        Ivan258 Hills818 Jeanelle736 Simonis280\nAdam631 Hoppe518             0.120355835              0.2571596\nAlesha810 Heaney114          0.257159556              0.3843690\nAlissa315 Altenwerth646      0.120355835              0.2571596\nAnalisa263 Kohler843         0.120355835              0.2571596\nAnnice210 Gleason633         0.257159556              0.3843690\nAnthony633 Kutch271          0.257159556              0.3843690\nBenedict104 Hintz995         0.430178690              0.5386251\nCarl856 Rempel203            0.009474183              0.1504567\nChanell45 Morissette863      0.009474183              0.1504567\nChaya236 Sporer811           0.257159556              0.3843690\n                        Jeanette800 Schinner682 Johnnie679 Hand679\nAdam631 Hoppe518                    0.120355835        0.120355835\nAlesha810 Heaney114                 0.257159556        0.257159556\nAlissa315 Altenwerth646             0.120355835        0.921939729\nAnalisa263 Kohler843                0.120355835        0.120355835\nAnnice210 Gleason633                0.257159556        0.257159556\nAnthony633 Kutch271                 0.257159556        0.257159556\nBenedict104 Hintz995                0.430178690        0.430178690\nCarl856 Rempel203                   0.009474183        0.009474183\nChanell45 Morissette863             0.009474183        0.009474183\nChaya236 Sporer811                  0.257159556        0.257159556\n                        Johnny786 Smith67 Jorge203 Ferry570\nAdam631 Hoppe518                0.9899175       0.120355835\nAlesha810 Heaney114             0.3843690       0.257159556\nAlissa315 Altenwerth646         0.9899175       0.921939729\nAnalisa263 Kohler843            0.2571596       0.120355835\nAnnice210 Gleason633            0.3843690       0.257159556\nAnthony633 Kutch271             0.3843690       0.257159556\nBenedict104 Hintz995            0.5386251       0.430178690\nCarl856 Rempel203               0.1504567       0.009474183\nChanell45 Morissette863         0.1504567       0.009474183\nChaya236 Sporer811              0.3843690       0.257159556\n                        Julianne852 Barrows492 Kandis954 Koepp521\nAdam631 Hoppe518                   0.120355835          0.2571596\nAlesha810 Heaney114                0.257159556          0.3843690\nAlissa315 Altenwerth646            0.120355835          0.2571596\nAnalisa263 Kohler843               0.120355835          0.2571596\nAnnice210 Gleason633               0.257159556          0.3843690\nAnthony633 Kutch271                0.257159556          0.3843690\nBenedict104 Hintz995               0.430178690          0.5386251\nCarl856 Rempel203                  0.009474183          0.1504567\nChanell45 Morissette863            0.009474183          0.1504567\nChaya236 Sporer811                 0.257159556          0.3843690\n                        Kathlyn335 Wisozk929 Kathrine376 Bosco882\nAdam631 Hoppe518                   0.2571596            0.2571596\nAlesha810 Heaney114                0.3843690            0.3843690\nAlissa315 Altenwerth646            0.2571596            0.2571596\nAnalisa263 Kohler843               0.2571596            0.2571596\nAnnice210 Gleason633               0.3843690            0.3843690\nAnthony633 Kutch271                0.3843690            0.3843690\nBenedict104 Hintz995               0.5386251            0.5386251\nCarl856 Rempel203                  0.1504567            0.1504567\nChanell45 Morissette863            0.1504567            0.1504567\nChaya236 Sporer811                 0.3843690            0.3843690\n                        Krystina167 Muller251 Lan153 Schmidt332 Lani848 Cole117\nAdam631 Hoppe518                    0.2571596       -0.08221549     0.120355835\nAlesha810 Heaney114                 0.3843690        0.05967181     0.257159556\nAlissa315 Altenwerth646             0.2571596       -0.08221549     0.921939729\nAnalisa263 Kohler843                0.2571596       -0.08221549     0.120355835\nAnnice210 Gleason633                0.3843690        0.05967181     0.257159556\nAnthony633 Kutch271                 0.3843690        0.05967181     0.257159556\nBenedict104 Hintz995                0.5386251        0.25131502     0.430178690\nCarl856 Rempel203                   0.1504567       -0.19149751     0.009474183\nChanell45 Morissette863             0.1504567       -0.19149751     0.009474183\nChaya236 Sporer811                  0.3843690        0.05967181     0.257159556\n                        Lawerence6 Grimes165 Leland44 Huels583\nAdam631 Hoppe518                 0.120355835         0.2571596\nAlesha810 Heaney114              0.257159556         0.3843690\nAlissa315 Altenwerth646          0.120355835         0.2571596\nAnalisa263 Kohler843             0.120355835         0.2571596\nAnnice210 Gleason633             0.257159556         0.3843690\nAnthony633 Kutch271              0.257159556         0.3843690\nBenedict104 Hintz995             0.430178690         0.5386251\nCarl856 Rempel203                0.009474183         0.1504567\nChanell45 Morissette863          0.009474183         0.1504567\nChaya236 Sporer811               0.257159556         0.3843690\n                        Lemuel304 Mante251 Leonel449 Witting912\nAdam631 Hoppe518               0.009474183          0.009474183\nAlesha810 Heaney114            0.150456744          0.150456744\nAlissa315 Altenwerth646        0.897590847          0.897590847\nAnalisa263 Kohler843           0.897590847          0.897590847\nAnnice210 Gleason633           0.150456744          0.150456744\nAnthony633 Kutch271            0.150456744          0.150456744\nBenedict104 Hintz995           0.335195531          0.335195531\nCarl856 Rempel203             -0.101651842         -0.101651842\nChanell45 Morissette863       -0.101651842         -0.101651842\nChaya236 Sporer811             0.150456744          0.150456744\n                        Lorina403 Cronin387 Lorretta561 Metz686\nAdam631 Hoppe518                  0.2571596           0.1203558\nAlesha810 Heaney114               0.3843690           0.2571596\nAlissa315 Altenwerth646           0.2571596           0.1203558\nAnalisa263 Kohler843              0.2571596           0.1203558\nAnnice210 Gleason633              0.3843690           0.2571596\nAnthony633 Kutch271               0.3843690           0.2571596\nBenedict104 Hintz995              0.5386251           0.4301787\nCarl856 Rempel203                 0.1504567           0.8975908\nChanell45 Morissette863           0.9297773           0.9715857\nChaya236 Sporer811                0.3843690           0.9466874\n                        Lou594 Krajcik437 Madelyn308 Schumm995\nAdam631 Hoppe518                0.2571596          0.009474183\nAlesha810 Heaney114             0.3843690          0.150456744\nAlissa315 Altenwerth646         0.2571596          0.897590847\nAnalisa263 Kohler843            0.2571596          0.009474183\nAnnice210 Gleason633            0.3843690          0.150456744\nAnthony633 Kutch271             0.3843690          0.150456744\nBenedict104 Hintz995            0.5386251          0.335195531\nCarl856 Rempel203               0.1504567         -0.101651842\nChanell45 Morissette863         0.1504567         -0.101651842\nChaya236 Sporer811              0.3843690          0.150456744\n                        Marcos263 Mills423 Margarito178 Schulist381\nAdam631 Hoppe518                 0.2571596              0.120355835\nAlesha810 Heaney114              0.3843690              0.257159556\nAlissa315 Altenwerth646          0.2571596              0.120355835\nAnalisa263 Kohler843             0.2571596              0.120355835\nAnnice210 Gleason633             0.3843690              0.257159556\nAnthony633 Kutch271              0.3843690              0.257159556\nBenedict104 Hintz995             0.5386251              0.999083410\nCarl856 Rempel203                0.1504567              0.009474183\nChanell45 Morissette863          0.1504567              0.009474183\nChaya236 Sporer811               0.3843690              0.257159556\n                        Mario764 Glover433 Maryellen651 Conn188 Mia349 Runte676\nAdam631 Hoppe518               0.009474183            0.2571596     0.120355835\nAlesha810 Heaney114            0.150456744            0.3843690     0.257159556\nAlissa315 Altenwerth646        0.897590847            0.9466874     0.120355835\nAnalisa263 Kohler843           0.009474183            0.2571596     0.120355835\nAnnice210 Gleason633           0.150456744            0.3843690     0.257159556\nAnthony633 Kutch271            0.150456744            0.3843690     0.257159556\nBenedict104 Hintz995           0.335195531            0.5386251     0.430178690\nCarl856 Rempel203             -0.101651842            0.1504567     0.009474183\nChanell45 Morissette863       -0.101651842            0.1504567     0.009474183\nChaya236 Sporer811             0.150456744            0.3843690     0.257159556\n                        Monroe732 Fritsch593 Mose244 Cummerata161\nAdam631 Hoppe518                   0.2571596          0.980751604\nAlesha810 Heaney114                0.3843690          0.257159556\nAlissa315 Altenwerth646            0.2571596          0.120355835\nAnalisa263 Kohler843               0.2571596          0.120355835\nAnnice210 Gleason633               0.3843690          0.257159556\nAnthony633 Kutch271                0.3843690          0.257159556\nBenedict104 Hintz995               0.5386251          0.430178690\nCarl856 Rempel203                  0.1504567          0.009474183\nChanell45 Morissette863            0.1504567          0.009474183\nChaya236 Sporer811                 0.3843690          0.257159556\n                        Mozelle144 Zboncak558 Nelida367 Emard19\nAdam631 Hoppe518                  0.120355835       0.120355835\nAlesha810 Heaney114               0.257159556       0.257159556\nAlissa315 Altenwerth646           0.120355835       0.120355835\nAnalisa263 Kohler843              0.120355835       0.120355835\nAnnice210 Gleason633              0.257159556       0.257159556\nAnthony633 Kutch271               0.257159556       0.257159556\nBenedict104 Hintz995              0.430178690       0.430178690\nCarl856 Rempel203                 0.009474183       0.009474183\nChanell45 Morissette863           0.009474183       0.009474183\nChaya236 Sporer811                0.257159556       0.257159556\n                        Odilia72 Upton904 Ola364 Kreiger457 Oliva247 Braun514\nAdam631 Hoppe518              0.120355835       0.120355835       0.120355835\nAlesha810 Heaney114           0.257159556       0.257159556       0.257159556\nAlissa315 Altenwerth646       0.120355835       0.120355835       0.120355835\nAnalisa263 Kohler843          0.120355835       0.120355835       0.120355835\nAnnice210 Gleason633          0.257159556       0.257159556       0.257159556\nAnthony633 Kutch271           0.257159556       0.257159556       0.257159556\nBenedict104 Hintz995          0.430178690       0.430178690       0.430178690\nCarl856 Rempel203             0.009474183       0.009474183       0.009474183\nChanell45 Morissette863       0.009474183       0.009474183       0.009474183\nChaya236 Sporer811            0.257159556       0.257159556       0.257159556\n                        Ouida808 Carroll471 Ramon749 Kozey370\nAdam631 Hoppe518                  0.2571596       -0.22500922\nAlesha810 Heaney114               0.3843690       -0.08654262\nAlissa315 Altenwerth646           0.2571596        0.82684289\nAnalisa263 Kohler843              0.2571596       -0.22500922\nAnnice210 Gleason633              0.3843690       -0.08654262\nAnthony633 Kutch271               0.3843690       -0.08654262\nBenedict104 Hintz995              0.5386251        0.10989011\nCarl856 Rempel203                 0.1504567        0.77626624\nChanell45 Morissette863           0.1504567        0.77626624\nChaya236 Sporer811                0.3843690        0.87986464\n                        Regan713 Kertzmann286 Rod343 Prosacco716\nAdam631 Hoppe518                  0.009474183          0.2571596\nAlesha810 Heaney114               0.150456744          0.3843690\nAlissa315 Altenwerth646           0.009474183          0.2571596\nAnalisa263 Kohler843              0.009474183          0.2571596\nAnnice210 Gleason633              0.150456744          0.3843690\nAnthony633 Kutch271               0.150456744          0.3843690\nBenedict104 Hintz995              0.335195531          0.5386251\nCarl856 Rempel203                -0.101651842          0.1504567\nChanell45 Morissette863          -0.101651842          0.1504567\nChaya236 Sporer811                0.150456744          0.3843690\n                        Rolland302 Kassulke119 Rosamaria757 Orn563\nAdam631 Hoppe518                   0.120355835         0.009474183\nAlesha810 Heaney114                0.257159556         0.150456744\nAlissa315 Altenwerth646            0.921939729         0.009474183\nAnalisa263 Kohler843               0.120355835         0.009474183\nAnnice210 Gleason633               0.257159556         0.150456744\nAnthony633 Kutch271                0.257159556         0.150456744\nBenedict104 Hintz995               0.430178690         0.335195531\nCarl856 Rempel203                  0.009474183        -0.101651842\nChanell45 Morissette863            0.009474183        -0.101651842\nChaya236 Sporer811                 0.257159556         0.150456744\n                        Rudy520 Hettinger594 Rupert654 Jenkins714\nAdam631 Hoppe518                 0.009474183          0.120355835\nAlesha810 Heaney114              0.150456744          0.257159556\nAlissa315 Altenwerth646          0.897590847          0.921939729\nAnalisa263 Kohler843             0.009474183          0.120355835\nAnnice210 Gleason633             0.150456744          0.257159556\nAnthony633 Kutch271              0.150456744          0.257159556\nBenedict104 Hintz995             0.335195531          0.430178690\nCarl856 Rempel203               -0.101651842          0.009474183\nChanell45 Morissette863         -0.101651842          0.009474183\nChaya236 Sporer811               0.150456744          0.257159556\n                        Russell422 Stracke611 Ryann170 Spencer878\nAdam631 Hoppe518                    0.2571596         0.009474183\nAlesha810 Heaney114                 0.3843690         0.150456744\nAlissa315 Altenwerth646             0.2571596         0.009474183\nAnalisa263 Kohler843                0.2571596         0.009474183\nAnnice210 Gleason633                0.3843690         0.150456744\nAnthony633 Kutch271                 0.3843690         0.150456744\nBenedict104 Hintz995                0.5386251         0.335195531\nCarl856 Rempel203                   0.1504567        -0.101651842\nChanell45 Morissette863             0.1504567        -0.101651842\nChaya236 Sporer811                  0.3843690         0.150456744\n                        Sabine292 Feil794 Sandee884 Rice937\nAdam631 Hoppe518              -0.15929908         0.2571596\nAlesha810 Heaney114           -0.01850995         0.3843690\nAlissa315 Altenwerth646        0.85005154         0.2571596\nAnalisa263 Kohler843          -0.15929908         0.2571596\nAnnice210 Gleason633          -0.01850995         0.3843690\nAnthony633 Kutch271           -0.01850995         0.3843690\nBenedict104 Hintz995           0.17669796         0.5386251\nCarl856 Rempel203             -0.26564138         0.1504567\nChanell45 Morissette863       -0.26564138         0.1504567\nChaya236 Sporer811            -0.01850995         0.3843690\n                        Serena400 Powlowski563 Shara355 Bruen238\nAdam631 Hoppe518                   0.009474183       0.120355835\nAlesha810 Heaney114                0.150456744       0.257159556\nAlissa315 Altenwerth646            0.009474183       0.120355835\nAnalisa263 Kohler843               0.009474183       0.120355835\nAnnice210 Gleason633               0.150456744       0.257159556\nAnthony633 Kutch271                0.150456744       0.257159556\nBenedict104 Hintz995               0.335195531       0.430178690\nCarl856 Rempel203                  0.866173075       0.009474183\nChanell45 Morissette863            0.866173075       0.009474183\nChaya236 Sporer811                 0.929777343       0.257159556\n                        Shila857 Heller342 Spencer878 Bailey598\nAdam631 Hoppe518               0.009474183            0.2571596\nAlesha810 Heaney114            0.150456744            0.3843690\nAlissa315 Altenwerth646        0.009474183            0.2571596\nAnalisa263 Kohler843           0.009474183            0.2571596\nAnnice210 Gleason633           0.150456744            0.3843690\nAnthony633 Kutch271            0.150456744            0.3843690\nBenedict104 Hintz995           0.335195531            0.5386251\nCarl856 Rempel203             -0.101651842            0.1504567\nChanell45 Morissette863       -0.101651842            0.1504567\nChaya236 Sporer811             0.150456744            0.3843690\n                        Stanley702 Cremin516 Stephan15 Auer97 Tera136 Swift555\nAdam631 Hoppe518                 -0.08221549        0.2571596      0.120355835\nAlesha810 Heaney114               0.05967181        0.3843690      0.257159556\nAlissa315 Altenwerth646          -0.08221549        0.2571596      0.120355835\nAnalisa263 Kohler843             -0.08221549        0.2571596      0.120355835\nAnnice210 Gleason633              0.05967181        0.3843690      0.257159556\nAnthony633 Kutch271               0.05967181        0.3843690      0.257159556\nBenedict104 Hintz995              0.25131502        0.5386251      0.430178690\nCarl856 Rempel203                -0.19149751        0.1504567      0.009474183\nChanell45 Morissette863          -0.19149751        0.1504567      0.009474183\nChaya236 Sporer811                0.05967181        0.3843690      0.257159556\n                        Theodore876 Thiel172 Tomika243 Walker122\nAdam631 Hoppe518                   0.1203558         -0.15929908\nAlesha810 Heaney114                0.2571596         -0.01850995\nAlissa315 Altenwerth646            0.1203558         -0.15929908\nAnalisa263 Kohler843               0.1203558         -0.15929908\nAnnice210 Gleason633               0.2571596         -0.01850995\nAnthony633 Kutch271                0.2571596         -0.01850995\nBenedict104 Hintz995               0.4301787          0.17669796\nCarl856 Rempel203                  0.8975908         -0.26564138\nChanell45 Morissette863            0.8975908         -0.26564138\nChaya236 Sporer811                 0.9466874         -0.01850995\n                        Tommy814 Miller503 Troy560 Kohler843\nAdam631 Hoppe518               0.921939729       0.120355835\nAlesha810 Heaney114            0.257159556       0.257159556\nAlissa315 Altenwerth646        0.120355835       0.120355835\nAnalisa263 Kohler843           0.120355835       0.120355835\nAnnice210 Gleason633           0.257159556       0.257159556\nAnthony633 Kutch271            0.257159556       0.257159556\nBenedict104 Hintz995           0.430178690       0.430178690\nCarl856 Rempel203              0.009474183       0.009474183\nChanell45 Morissette863        0.009474183       0.009474183\nChaya236 Sporer811             0.257159556       0.257159556\n                        Tyler508 Ankunding277 Wilburn655 Sipes176\nAdam631 Hoppe518                  0.120355835           0.4301787\nAlesha810 Heaney114               0.257159556           0.5386251\nAlissa315 Altenwerth646           0.120355835           0.4301787\nAnalisa263 Kohler843              0.120355835           0.4301787\nAnnice210 Gleason633              0.257159556           0.5386251\nAnthony633 Kutch271               0.257159556           0.5386251\nBenedict104 Hintz995              0.430178690           0.6636156\nCarl856 Rempel203                 0.009474183           0.3351955\nChanell45 Morissette863           0.009474183           0.3351955\nChaya236 Sporer811                0.257159556           0.5386251\n                        Wilfred787 Nienow652\nAdam631 Hoppe518                 0.120355835\nAlesha810 Heaney114              0.257159556\nAlissa315 Altenwerth646          0.120355835\nAnalisa263 Kohler843             0.120355835\nAnnice210 Gleason633             0.257159556\nAnthony633 Kutch271              0.257159556\nBenedict104 Hintz995             0.430178690\nCarl856 Rempel203                0.009474183\nChanell45 Morissette863          0.009474183\nChaya236 Sporer811               0.257159556\n\n\n\nQ_patient &lt;- ifelse(patient_Q&gt;0.9, 1, 0) # Binarize\ndiag(Q_patient)&lt;-0\n# Q_patient    # Take a look at the matrix\n\nYQ_patient &lt;- graph_from_adjacency_matrix(Q_patient,     # Create an igraph network\n                                        mode = \"undirected\")\nplot(YQ_patient,   vertex.label.dist = 1, \n     vertex.size = 5, vertex.label.cex = .8, layout = layout_with_fr)\n\n\n\n\n\nlayouts &lt;- grep(\"^layout_\", ls(\"package:igraph\"), value=TRUE)[-1] \n\n# Remove layouts that do not apply to our graph.\n\nlayouts &lt;- layouts[!grepl(\"bipartite|merge|norm|sugiyama|tree\", layouts)]\n\npar(mfrow=c(3,3), mar=c(1,1,1,1))\n\nfor (layout in layouts) {\n\n  print(layout)\n\n  l &lt;- do.call(layout, list(encounters.ig)) \n\n  plot(encounters.ig, vertex.label = NA,      vertex.label.dist = 2, \n     vertex.size = 3, vertex.label.cex = 0.2, edge.arrow.mode=0, layout=l, main=layout) }\n\n[1] \"layout_as_star\"\n\n\n[1] \"layout_components\"\n\n\n[1] \"layout_in_circle\"\n\n\n[1] \"layout_nicely\"\n\n\n[1] \"layout_on_grid\"\n\n\n[1] \"layout_on_sphere\"\n\n\n[1] \"layout_randomly\"\n\n\n[1] \"layout_with_dh\"\n\n\n[1] \"layout_with_drl\"\n\n\n\n\n\n[1] \"layout_with_fr\"\n\n\n[1] \"layout_with_gem\"\n\n\n[1] \"layout_with_graphopt\"\n\n\n[1] \"layout_with_kk\"\n\n\n[1] \"layout_with_lgl\"\n\n\nWarning in layout_with_lgl(structure(list(308, FALSE, c(86, 87, 88, 89, : At\nvendor/cigraph/src/layout/large_graph.c:174 : LGL layout does not support\ndisconnected graphs yet.\n\n\n[1] \"layout_with_mds\"\n\n\n\n\n\n\nedge_density(encounters.ig, loops=F)\n\n[1] 0.007212657\n\ntransitivity(encounters.ig, type=\"global\")  # net is treated as an undirected network\n\n[1] 0\n\ntransitivity(as.undirected(encounters.ig, mode=\"collapse\")) # same as above\n\n[1] 0\n\ntriad_census(encounters.ig)\n\nWarning in triad_census(encounters.ig): At\nvendor/cigraph/src/misc/motifs.c:1140 : Triad census called on an undirected\ngraph. All connections will be treated as mutual.\n\n\n [1] 4718886       0  102594       0       0       0       0       0       0\n[10]       0     876       0       0       0       0       0\n\n\n\ndiameter(encounters.ig, directed=F, weights=NA)\n\n[1] 14\n\ndiameter(encounters.ig, directed=F)\n\n[1] 14\n\ndiam &lt;- get_diameter(encounters.ig, directed=T)\n\ndiam\n\n+ 15/308 vertices, named, from 5d1ed35:\n [1] Aubrey96 Emard19       Gino587 Vandervort697  Jettie913 Rodriguez71 \n [4] Dortha70 Rutherford999 Anderson154 Lemke654   Johnnie679 Hand679    \n [7] Ted955 Reilly981       Sabine292 Feil794      Gino587 Block661      \n[10] Rosamaria757 Orn563    Cortez851 Price929     Nelida367 Emard19     \n[13] Chantell995 Krajcik437 Kandis954 Koepp521     Annelle169 Schmidt332 \n\nclass(diam)\n\n[1] \"igraph.vs\"\n\nas.vector(diam)\n\n [1] 161  24 145  19 143  31  95  71 261  66 120  57 188  35 187\n\nvcol &lt;- rep(\"gray40\", vcount(encounters.ig))\n\nvcol[diam] &lt;- \"gold\"\n\necol &lt;- rep(\"gray80\", ecount(encounters.ig))\n\necol[E(encounters.ig, path=diam)] &lt;- \"orange\" \n\n# E(encounters.ig, path=diam) finds edges along a path, here 'diam'\n\nplot(encounters.ig, vertex.color=vcol,  vertex.label = NA,      vertex.label.dist = 2, \n     vertex.size = 3, vertex.label.cex = 0.2, edge.color=ecol, vertex.name = NA, edge.arrow.mode=0)\n\n\n\n\n#deg &lt;- degree(encounters.ig, mode=“all”)\n#hist(deg, breaks=1:vcount(encounters.ig)-1, main=“Histogram of node degree”)\n#deg.dist &lt;- degree_distribution(encounters.ig, cumulative=T, mode=“all”)\n#plot( x=0:max(deg), y=1-deg.dist, pch=19, cex=1.2, col=“orange”,\n # xlab=\"Degree\", ylab=\"Cumulative Frequency\")\n#degree(encounters.ig, mode=“in”)\ncentr_degree(encounters.ig, mode=“in”, normalized=T)\n#closeness(encounters.ig, mode=“all”, weights=NA)\ncentr_clo(encounters.ig, mode=“all”, normalized=T)\neigen_centrality(encounters.ig, directed=F, weights=NA)\ncentr_eigen(encounters.ig, directed=F, normalized=T)\nbetweenness(encounters.ig, directed=F, weights=NA)\nedge_betweenness(encounters.ig, directed=F, weights=NA)\ncentr_betw(encounters.ig, directed=F, normalized=T)\n\nhs &lt;- hub_score(encounters.ig, weights=NA)$vector\n\nas &lt;- authority_score(encounters.ig, weights=NA)$vector\n\n\n\npar(mfrow=c(1,2))\n\n plot(encounters.ig,  vertex.label = NA,      vertex.label.dist = 2, \n     vertex.label.cex = 0.2,vertex.size=hs*50, main=\"Hubs\")\n\n plot(encounters.ig,  vertex.label = NA,      vertex.label.dist = 2, \n   vertex.label.cex = 0.2,vertex.size=as*30, main=\"Authorities\")\n\n\n\n mean_distance(encounters.ig, directed=F)\n\n[1] 6.160216\n\n#distances(encounters.ig) # with edge weights\n\n#distances(encounters.ig, weights=NA) # ignore weights\n\nkc &lt;- coreness(encounters.ig, mode=\"all\")\n\nplot(encounters.ig, vertex.size=kc*6, vertex.label=kc, vertex.color=kc)\n\n\n\n\n\n# Calculate assortativity\nassortativity_degree(encounters.ig, directed=F)\n\n[1] 0.007701883\n\n\nassortativity_degree() checks assortativity in node degrees\n\n\nCreate Gender Matrix\n\ngender &lt;- attributes %&gt;%\n  select(NAME, GENDER) \ngender\n\n# A tibble: 308 × 2\n   NAME                   GENDER\n   &lt;chr&gt;                  &lt;chr&gt; \n 1 Annice210 Gleason633   Female\n 2 Julianne852 Barrows492 Female\n 3 Alesha810 Heaney114    Female\n 4 Sandee884 Rice937      Female\n 5 Mia349 Runte676        Female\n 6 Damian46 Dach178       Male  \n 7 Nelida367 Emard19      Female\n 8 Anthony633 Kutch271    Male  \n 9 Mose244 Cummerata161   Male  \n10 Shila857 Heller342     Female\n# ℹ 298 more rows\n\n\n\n# first create a matrix\ngender.m &lt;- matrix(0, \n                   nrow = nrow(gender),\n                   ncol = nrow(gender))\ndim(gender.m)\n\n[1] 308 308\n\nfor(i in 1:nrow(gender)){\n  for(j in 1:nrow(gender)){\n    gender.m[i, j] &lt;- ifelse(gender$GENDER[i] == gender$GENDER[j], 1, 0)\n  }\n}\n\ndiag(gender.m) &lt;- 0\n\ncolnames(gender.m) &lt;- gender$NAME\nrownames(gender.m) &lt;- gender$NAME\n\ngender.m + 2*encounters.m\nThe above code doesn’t work - but I think this would give the graph I want?"
  },
  {
    "objectID": "posts/Post_Ten - Copy/post_10_drug.html",
    "href": "posts/Post_Ten - Copy/post_10_drug.html",
    "title": "POST 10",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(igraph)\nlibrary(sna)\nlibrary(intergraph)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(tigris)\nlibrary(stplanr)\nThis post will explore the a Gender Matrix"
  },
  {
    "objectID": "posts/Post_Ten - Copy/post_10_drug.html#create-binary-encounter-matrix",
    "href": "posts/Post_Ten - Copy/post_10_drug.html#create-binary-encounter-matrix",
    "title": "POST 10",
    "section": "Create Binary Encounter Matrix",
    "text": "Create Binary Encounter Matrix\n\n# Extract unique patients and providers\npatients &lt;- unique(encounters_el$PATIENT)\nproviders &lt;- unique(encounters_el$PROVIDER)\n\n# Create an empty biadjacency matrix\nencounters_matrix &lt;- matrix(0, nrow = length(patients), ncol = length(providers),\n                            dimnames = list(patients, providers))\n\n# Populate the matrix based on encounter COUNT\nfor (i in 1:nrow(encounters_el)) {\n  patient &lt;- encounters_el$PATIENT[i]\n  provider &lt;- encounters_el$PROVIDER[i]\n  count &lt;- encounters_el$COUNT[i]\n  \n  # Update matrix based on encounter COUNT\n  if (count &gt; 0) {\n    encounters_matrix[patient, provider] &lt;- 1  # Encounter\n  } else {\n    encounters_matrix[patient, provider] &lt;- 0  # No encounter\n  }\n}"
  },
  {
    "objectID": "posts/Post_Ten - Copy/post_10_drug.html#create-gender-sameness-matrix",
    "href": "posts/Post_Ten - Copy/post_10_drug.html#create-gender-sameness-matrix",
    "title": "POST 10",
    "section": "Create Gender Sameness Matrix",
    "text": "Create Gender Sameness Matrix\n\n# Step 1: Extract genders of patients and providers\npatients &lt;- rownames(encounters_matrix)\nproviders &lt;- colnames(encounters_matrix)\n\n# Extract genders of patients and providers\npatient_genders &lt;- encounter_attributes$GENDER.x\nprovider_genders &lt;- encounter_attributes$GENDER.y\n\n# Step 2: Create a new matrix indicating gender sameness only for encounters\ngender_sameness_matrix &lt;- matrix(0, nrow = length(patients), ncol = length(providers),\n                                 dimnames = list(patients, providers))\n\nfor (i in 1:length(patients)) {\n  for (j in 1:length(providers)) {\n    if (encounters_matrix[i, j] == 1) {  # Check if encounter exists\n      # Determine gender sameness based on the 1-4 scale\n      if (patient_genders[i] == \"Female\" && provider_genders[j] == \"Female\") {\n        gender_sameness_matrix[i, j] &lt;- 1  # Female patient and female provider\n      } else if (patient_genders[i] == \"Male\" && provider_genders[j] == \"Male\") {\n        gender_sameness_matrix[i, j] &lt;- 2  # Male patient and male provider\n      } else if (patient_genders[i] == \"Female\" && provider_genders[j] == \"Male\") {\n        gender_sameness_matrix[i, j] &lt;- 3  # Female patient and male provider\n      } else if (patient_genders[i] == \"Male\" && provider_genders[j] == \"Female\") {\n        gender_sameness_matrix[i, j] &lt;- 4  # Male patient and female provider\n      }\n    }\n  }\n}\n\n# Step 3: Convert the matrix into an adjacency matrix format\ngender_sameness_adj_matrix &lt;- gender_sameness_matrix  # Use the gender sameness matrix as the adjacency matrix"
  },
  {
    "objectID": "posts/Post_Ten - Copy/post_10_drug.html#graph",
    "href": "posts/Post_Ten - Copy/post_10_drug.html#graph",
    "title": "POST 10",
    "section": "Graph",
    "text": "Graph\n\ngender_graph &lt;- graph_from_biadjacency_matrix(gender_sameness_adj_matrix, weight = \"TRUE\")\n\nlibrary(igraph)\n\n# Define color palette for the GENDER_SAMENESS attribute\ncolor_palette &lt;- c(\"blue\", \"green\", \"orange\", \"red\")\n\n# Map color palette to the GENDER_SAMENESS values\nedge_colors &lt;- color_palette[encounter_attributes$GENDER_SAMENESS]\n\n# Plot the graph with colored edges\nplot(gender_graph, vertex.size = 1, vertex.label.cex = 0.8, vertex.label = NA, edge.color = edge_colors)"
  }
]